{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1604085287728,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "vhdyliqX3u9G"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub7LYZkn3u9N"
   },
   "source": [
    "# Classifying Music Note sounds using Few Shot Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1604085289594,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "AJfQJHZg4fCD",
    "outputId": "f4fc30fc-cca8-4f00-8b06-c68d42734570"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1604085291847,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "nS19oxec3u9N"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45qAhijR3u9T"
   },
   "source": [
    "#### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1604087202357,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "x1YSn5ic3u9U"
   },
   "outputs": [],
   "source": [
    "def fft(f):\n",
    "    Ni = len(f)\n",
    "    Mi = int(Ni / 2)\n",
    "    if Mi <= 2:\n",
    "        return [f[0] + f[1] + f[2] + f[3], \n",
    "               f[0] - 1j*f[1] - f[2] + 1j*f[3],\n",
    "               f[0] - f[1] + f[2] - f[3],\n",
    "               f[0] + 1j*f[1] - f[2] - 1j*f[3]]\n",
    "    \n",
    "    wn = math.cos(2*math.pi/Ni) - 1j*math.sin(2*math.pi/Ni)\n",
    "    fe = [f[i] for i in range(Ni) if i % 2 == 0]\n",
    "    fo = [f[i] for i in range(Ni) if i % 2 == 1]\n",
    "    Fe = fft(fe)\n",
    "    Fo = fft(fo)\n",
    "    return [np.around(Fe[i] + (wn**i)*Fo[i], decimals=10) for i in range(Mi)] + [np.around(Fe[i] - (wn**i)*Fo[i], decimals=10) for i in range(Mi)]\n",
    "\n",
    "def get_audio_data(filename):\n",
    "    fs = 2**12 # sample rate\n",
    "    tp = 2 # sampling duration\n",
    "    N = n = fs*tp # number of samples\n",
    "    \n",
    "    # Extract data and sampling rate from file\n",
    "    recording, fs = librosa.load(filename, sr=fs, duration=tp, mono=True)\n",
    "\n",
    "    n = len(recording)        \n",
    "    tp = int(n / fs)\n",
    "\n",
    "    if tp < 2:\n",
    "        pad_width = N - recording.shape[0]\n",
    "        recording = np.pad(recording, pad_width=((0, pad_width),), mode='constant')\n",
    "\n",
    "        n = len(recording)\n",
    "        tp = int(n / fs)\n",
    "\n",
    "    N = fs*tp # number of samples\n",
    "    x = [np.round(float(recording[i]), 10) for i in range(n)] # input sequence\n",
    "    return x, tp, n\n",
    "\n",
    "def get_frequency_amplitude(x, tp, N):\n",
    "    _X = fft(x) # discrete Fourier transform\n",
    "    X = [np.round(Xi/N, 10) for Xi in _X] # frequency spectrum\n",
    "    X_amp = [np.absolute(Xi) for Xi in X] # amplitude spectrum\n",
    "\n",
    "    M = int(N/2)\n",
    "    ti = [i*tp/N for i in range(N)]\n",
    "    fi = [i/tp for i in range(M)]\n",
    "    X_amp = np.array(X_amp[:M])*2\n",
    "    \n",
    "    return ti, fi, X_amp\n",
    "\n",
    "def extract_features(filepath):\n",
    "    # try:\n",
    "    audio_features = get_audio_data(filepath)\n",
    "    if not audio_features:\n",
    "        return\n",
    "\n",
    "    x, tp, N = audio_features\n",
    "    ti, fi, X_amp = get_frequency_amplitude(x, tp, N)\n",
    "    return X_amp\n",
    "#     return fi, X_amp\n",
    "    \n",
    "    # except Exception as e:\n",
    "    #     print(\"Error encountered while parsing file: \", file_name, e)\n",
    "    #     return None \n",
    "    \n",
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=3) \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    pad_width = 256 - mfccs.shape[1]\n",
    "    \n",
    "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')     \n",
    "    return mfccs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ6ISFg-3u9Y"
   },
   "source": [
    "#### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406,
     "referenced_widgets": [
      "e46f85e99e09488bae8eb6d70666e4ef",
      "02fa5eedbf8c403c94e45735e8e2072e",
      "cc12aa92344d4fd885d91aafeda3da2a",
      "32033641990b41f0bbee1cb4eb29f795",
      "8b729491eac44963bc4949b2d3ffda1a",
      "0fb775d8199642539df1f477850b9bb8",
      "01870c47bcd4473ea6d4a75a5671983c",
      "ab984203a3b64540aaf15530cd751c56"
     ]
    },
    "executionInfo": {
     "elapsed": 907,
     "status": "error",
     "timestamp": 1604087204042,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "wR58CuvV3u9Y",
    "outputId": "8874ee84-9086-4b8c-9028-ddf902d6d4bc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881c264f67ec4f33a9514845276fee05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished feature extraction from  118  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "DATA_DIR = os.path.join(\"data\", \"guitar_sample\")\n",
    "\n",
    "# feature list\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for folder in tqdm(os.listdir(DATA_DIR)):\n",
    "    class_label = folder\n",
    "    \n",
    "    if class_label.startswith(\"0\"):\n",
    "        continue\n",
    "        \n",
    "    for file in os.listdir(os.path.join(DATA_DIR, folder)):\n",
    "        file_name = os.path.join(os.path.join(DATA_DIR, folder, file))\n",
    "        \n",
    "        data = extract_features(file_name)\n",
    "        if data is None:\n",
    "            continue\n",
    "        \n",
    "        data = np.array(data)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 256, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# featuresdf.feature = featuresdf.feature.apply(lambda xx: xx.reshape((4096, 2)))\n",
    "featuresdf.feature.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "phknq-qI3u9d",
    "outputId": "7742269a-54bf-43d4-afe4-c53ea9737531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-403.97342], [-427.74152], [-478.33362], [-...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-449.60074], [-470.32797], [-528.5974], [-5...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-374.77917], [-398.41254], [-462.8929], [-4...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-400.76926], [-423.18558], [-481.08386], [-...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-391.5319], [-416.02634], [-477.748], [-511...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature class_label\n",
       "0  [[[-403.97342], [-427.74152], [-478.33362], [-...          1A\n",
       "1  [[[-449.60074], [-470.32797], [-528.5974], [-5...          1A\n",
       "2  [[[-374.77917], [-398.41254], [-462.8929], [-4...          1A\n",
       "3  [[[-400.76926], [-423.18558], [-481.08386], [-...          1A\n",
       "4  [[[-391.5319], [-416.02634], [-477.748], [-511...          1A"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HqmrjFhq3u9i"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from math import factorial\n",
    "\n",
    "def number_of_combinations(n, r):\n",
    "    return int(factorial(n) / (factorial(n - r) * factorial(r)))\n",
    "\n",
    "def prepare_data_pair(X, y, labels):\n",
    "    data = [[], []]\n",
    "    data_labels = [[], []]\n",
    "    data_output = []\n",
    "    \n",
    "    for label in labels:\n",
    "        label = f\"1{label}\"\n",
    "        semilabel = f\"0{label}\"\n",
    "\n",
    "        indices = np.array(list(range(len(y))))\n",
    "        similar_indices = indices[y == label]\n",
    "        if len(similar_indices) < 2:\n",
    "            continue\n",
    "            \n",
    "        train_half_size = number_of_combinations(len(similar_indices), 2)\n",
    "\n",
    "        semisimilar_indices = indices[y == semilabel][:train_half_size]\n",
    "\n",
    "        dissimilar_indices = indices[(y != label) & (y != semilabel)]\n",
    "        np.random.shuffle(dissimilar_indices)\n",
    "\n",
    "        dissimilar_indices = dissimilar_indices[:train_half_size - len(semisimilar_indices)]\n",
    "        dissimilar_indices = np.concatenate([semisimilar_indices, dissimilar_indices])\n",
    "\n",
    "        np.random.shuffle(dissimilar_indices)\n",
    "        \n",
    "        counter = 0\n",
    "        it = iter(dissimilar_indices)\n",
    "\n",
    "        for i, j in combinations(similar_indices, 2):\n",
    "            if counter >= len(dissimilar_indices):\n",
    "                break\n",
    "                \n",
    "            counter += 1\n",
    "            z = next(it)\n",
    "#             for sim_index, li in enumerate([[i, j], [z, i]]):\n",
    "            for sim_index, li in enumerate([[z, i], [i, j]]):\n",
    "                data_output.append(float(sim_index))\n",
    "                for index, value in enumerate(li):\n",
    "                    data[index].append(X[value])\n",
    "                    data_labels[index].append(y[value])\n",
    "                    \n",
    "            \n",
    "        print(y[i], y[j], y[z])\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data_labels = np.array(data_labels)\n",
    "    data_output = np.array(data_output)\n",
    "    return data, data_output, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qq7qH_Eh3u9m",
    "outputId": "02734d1c-465a-479e-f383-503415d5f3b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0A', '0B', '0D', '0EH', '0EL', '0G', '1A', '1B', '1D', '1EH', '1EL', '1G']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T9FB6PBB3u9r",
    "outputId": "1759fa47-1cd9-4bad-fe2b-af5260cd2465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1EH 1EH 1B\n",
      "1D 1D 1B\n",
      "1A 1A 1B\n",
      "1B 1B 1EL\n",
      "1G 1G 1B\n",
      "1EL 1EL 1G\n"
     ]
    }
   ],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "input_data = np.array(featuresdf.feature.tolist())\n",
    "output_labels = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split train and test data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=100)\n",
    "for train_index, test_index in sss.split(input_data, output_label):\n",
    "    x_train, x_test = input_data[train_index], input_data[test_index]\n",
    "    y_train_label, y_test_label = output_label[train_index], output_label[test_index]\n",
    "    \n",
    "# labels\n",
    "labels = [\"EH\", \"D\", \"A\", \"B\", \"G\", \"EL\"]\n",
    "\n",
    "# prepare data set pairs\n",
    "x_train_pair, y_train_pair, x_train_label_pair = prepare_data_pair(x_train, y_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lJv29W0y3u91",
    "outputId": "192dd052-b77e-42c0-a50b-74d4e264f5d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 40, 256, 1), (94,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Ri3TLncR3u94",
    "outputId": "90a6c723-2e0f-4a17-e348-8f5f5703b7a9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24, 40, 256, 1), (24,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 940, 40, 256, 1), (940,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pair.shape, y_train_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PhF_lk3g3u98",
    "outputId": "fbdeeee8-c0b5-416e-db4b-e8e687e4aa76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ['1EL' '1EH']\n",
      "1.0 ['1EH' '1EH']\n",
      "0.0 ['1B' '1EH']\n",
      "1.0 ['1EH' '1EH']\n",
      "0.0 ['1EL' '1EH']\n",
      "1.0 ['1EH' '1EH']\n",
      "0.0 ['1D' '1EH']\n",
      "1.0 ['1EH' '1EH']\n",
      "0.0 ['1B' '1EH']\n",
      "1.0 ['1EH' '1EH']\n",
      "0.0 ['1D' '1EH']\n",
      "1.0 ['1EH' '1EH']\n",
      "0.0 ['1A' '1EH']\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    print(y_train_pair[i], x_train_label_pair[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtEvp-x53u9_"
   },
   "source": [
    "### Convolutional Neural Network (CNN) model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "J98TupvE3u-A"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Lambda, LayerNormalization, Layer\n",
    "from tensorflow.keras.layers import BatchNormalization as LayerNormalization, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Conv2D as Conv1D, MaxPooling2D as MaxPooling1D\n",
    "K.clear_session()\n",
    "\n",
    "def build_base_network(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(LayerNormalization(axis=2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=5, activation='relu'))\n",
    "    model.add(LayerNormalization(axis=2))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(LayerNormalization(axis=2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "# #     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(1024))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(LayerNormalization(axis=-1))\n",
    "    model.add(Dropout(0.15))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "#     model.add(LayerNormalization(axis=1))\n",
    "    model.add(Dropout(0.05))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    return model\n",
    "\n",
    "def build_base_network2(input_dim):\n",
    "    # We only test DenseNet-121 in this script for demo purpose\n",
    "    \n",
    "    base_model = tf.keras.applications.DenseNet201(\n",
    "    # base_network = tf.keras.applications.InceptionV3(\n",
    "    # base_network = tf.keras.applications.ResNet101(\n",
    "        include_top=False, weights=None, input_tensor=None, input_shape=input_dim,\n",
    "        pooling=\"max\", classes=128\n",
    "    )\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(128)(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "    \n",
    "def distance(emb1, emb2):\n",
    "    return K.sum(K.square(emb1 - emb2), axis=-1)\n",
    "\n",
    "def get_euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def get_eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSgJQc8F3u-F"
   },
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the same three parameters as the previous model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "niWxBn6e3u-F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_dim = x_train_pair.shape[2:]\n",
    "base_network = build_base_network(input_dim)\n",
    "\n",
    "audio_1 = Input(shape=input_dim)\n",
    "audio_2 = Input(shape=input_dim)\n",
    "\n",
    "feat_vecs_1 = base_network(audio_1)\n",
    "feat_vecs_2 = base_network(audio_2)\n",
    "\n",
    "# # Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "difference = Lambda(get_euclidean_distance, output_shape=get_eucl_dist_output_shape)([feat_vecs_1, feat_vecs_2])\n",
    "\n",
    "# initialize training params\n",
    "epochs = 8\n",
    "batch_size = 32\n",
    "\n",
    "# optimizer = Adam()\n",
    "optimizer = RMSprop()\n",
    "\n",
    "# initialize the network\n",
    "model = Model(inputs=[audio_1, audio_2], outputs=difference)\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 256, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qgqWP5213u-J",
    "outputId": "130f9fc4-709a-4eb8-8541-8d69ce2f095c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 40, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          514944      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "==================================================================================================\n",
      "Total params: 514,944\n",
      "Trainable params: 513,088\n",
      "Non-trainable params: 1,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "pgCkA14N3u-M",
    "outputId": "1d2a63ea-3861-449a-f882-8966d8b53e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 38, 254, 32)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 38, 254, 32)       1016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 127, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 127, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 123, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 123, 32)       492       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 41, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 41, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 39, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 39, 32)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 19, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 19, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 608)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               311808    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 514,944\n",
      "Trainable params: 513,088\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[2].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixLSgTDl3u-P"
   },
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. As training a CNN can take a sigificant amount of time, we will start with a low number of epochs and a low batch size. If we can see from the output that the model is converging, we will increase both numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "rvVo5MbA3u-Q",
    "outputId": "cb3f5a7c-c9cc-4dba-847d-999509bfb5f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 143.2380\n",
      "Epoch 00001: val_loss improved from inf to 459.71283, saving model to saved_models\\weights.best.basic_cnn2.hdf5\n",
      "23/23 [==============================] - 36s 2s/step - loss: 143.2380 - val_loss: 459.7128\n",
      "Epoch 2/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 63.4564\n",
      "Epoch 00002: val_loss improved from 459.71283 to 61.22050, saving model to saved_models\\weights.best.basic_cnn2.hdf5\n",
      "23/23 [==============================] - 36s 2s/step - loss: 63.4564 - val_loss: 61.2205\n",
      "Epoch 3/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 42.1639\n",
      "Epoch 00003: val_loss did not improve from 61.22050\n",
      "23/23 [==============================] - 40s 2s/step - loss: 42.1639 - val_loss: 70.0766\n",
      "Epoch 4/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 28.6848\n",
      "Epoch 00004: val_loss improved from 61.22050 to 43.38447, saving model to saved_models\\weights.best.basic_cnn2.hdf5\n",
      "23/23 [==============================] - 43s 2s/step - loss: 28.6848 - val_loss: 43.3845\n",
      "Epoch 5/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 20.8227\n",
      "Epoch 00005: val_loss did not improve from 43.38447\n",
      "23/23 [==============================] - 40s 2s/step - loss: 20.8227 - val_loss: 44.7453\n",
      "Epoch 6/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 15.9591\n",
      "Epoch 00006: val_loss improved from 43.38447 to 27.46208, saving model to saved_models\\weights.best.basic_cnn2.hdf5\n",
      "23/23 [==============================] - 46s 2s/step - loss: 15.9591 - val_loss: 27.4621\n",
      "Epoch 7/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 10.8316\n",
      "Epoch 00007: val_loss did not improve from 27.46208\n",
      "23/23 [==============================] - 48s 2s/step - loss: 10.8316 - val_loss: 175.8224\n",
      "Epoch 8/8\n",
      "23/23 [==============================] - ETA: 0s - loss: 12.1679\n",
      "Epoch 00008: val_loss improved from 27.46208 to 19.67082, saving model to saved_models\\weights.best.basic_cnn2.hdf5\n",
      "23/23 [==============================] - 43s 2s/step - loss: 12.1679 - val_loss: 19.6708\n",
      "Training completed in time:  7.2674429257710775 min\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from time import time\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models/weights.best.basic_cnn2.hdf5', \n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "start = time()\n",
    "model.fit(\n",
    "    [x_train_pair[0], x_train_pair[1]], \n",
    "    y_train_pair, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=0.25,\n",
    "    callbacks=[early_stopper, checkpointer], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "duration = (time() - start)/60\n",
    "print(\"Training completed in time: \", duration, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model.load_weights(\"saved_models/weights.best.basic_cnn2.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-n0tMCh3u-Y"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6GmeWNQ3u-Y"
   },
   "source": [
    "### Best freq treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "yjOou5Gu3u-a",
    "outputId": "12f7cdf8-da93-4502-8187-8949147d0f20"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def get_eval_params(data_input, data_labels):\n",
    "    pairs = []\n",
    "    distances = [] # squared L2 distance between pairs\n",
    "    identical = [] # 1 if same identity, 0 otherwise\n",
    "\n",
    "    num = len(data_input)\n",
    "    embedded = model.layers[2].predict(data_input)\n",
    "\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            pairs.append([embedded[i], embedded[j]])\n",
    "            distances.append(distance(embedded[i], embedded[j]))\n",
    "            identical.append(1 if data_labels[i] == data_labels[j] else 0)\n",
    "            \n",
    "    pairs = np.array(pairs)\n",
    "    distances = np.array(distances)\n",
    "    identical = np.array(identical)\n",
    "    \n",
    "    return pairs, distances, identical, embedded\n",
    "\n",
    "train_pairs, train_distances, train_identical, train_embedded = get_eval_params(x_train, y_train)\n",
    "test_pairs, test_distances, test_identical, test_embedded = get_eval_params(x_test, y_test)\n",
    "\n",
    "min_threshold = min(train_distances)\n",
    "max_threshold = max(train_distances)\n",
    "threshold_step = (max_threshold - min_threshold)/1000\n",
    "thresholds = np.arange(min_threshold, max_threshold, threshold_step)\n",
    "\n",
    "f1_scores = [f1_score(train_identical, train_distances < t) for t in thresholds]\n",
    "acc_scores = [accuracy_score(train_identical, train_distances < t) for t in thresholds]\n",
    "\n",
    "# max f1\n",
    "opt_idx = np.argmax(f1_scores)\n",
    "opt_f1 = np.max(f1_scores)\n",
    "\n",
    "# Threshold at maximal F1 score\n",
    "opt_tau = thresholds[opt_idx]\n",
    "\n",
    "# Accuracy at maximal F1 score\n",
    "opt_acc = accuracy_score(train_identical, train_distances < opt_tau)\n",
    "\n",
    "# Plot F1 score and accuracy as function of distance threshold\n",
    "plt.plot(thresholds, f1_scores, label='F1 score');\n",
    "plt.plot(thresholds, acc_scores, label='Accuracy');\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title(f'Max: Acc={opt_acc:.2f}, f1={opt_f1:.2f} at threshold {opt_tau:.8f}');\n",
    "plt.xlabel('Distance threshold')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8836,), (8836, 2, 128), (8836,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distances.shape, train_pairs.shape, train_identical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1A', '1B', '1D', '1EH', '1EL', '1G'], dtype='<U3')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022181982797646"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(SVC(kernel=\"rbf\", gamma='auto'))\n",
    "\n",
    "xx_train, yy_train = train_distances.reshape(-1, 1), train_identical\n",
    "xx_test, yy_test = test_distances.reshape(-1, 1), test_identical\n",
    "\n",
    "# xx_train, yy_train = train_embedded, y_train_le\n",
    "# xx_test, yy_test = test_embedded, y_test_le\n",
    "\n",
    "clf.fit(xx_train, yy_train)\n",
    "clf.score(xx_train, yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8836, 1), (8836,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_train.shape, yy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(xx_train, yy_train, c=yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[460,   8],\n",
       "       [ 44,  64]], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(xx_test)\n",
    "confusion_matrix(yy_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([0, 1]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yy_test), np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95       468\n",
      "           1       0.89      0.59      0.71       108\n",
      "\n",
      "    accuracy                           0.91       576\n",
      "   macro avg       0.90      0.79      0.83       576\n",
      "weighted avg       0.91      0.91      0.90       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yy_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "p6kh4vMb3u-f",
    "outputId": "1f655966-f0a8-4924-93e4-4a3f6c1dfb09"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_pos = train_distances[train_identical == 1]\n",
    "dist_neg = train_distances[train_identical == 0]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(dist_pos)\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Distances (pos. pairs)')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(dist_neg)\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Distances (neg. pairs)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOMgyhXR3u-j"
   },
   "source": [
    "### Testing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "rGOEbCnt3u-k",
    "outputId": "fceebb3f-0dff-4f2e-9872-3be7e228020f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8472222222222222\n",
      "\n",
      "classification_report\n",
      "========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       468\n",
      "           1       0.60      0.54      0.57       108\n",
      "\n",
      "    accuracy                           0.85       576\n",
      "   macro avg       0.75      0.73      0.74       576\n",
      "weighted avg       0.84      0.85      0.84       576\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "========================\n",
      "[[430  38]\n",
      " [ 50  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "prediction = test_distances < opt_tau\n",
    "print(\"accuracy =\", accuracy_score(test_identical, prediction))\n",
    "\n",
    "print(\"\\nclassification_report\")\n",
    "print(\"========================\")\n",
    "print(classification_report(test_identical, prediction))\n",
    "\n",
    "print(\"\\nconfusion matrix\")\n",
    "print(\"========================\")\n",
    "print(confusion_matrix(test_identical, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCuryhb33u-n"
   },
   "source": [
    "### Testing (new data) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 128 should be equal to 1, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-f52c40d4d479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msample_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_embedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    482\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[0;32m    483\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0m\u001b[0;32m    485\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m                              (X.shape[1], self.shape_fit_[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 128 should be equal to 1, the number of features at training time"
     ]
    }
   ],
   "source": [
    "sample_label = \"A\"\n",
    "sample_filepath = os.path.join(\"data\", \"sampleA.wav\")\n",
    "\n",
    "sample_vector = extract_features(sample_filepath)\n",
    "sample_vector = np.expand_dims(np.expand_dims(sample_vector, axis=-1), axis=0)\n",
    "\n",
    "sample_embedded = model.layers[2].predict(sample_vector)\n",
    "le.inverse_transform(clf.predict(sample_embedded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "36ddc801b7524eab81e40dcf39c8c0d2"
     ]
    },
    "id": "GXxLglE33u-p",
    "outputId": "adb9efe7-5fae-4b5f-ed4b-e7e8f1e804e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af49b330c43b46e7a5dbc0db7c15ed29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH, D, A, B, G, EL, \n",
      "\n",
      "(58, 40, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_sample = []\n",
    "y_test_sample = []\n",
    "\n",
    "sample_dirs = [\"EH\", \"D\", \"A\", \"B\", \"G\", \"EL\"]\n",
    "# sample_dirs = [\"A\"]\n",
    "\n",
    "for label in tqdm(sample_dirs):\n",
    "    print(label, end=\", \")\n",
    "    labeldir= os.path.join(\"data\", \"old_guitar_sample\", label)\n",
    "\n",
    "    for filename in (os.listdir(labeldir)):\n",
    "        anchor_filepath = os.path.join(\"data\", \"old_guitar_sample\", label, filename)\n",
    "        \n",
    "        anchor_file_vector = extract_features(anchor_filepath)\n",
    "        anchor_file_vector = np.expand_dims(anchor_file_vector, axis=-1)\n",
    "        x_test_sample.append(anchor_file_vector)\n",
    "        y_test_sample.append(label)\n",
    "\n",
    "print()\n",
    "x_test_sample = np.array(x_test_sample)\n",
    "y_test_sample = np.array(y_test_sample)\n",
    "\n",
    "print(x_test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "-Y3kHXH-3u-s",
    "outputId": "cb6b75a1-0c58-458b-e4a8-e90a6739e5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 40, 256, 1)\n",
      "accuracy = 0.786563614744352\n",
      "\n",
      "classification_report\n",
      "========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.86      2802\n",
      "           1       0.41      0.63      0.50       562\n",
      "\n",
      "    accuracy                           0.79      3364\n",
      "   macro avg       0.66      0.73      0.68      3364\n",
      "weighted avg       0.83      0.79      0.80      3364\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "========================\n",
      "[[2290  512]\n",
      " [ 206  356]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "prediction = []\n",
    "\n",
    "num = len(x_test_sample)\n",
    "print(x_test_sample.shape)\n",
    "embedded = model.layers[2].predict(x_test_sample)\n",
    "\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        distances.append(distance(embedded[i], embedded[j]))\n",
    "        identical.append(1 if y_test_sample[i] == y_test_sample[j] else 0)\n",
    "        prediction.append(1 if distances[-1] < opt_tau else 0)\n",
    "        \n",
    "distances = np.array(distances)\n",
    "identical = np.array(identical)\n",
    "prediction = np.array(prediction)\n",
    "\n",
    "print(\"accuracy =\", accuracy_score(identical, prediction))\n",
    "\n",
    "print(\"\\nclassification_report\")\n",
    "print(\"========================\")\n",
    "print(classification_report(identical, prediction))\n",
    "\n",
    "print(\"\\nconfusion matrix\")\n",
    "print(\"========================\")\n",
    "print(confusion_matrix(identical, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LuC2AcO3u-w"
   },
   "source": [
    "### Testing (sample) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "5AMEATl53u-w",
    "outputId": "cff24703-b5d2-46a0-95cd-2a17eaef1bd0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e5c7f7328f4bedb32d8107e8b24673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A, \n",
      "\n",
      "(20, 40, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_sample = []\n",
    "y_test_sample = []\n",
    "\n",
    "sample_dirs = [\"1EH\", \"1D\", \"1A\", \"1B\", \"1G\", \"1EL\"]\n",
    "sample_dirs = [\"1A\"]\n",
    "\n",
    "sample_label = \"A\"\n",
    "sample_filepath = os.path.join(\"data\", \"sampleA.wav\")\n",
    "sample_vector = extract_features(sample_filepath)\n",
    "sample_vector = np.expand_dims(np.expand_dims(sample_vector, axis=-1), axis=0)\n",
    "sample_embedded = model.layers[2].predict(sample_vector)\n",
    "\n",
    "for label in tqdm(sample_dirs):\n",
    "    print(label, end=\", \")\n",
    "    labeldir= os.path.join(DATA_DIR, label)\n",
    "\n",
    "    for filename in (os.listdir(labeldir)):\n",
    "        anchor_filepath = os.path.join(DATA_DIR, label, filename)\n",
    "        \n",
    "        anchor_file_vector = extract_features(anchor_filepath)\n",
    "        anchor_file_vector = np.expand_dims(anchor_file_vector, axis=-1)\n",
    "        x_test_sample.append(anchor_file_vector)\n",
    "        y_test_sample.append(1 if label.startswith(\"1\") and label.endswith(sample_label) else 0)\n",
    "\n",
    "print()\n",
    "x_test_sample = np.array(x_test_sample)\n",
    "y_test_sample = np.array(y_test_sample)\n",
    "\n",
    "print(x_test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "M4omNHOQ3u-1",
    "outputId": "f640715d-b1e0-4685-ee26-4064bdcdcc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.0\n",
      "\n",
      "classification_report\n",
      "========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00      20.0\n",
      "\n",
      "    accuracy                           0.00      20.0\n",
      "   macro avg       0.00      0.00      0.00      20.0\n",
      "weighted avg       0.00      0.00      0.00      20.0\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "========================\n",
      "[[ 0  0]\n",
      " [20  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\christian\\.virtualenvs\\guitar_audio_sample_detection\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "prediction = []\n",
    "\n",
    "num = len(x_test_sample)\n",
    "embedded = model.layers[2].predict(x_test_sample)\n",
    "\n",
    "for i in range(num):\n",
    "    distances.append(distance(embedded[i], sample_embedded))\n",
    "    prediction.append(1 if distances[-1] < opt_tau else 0)\n",
    "\n",
    "identical = y_test_sample\n",
    "distances = np.array(distances)\n",
    "prediction = np.array(prediction)\n",
    "\n",
    "print(\"accuracy =\", accuracy_score(identical, prediction))\n",
    "\n",
    "print(\"\\nclassification_report\")\n",
    "print(\"========================\")\n",
    "print(classification_report(identical, prediction))\n",
    "\n",
    "print(\"\\nconfusion matrix\")\n",
    "print(\"========================\")\n",
    "print(confusion_matrix(identical, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXy-pxCh3u-4",
    "outputId": "72300e2d-ad6b-4897-be37-1cdae1cd69f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction.shape, identical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuE-EUf43u-8"
   },
   "outputs": [],
   "source": [
    "# weights path\n",
    "# weights_path = os.path.join(\"C:\\\\Users\\\\christian\\\\Documents\\\\christian\\\\work\\\\python\\\\guitar_music_note_recognizer\\\\music_note_recognizer\\\\static\\\\music_note_recognizer\\\\weights\", f'{label}_weights.h5')\n",
    "# weights_path = \"saved_models/triplet_128_32.h5\"\n",
    "\n",
    "# load weights\n",
    "# model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JzbHvLB3u--"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Triplet Siamese Network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01870c47bcd4473ea6d4a75a5671983c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02fa5eedbf8c403c94e45735e8e2072e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fb775d8199642539df1f477850b9bb8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32033641990b41f0bbee1cb4eb29f795": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab984203a3b64540aaf15530cd751c56",
      "placeholder": "",
      "style": "IPY_MODEL_01870c47bcd4473ea6d4a75a5671983c",
      "value": " 0/12 [00:00&lt;?, ?it/s]"
     }
    },
    "8b729491eac44963bc4949b2d3ffda1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab984203a3b64540aaf15530cd751c56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc12aa92344d4fd885d91aafeda3da2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fb775d8199642539df1f477850b9bb8",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b729491eac44963bc4949b2d3ffda1a",
      "value": 0
     }
    },
    "e46f85e99e09488bae8eb6d70666e4ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc12aa92344d4fd885d91aafeda3da2a",
       "IPY_MODEL_32033641990b41f0bbee1cb4eb29f795"
      ],
      "layout": "IPY_MODEL_02fa5eedbf8c403c94e45735e8e2072e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
