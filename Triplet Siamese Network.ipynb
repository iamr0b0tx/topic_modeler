{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1604085287728,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "vhdyliqX3u9G"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub7LYZkn3u9N"
   },
   "source": [
    "# Classifying Music Note sounds using Few Shot Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1604085289594,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "AJfQJHZg4fCD",
    "outputId": "f4fc30fc-cca8-4f00-8b06-c68d42734570"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1604085291847,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "nS19oxec3u9N"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45qAhijR3u9T"
   },
   "source": [
    "#### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1604087202357,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "x1YSn5ic3u9U"
   },
   "outputs": [],
   "source": [
    "def fft(f):\n",
    "    Ni = len(f)\n",
    "    Mi = int(Ni / 2)\n",
    "    if Mi <= 2:\n",
    "        return [f[0] + f[1] + f[2] + f[3], \n",
    "               f[0] - 1j*f[1] - f[2] + 1j*f[3],\n",
    "               f[0] - f[1] + f[2] - f[3],\n",
    "               f[0] + 1j*f[1] - f[2] - 1j*f[3]]\n",
    "    \n",
    "    wn = math.cos(2*math.pi/Ni) - 1j*math.sin(2*math.pi/Ni)\n",
    "    fe = [f[i] for i in range(Ni) if i % 2 == 0]\n",
    "    fo = [f[i] for i in range(Ni) if i % 2 == 1]\n",
    "    Fe = fft(fe)\n",
    "    Fo = fft(fo)\n",
    "    return [np.around(Fe[i] + (wn**i)*Fo[i], decimals=10) for i in range(Mi)] + [np.around(Fe[i] - (wn**i)*Fo[i], decimals=10) for i in range(Mi)]\n",
    "\n",
    "def get_audio_data(filename):\n",
    "    fs = 2**12 # sample rate\n",
    "    tp = 2 # sampling duration\n",
    "    N = n = fs*tp # number of samples\n",
    "    \n",
    "    # Extract data and sampling rate from file\n",
    "    recording, fs = librosa.load(filename, sr=fs, duration=tp, mono=True)\n",
    "\n",
    "    n = len(recording)        \n",
    "    tp = int(n / fs)\n",
    "\n",
    "    if tp < 2:\n",
    "        pad_width = N - recording.shape[0]\n",
    "        recording = np.pad(recording, pad_width=((0, pad_width),), mode='constant')\n",
    "\n",
    "        n = len(recording)\n",
    "        tp = int(n / fs)\n",
    "\n",
    "    N = fs*tp # number of samples\n",
    "    x = [np.round(float(recording[i]), 10) for i in range(n)] # input sequence\n",
    "    return x, tp, n\n",
    "\n",
    "def get_frequency_amplitude(x, tp, N):\n",
    "    _X = fft(x) # discrete Fourier transform\n",
    "    X = [np.round(Xi/N, 10) for Xi in _X] # frequency spectrum\n",
    "    X_amp = [np.absolute(Xi) for Xi in X] # amplitude spectrum\n",
    "\n",
    "    M = int(N/2)\n",
    "    ti = [i*tp/N for i in range(N)]\n",
    "    fi = [i/tp for i in range(M)]\n",
    "    X_amp = np.array(X_amp[:M])*2\n",
    "    \n",
    "    return ti, fi, X_amp\n",
    "\n",
    "def extract_features(filepath):\n",
    "    # try:\n",
    "    audio_features = get_audio_data(filepath)\n",
    "    if not audio_features:\n",
    "        return\n",
    "\n",
    "    x, tp, N = audio_features\n",
    "    ti, fi, X_amp = get_frequency_amplitude(x, tp, N)\n",
    "    return X_amp\n",
    "#     return fi, X_amp\n",
    "    \n",
    "    # except Exception as e:\n",
    "    #     print(\"Error encountered while parsing file: \", file_name, e)\n",
    "    #     return None \n",
    "    \n",
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=3) \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    pad_width = 256 - mfccs.shape[1]\n",
    "    \n",
    "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')     \n",
    "    return mfccs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ6ISFg-3u9Y"
   },
   "source": [
    "#### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406,
     "referenced_widgets": [
      "e46f85e99e09488bae8eb6d70666e4ef",
      "02fa5eedbf8c403c94e45735e8e2072e",
      "cc12aa92344d4fd885d91aafeda3da2a",
      "32033641990b41f0bbee1cb4eb29f795",
      "8b729491eac44963bc4949b2d3ffda1a",
      "0fb775d8199642539df1f477850b9bb8",
      "01870c47bcd4473ea6d4a75a5671983c",
      "ab984203a3b64540aaf15530cd751c56"
     ]
    },
    "executionInfo": {
     "elapsed": 907,
     "status": "error",
     "timestamp": 1604087204042,
     "user": {
      "displayName": "Abdulfatah Adeneye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwwTkgOMGbA-QRk6klobTr8Aqxlub_7jKWXCJLvA=s64",
      "userId": "17752013653843449263"
     },
     "user_tz": -60
    },
    "id": "wR58CuvV3u9Y",
    "outputId": "8874ee84-9086-4b8c-9028-ddf902d6d4bc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd50293609ac496f86d5c294be5c707d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished feature extraction from  118  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "DATA_DIR = os.path.join(\"data\", \"guitar_sample\")\n",
    "# DATA_DIR = os.path.join(\"/content/drive/My Drive/Colab Notebooks/data\", \"guitar_sample\")\n",
    "\n",
    "# feature list\n",
    "features = []\n",
    "labels = os.listdir(DATA_DIR)\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for folder in tqdm(labels):\n",
    "    class_label = folder\n",
    "    if class_label.startswith(\"0\"):\n",
    "        continue\n",
    "        \n",
    "    for file in os.listdir(os.path.join(DATA_DIR, folder)):\n",
    "        file_name = os.path.join(os.path.join(DATA_DIR, folder, file))\n",
    "        \n",
    "        data = extract_features(file_name)\n",
    "        if data is None:\n",
    "            continue\n",
    "        \n",
    "        data = np.array(data)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "labels = np.unique(featuresdf.class_label)\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# featuresdf.feature = featuresdf.feature.apply(lambda xx: xx.reshape((4096, 2)))\n",
    "featuresdf.feature.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "phknq-qI3u9d",
    "outputId": "7742269a-54bf-43d4-afe4-c53ea9737531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[-403.97342], [-427.74152], [-478.33362], [-...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-449.60074], [-470.32797], [-528.5974], [-5...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-374.77917], [-398.41254], [-462.8929], [-4...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-400.76926], [-423.18558], [-481.08386], [-...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-391.5319], [-416.02634], [-477.748], [-511...</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature class_label\n",
       "0  [[[-403.97342], [-427.74152], [-478.33362], [-...          1A\n",
       "1  [[[-449.60074], [-470.32797], [-528.5974], [-5...          1A\n",
       "2  [[[-374.77917], [-398.41254], [-462.8929], [-4...          1A\n",
       "3  [[[-400.76926], [-423.18558], [-481.08386], [-...          1A\n",
       "4  [[[-391.5319], [-416.02634], [-477.748], [-511...          1A"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HqmrjFhq3u9i"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from math import factorial\n",
    "\n",
    "def number_of_combinations(n, r):\n",
    "    return int(factorial(n) / (factorial(n - r) * factorial(r)))\n",
    "\n",
    "def prepare_data_pair(X, y, labels):\n",
    "    data = [[], [], []]\n",
    "    data_labels = [[], [], []]\n",
    "    \n",
    "    for label in labels:\n",
    "        label = f\"1{label}\"\n",
    "        semilabel = f\"0{label}\"\n",
    "\n",
    "        indices = np.array(list(range(len(y))))\n",
    "        similar_indices = indices[y == label]\n",
    "        \n",
    "        if len(similar_indices) < 2:\n",
    "            continue\n",
    "        \n",
    "        train_half_size = number_of_combinations(len(similar_indices), 2)\n",
    "        semisimilar_indices = indices[y == semilabel][:train_half_size]\n",
    "\n",
    "        dissimilar_indices = indices[(y != label) & (y != semilabel)]\n",
    "        np.random.shuffle(dissimilar_indices)\n",
    "\n",
    "        dissimilar_indices = dissimilar_indices[:train_half_size - len(semisimilar_indices)]\n",
    "        dissimilar_indices = np.concatenate([semisimilar_indices, dissimilar_indices])\n",
    "\n",
    "        np.random.shuffle(dissimilar_indices)\n",
    "        it = iter(dissimilar_indices)\n",
    "        \n",
    "        counter = 0\n",
    "        for i, j in combinations(similar_indices, 2):\n",
    "            if counter >= len(dissimilar_indices):\n",
    "                break\n",
    "                \n",
    "            counter += 1\n",
    "            z = next(it)\n",
    "            \n",
    "            for index, value in enumerate([i, j, z]):\n",
    "                data[index].append(X[value])\n",
    "                data_labels[index].append(y[value])\n",
    "            \n",
    "        print(y[i], y[j], y[z])\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data_labels = np.array(data_labels)\n",
    "    return data, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qq7qH_Eh3u9m",
    "outputId": "02734d1c-465a-479e-f383-503415d5f3b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1A', '1B', '1D', '1EH', '1EL', '1G'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T9FB6PBB3u9r",
    "outputId": "1759fa47-1cd9-4bad-fe2b-af5260cd2465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1EH 1EH 1G\n",
      "1D 1D 1EH\n",
      "1A 1A 1EH\n",
      "1B 1B 1G\n",
      "1G 1G 1A\n",
      "1EL 1EL 1G\n"
     ]
    }
   ],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "input_data = np.array(featuresdf.feature.tolist())\n",
    "output_labels = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split train and test data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=100)\n",
    "for train_index, test_index in sss.split(input_data, output_label):\n",
    "    x_train, x_test = input_data[train_index], input_data[test_index]\n",
    "    y_train_label, y_test_label = output_label[train_index], output_label[test_index]\n",
    "    \n",
    "# labels\n",
    "labels = [\"EH\", \"D\", \"A\", \"B\", \"G\", \"EL\"]\n",
    "\n",
    "# prepare data set pairs\n",
    "x_train_pair, y_train_pair = prepare_data_pair(x_train, y_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lJv29W0y3u91",
    "outputId": "192dd052-b77e-42c0-a50b-74d4e264f5d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 40, 256, 1), (94,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ri3TLncR3u94",
    "outputId": "90a6c723-2e0f-4a17-e348-8f5f5703b7a9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24, 40, 256, 1), (24,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 470, 40, 256, 1), (3, 470))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pair.shape, y_train_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PhF_lk3g3u98",
    "outputId": "fbdeeee8-c0b5-416e-db4b-e8e687e4aa76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1EH' '1EH' '1EL']\n",
      "['1EH' '1EH' '1G']\n",
      "['1EH' '1EH' '1A']\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(y_train_pair[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtEvp-x53u9_"
   },
   "source": [
    "### Convolutional Neural Network (CNN) model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "J98TupvE3u-A"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Lambda, LayerNormalization, Layer\n",
    "from tensorflow.keras.layers import BatchNormalization as LayerNormalization, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Conv2D as Conv1D, MaxPooling2D as MaxPooling1D\n",
    "K.clear_session()\n",
    "\n",
    "def build_base_network(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "#     model.add(LayerNormalization(axis=2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(16, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(8, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "# #     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(1024))\n",
    "#     model.add(LayerNormalization(axis=-1))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(LayerNormalization(axis=-1))\n",
    "    model.add(Dropout(0.15))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "#     model.add(LayerNormalization(axis=1))\n",
    "    model.add(Dropout(0.05))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    return model\n",
    "\n",
    "def build_base_network2(input_dim):\n",
    "    # We only test DenseNet-121 in this script for demo purpose\n",
    "    \n",
    "    base_model = tf.keras.applications.DenseNet201(\n",
    "    # base_network = tf.keras.applications.InceptionV3(\n",
    "    # base_network = tf.keras.applications.ResNet101(\n",
    "        include_top=False, weights=None, input_tensor=None, input_shape=input_dim,\n",
    "        pooling=\"max\", classes=128\n",
    "    )\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(128)(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "    \n",
    "def distance(emb1, emb2):\n",
    "    return K.sum(K.square(emb1 - emb2), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSgJQc8F3u-F"
   },
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the same three parameters as the previous model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "niWxBn6e3u-F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from model import create_model as build_base_network\n",
    "\n",
    "input_dim = x_train_pair.shape[2:]\n",
    "base_network = build_base_network(input_dim)\n",
    "\n",
    "audio_a = Input(shape=input_dim)\n",
    "audio_p = Input(shape=input_dim)\n",
    "audio_n = Input(shape=input_dim)\n",
    "\n",
    "feat_vecs_a = base_network(audio_a)\n",
    "feat_vecs_p = base_network(audio_p)\n",
    "feat_vecs_n = base_network(audio_n)\n",
    "\n",
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(TripletLossLayer, self).get_config()\n",
    "        config.update({\"alpha\": self.alpha})\n",
    "        return config\n",
    "\n",
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "difference = TripletLossLayer(alpha=0.2, name='triplet_loss_layer')([feat_vecs_a, feat_vecs_p, feat_vecs_n])\n",
    "\n",
    "# initialize the network\n",
    "model = Model(inputs=[audio_a, audio_p, audio_n], outputs=difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 256, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "qgqWP5213u-J",
    "outputId": "130f9fc4-709a-4eb8-8541-8d69ce2f095c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 40, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 40, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 40, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 128)          541528      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "triplet_loss_layer (TripletLoss ()                   0           sequential_2[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 541,528\n",
      "Trainable params: 540,504\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "pgCkA14N3u-M",
    "outputId": "1d2a63ea-3861-449a-f882-8966d8b53e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 38, 254, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 19, 127, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 19, 127, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 17, 125, 16)       4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 62, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 62, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 60, 8)          1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 30, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3, 30, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               369152    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 541,528\n",
      "Trainable params: 540,504\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[3].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixLSgTDl3u-P"
   },
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. As training a CNN can take a sigificant amount of time, we will start with a low number of epochs and a low batch size. If we can see from the output that the model is converging, we will increase both numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "rvVo5MbA3u-Q",
    "outputId": "cb3f5a7c-c9cc-4dba-847d-999509bfb5f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 484.3480\n",
      "Epoch 00001: val_loss improved from inf to 103.95722, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "11/11 [==============================] - 9s 796ms/step - loss: 484.3480 - val_loss: 103.9572\n",
      "Epoch 2/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 167.0072\n",
      "Epoch 00002: val_loss improved from 103.95722 to 93.91332, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "11/11 [==============================] - 8s 737ms/step - loss: 167.0072 - val_loss: 93.9133\n",
      "Epoch 3/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 105.8282\n",
      "Epoch 00003: val_loss improved from 93.91332 to 35.07957, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "11/11 [==============================] - 8s 721ms/step - loss: 105.8282 - val_loss: 35.0796\n",
      "Epoch 4/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 17.2586\n",
      "Epoch 00004: val_loss improved from 35.07957 to 12.67769, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "11/11 [==============================] - 9s 857ms/step - loss: 17.2586 - val_loss: 12.6777\n",
      "Epoch 5/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 18.7240\n",
      "Epoch 00005: val_loss did not improve from 12.67769\n",
      "11/11 [==============================] - 10s 872ms/step - loss: 18.7240 - val_loss: 131.0968\n",
      "Epoch 6/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 10.7017   \n",
      "Epoch 00006: val_loss did not improve from 12.67769\n",
      "11/11 [==============================] - 11s 1s/step - loss: 10.7017 - val_loss: 117.3534\n",
      "Epoch 7/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 24.9953\n",
      "Epoch 00007: val_loss did not improve from 12.67769\n",
      "11/11 [==============================] - 11s 977ms/step - loss: 24.9953 - val_loss: 19.3523\n",
      "Epoch 8/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 13.1222\n",
      "Epoch 00008: val_loss improved from 12.67769 to 0.00000, saving model to saved_models\\weights.best.basic_cnn.hdf5\n",
      "11/11 [==============================] - 13s 1s/step - loss: 13.1222 - val_loss: 0.0000e+00\n",
      "Epoch 9/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 69.8811\n",
      "Epoch 00009: val_loss did not improve from 0.00000\n",
      "11/11 [==============================] - 9s 863ms/step - loss: 69.8811 - val_loss: 11.6701\n",
      "Epoch 10/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 117.9556\n",
      "Epoch 00010: val_loss did not improve from 0.00000\n",
      "11/11 [==============================] - 12s 1s/step - loss: 117.9556 - val_loss: 17.8480\n",
      "Epoch 11/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.3432\n",
      "Epoch 00011: val_loss did not improve from 0.00000\n",
      "11/11 [==============================] - 10s 917ms/step - loss: 2.3432 - val_loss: 22.2043\n",
      "Epoch 12/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 5.5540\n",
      "Epoch 00012: val_loss did not improve from 0.00000\n",
      "11/11 [==============================] - 10s 912ms/step - loss: 5.5540 - val_loss: 0.0000e+00\n",
      "Epoch 13/16\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.5564\n",
      "Epoch 00013: val_loss did not improve from 0.00000\n",
      "11/11 [==============================] - 12s 1s/step - loss: 1.5564 - val_loss: 0.0000e+00\n",
      "Training completed in time:  2.4164001901944476 min\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from time import time\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# initialize training params\n",
    "epochs = 16\n",
    "batch_size = 32\n",
    "\n",
    "# optimizer = Adam()\n",
    "optimizer = RMSprop()\n",
    "model.compile(loss=None, optimizer=optimizer)\n",
    "\n",
    "start = time()\n",
    "model.fit(\n",
    "    [x_train_pair[0], x_train_pair[1], x_train_pair[2]], \n",
    "    None, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=0.25,\n",
    "    callbacks=[early_stopper, checkpointer], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "duration = (time() - start)/60\n",
    "print(\"Training completed in time: \", duration, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model.load_weights(\"saved_models/weights.best.basic_cnn.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-n0tMCh3u-Y"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6GmeWNQ3u-Y"
   },
   "source": [
    "### Best freq treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "yjOou5Gu3u-a",
    "outputId": "12f7cdf8-da93-4502-8187-8949147d0f20"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def get_eval_params(data_input, data_labels):\n",
    "    pairs = []\n",
    "    distances = [] # squared L2 distance between pairs\n",
    "    identical = [] # 1 if same identity, 0 otherwise\n",
    "\n",
    "    num = len(data_input)\n",
    "    embedded = model.layers[3].predict(data_input)\n",
    "\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            pairs.append([embedded[i], embedded[j]])\n",
    "            distances.append(distance(embedded[i], embedded[j]))\n",
    "            identical.append(1 if data_labels[i] == data_labels[j] else 0)\n",
    "            \n",
    "    pairs = np.array(pairs)\n",
    "    distances = np.array(distances)\n",
    "    identical = np.array(identical)\n",
    "    \n",
    "    return pairs, distances, identical, embedded\n",
    "\n",
    "train_pairs, train_distances, train_identical, train_embedded = get_eval_params(x_train, y_train)\n",
    "test_pairs, test_distances, test_identical, test_embedded = get_eval_params(x_test, y_test)\n",
    "\n",
    "min_threshold = min(train_distances)\n",
    "max_threshold = max(train_distances)\n",
    "threshold_step = (max_threshold - min_threshold)/1000\n",
    "thresholds = np.arange(min_threshold, max_threshold, threshold_step)\n",
    "\n",
    "f1_scores = [f1_score(train_identical, train_distances < t) for t in thresholds]\n",
    "acc_scores = [accuracy_score(train_identical, train_distances < t) for t in thresholds]\n",
    "\n",
    "# max f1\n",
    "opt_idx = np.argmax(f1_scores)\n",
    "opt_f1 = np.max(f1_scores)\n",
    "\n",
    "# Threshold at maximal F1 score\n",
    "opt_tau = thresholds[opt_idx]\n",
    "\n",
    "# Accuracy at maximal F1 score\n",
    "opt_acc = accuracy_score(train_identical, train_distances < opt_tau)\n",
    "\n",
    "# Plot F1 score and accuracy as function of distance threshold\n",
    "plt.plot(thresholds, f1_scores, label='F1 score');\n",
    "plt.plot(thresholds, acc_scores, label='Accuracy');\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title(f'Max: Acc={opt_acc:.2f}, f1={opt_f1:.2f} at threshold {opt_tau:.8f}');\n",
    "plt.xlabel('Distance threshold')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8836,), (8836, 2, 128), (8836,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distances.shape, train_pairs.shape, train_identical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "rGOEbCnt3u-k",
    "outputId": "fceebb3f-0dff-4f2e-9872-3be7e228020f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9444444444444444\n",
      "\n",
      "classification_report\n",
      "========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       468\n",
      "           1       0.79      0.96      0.87       108\n",
      "\n",
      "    accuracy                           0.94       576\n",
      "   macro avg       0.89      0.95      0.92       576\n",
      "weighted avg       0.95      0.94      0.95       576\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "========================\n",
      "[[440  28]\n",
      " [  4 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "prediction = test_distances < opt_tau\n",
    "\n",
    "print(\"accuracy =\", accuracy_score(test_identical, prediction))\n",
    "\n",
    "print(\"\\nclassification_report\")\n",
    "print(\"========================\")\n",
    "print(classification_report(test_identical, prediction))\n",
    "\n",
    "print(\"\\nconfusion matrix\")\n",
    "print(\"========================\")\n",
    "print(confusion_matrix(test_identical, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOMgyhXR3u-j"
   },
   "source": [
    "### Testing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1A', '1B', '1D', '1EH', '1EL', '1G'], dtype='<U3')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy = 0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "using_distance = True\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", gamma='auto'))\n",
    "# clf = make_pipeline(StandardScaler(), LogisticRegression(multi_class=\"ovr\", random_state=0, max_iter=128))\n",
    "\n",
    "if using_distance:\n",
    "    xx_train, yy_train = train_distances.reshape(-1, 1), train_identical\n",
    "    xx_test, yy_test = test_distances.reshape(-1, 1), test_identical\n",
    "\n",
    "else:\n",
    "    xx_train, yy_train = train_embedded, y_train_le\n",
    "    xx_test, yy_test = test_embedded, y_test_le\n",
    "\n",
    "clf.fit(xx_train, yy_train)\n",
    "print(f\"training accuracy = {clf.score(xx_train, yy_train):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8836, 1), (8836,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_train.shape, yy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if using_distance:\n",
    "    plt.scatter(xx_train, yy_train, c=yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.94\n"
     ]
    }
   ],
   "source": [
    "print(f\"test accuracy = {clf.score(xx_test, yy_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[436,  32],\n",
       "       [  4, 104]], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(xx_test)\n",
    "confusion_matrix(yy_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([0, 1]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yy_test), np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       468\n",
      "           1       0.76      0.96      0.85       108\n",
      "\n",
      "    accuracy                           0.94       576\n",
      "   macro avg       0.88      0.95      0.91       576\n",
      "weighted avg       0.95      0.94      0.94       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yy_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCuryhb33u-n"
   },
   "source": [
    "### Testing (new data) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c94e6799d5b405fac37dca88b039617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH, D, A, B, G, EL, \n",
      "\n",
      "(58, 40, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_sample = []\n",
    "y_test_sample = []\n",
    "\n",
    "sample_dirs = [\"EH\", \"D\", \"A\", \"B\", \"G\", \"EL\"]\n",
    "# sample_dirs = [\"A\"]\n",
    "\n",
    "for label in tqdm(sample_dirs):\n",
    "    print(label, end=\", \")\n",
    "    labeldir= os.path.join(\"data\", \"old_guitar_sample\", label)\n",
    "\n",
    "    for filename in (os.listdir(labeldir)):\n",
    "        anchor_filepath = os.path.join(\"data\", \"old_guitar_sample\", label, filename)\n",
    "        \n",
    "        anchor_file_vector = extract_features(anchor_filepath)\n",
    "        anchor_file_vector = np.expand_dims(anchor_file_vector, axis=-1)\n",
    "        x_test_sample.append(anchor_file_vector)\n",
    "        y_test_sample.append(\"1\"+label)\n",
    "\n",
    "print()\n",
    "x_test_sample = np.array(x_test_sample)\n",
    "y_test_sample = np.array(y_test_sample)\n",
    "\n",
    "print(x_test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "-Y3kHXH-3u-s",
    "outputId": "cb6b75a1-0c58-458b-e4a8-e90a6739e5a3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 40, 256, 1)\n",
      "accuracy = 0.8632580261593341\n",
      "\n",
      "classification_report\n",
      "========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      2802\n",
      "           1       0.55      0.94      0.70       562\n",
      "\n",
      "    accuracy                           0.86      3364\n",
      "   macro avg       0.77      0.89      0.80      3364\n",
      "weighted avg       0.91      0.86      0.88      3364\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "========================\n",
      "[[2378  424]\n",
      " [  36  526]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "prediction = []\n",
    "\n",
    "num = len(x_test_sample)\n",
    "print(x_test_sample.shape)\n",
    "embedded = model.layers[3].predict(x_test_sample)\n",
    "\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        distances.append(distance(embedded[i], embedded[j]))\n",
    "        identical.append(1 if y_test_sample[i] == y_test_sample[j] else 0)\n",
    "        prediction.append(1 if distances[-1] < opt_tau else 0)\n",
    "        \n",
    "distances = np.array(distances)\n",
    "identical = np.array(identical)\n",
    "prediction = np.array(prediction)\n",
    "\n",
    "print(\"accuracy =\", accuracy_score(identical, prediction))\n",
    "\n",
    "print(\"\\nclassification_report\")\n",
    "print(\"========================\")\n",
    "print(classification_report(identical, prediction))\n",
    "\n",
    "print(\"\\nconfusion matrix\")\n",
    "print(\"========================\")\n",
    "print(confusion_matrix(identical, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_distance:\n",
    "    x_test_sample, y_test_sample = distances.reshape(-1, 1), identical\n",
    "\n",
    "else:\n",
    "    x_test_sample, y_test_sample = embedded, le.transform(y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.86\n"
     ]
    }
   ],
   "source": [
    "print(f\"test accuracy = {clf.score(x_test_sample, y_test_sample):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2360,  442],\n",
       "       [  36,  526]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(x_test_sample)\n",
    "confusion_matrix(y_test_sample, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      2802\n",
      "           1       0.54      0.94      0.69       562\n",
      "\n",
      "    accuracy                           0.86      3364\n",
      "   macro avg       0.76      0.89      0.80      3364\n",
      "weighted avg       0.91      0.86      0.87      3364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_sample, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LuC2AcO3u-w"
   },
   "source": [
    "### Testing (sample) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "5AMEATl53u-w",
    "outputId": "cff24703-b5d2-46a0-95cd-2a17eaef1bd0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd20e9a744d444aabcd3452dc9d91ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1EH, 1D, 1A, 1B, 1G, 1EL, \n",
      "\n",
      "(118, 40, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_sample = []\n",
    "y_test_sample = []\n",
    "\n",
    "sample_dirs = [\"1EH\", \"1D\", \"1A\", \"1B\", \"1G\", \"1EL\"]\n",
    "\n",
    "sample_label = \"1A\"\n",
    "sample_filepath = os.path.join(\"data\", \"sampleA.wav\")\n",
    "sample_vector = extract_features(sample_filepath)\n",
    "sample_vector = np.expand_dims(np.expand_dims(sample_vector, axis=-1), axis=0)\n",
    "sample_embedded = model.layers[3].predict(sample_vector)\n",
    "\n",
    "for label in tqdm(sample_dirs):\n",
    "    print(label, end=\", \")\n",
    "    labeldir= os.path.join(DATA_DIR, label)\n",
    "\n",
    "    for filename in (os.listdir(labeldir)):\n",
    "        anchor_filepath = os.path.join(DATA_DIR, label, filename)\n",
    "        \n",
    "        anchor_file_vector = extract_features(anchor_filepath)\n",
    "        anchor_file_vector = np.expand_dims(anchor_file_vector, axis=-1)\n",
    "        x_test_sample.append(anchor_file_vector)\n",
    "        y_test_sample.append(label)\n",
    "\n",
    "print()\n",
    "x_test_sample = np.array(x_test_sample)\n",
    "y_test_sample = np.array(y_test_sample)\n",
    "\n",
    "print(x_test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "M4omNHOQ3u-1",
    "outputId": "f640715d-b1e0-4685-ee26-4064bdcdcc74",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.711864406779661\n",
      "\n",
      "classification_report\n",
      "========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83        98\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.71       118\n",
      "   macro avg       0.40      0.43      0.42       118\n",
      "weighted avg       0.67      0.71      0.69       118\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "========================\n",
      "[[84 14]\n",
      " [20  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "identical = []\n",
    "distances = [] # squared L2 distance between pairs\n",
    "prediction = []\n",
    "\n",
    "num = len(x_test_sample)\n",
    "embedded = model.layers[3].predict(x_test_sample)\n",
    "\n",
    "for i in range(num):\n",
    "    identical.append(1 if sample_label == y_test_sample[i] else 0)\n",
    "    distances.append(distance(embedded[i], sample_embedded))\n",
    "    prediction.append(1 if distances[-1] < opt_tau else 0)\n",
    "\n",
    "identical = np.array(identical)\n",
    "distances = np.array(distances)\n",
    "prediction = np.array(prediction)\n",
    "\n",
    "print(\"accuracy =\", accuracy_score(identical, prediction))\n",
    "\n",
    "print(\"\\nclassification_report\")\n",
    "print(\"========================\")\n",
    "print(classification_report(identical, prediction))\n",
    "\n",
    "print(\"\\nconfusion matrix\")\n",
    "print(\"========================\")\n",
    "print(confusion_matrix(identical, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_distance:\n",
    "    x_test_sample, y_test_sample = distances.reshape(-1, 1), identical\n",
    "\n",
    "else:\n",
    "    x_test_sample, y_test_sample = sample_embedded, le.transform([sample_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.70\n"
     ]
    }
   ],
   "source": [
    "print(f\"test accuracy = {clf.score(x_test_sample, y_test_sample):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 15],\n",
       "       [20,  0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(x_test_sample)\n",
    "confusion_matrix(y_test_sample, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        98\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.70       118\n",
      "   macro avg       0.40      0.42      0.41       118\n",
      "weighted avg       0.67      0.70      0.69       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_sample, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JzbHvLB3u--"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Triplet Siamese Network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01870c47bcd4473ea6d4a75a5671983c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02fa5eedbf8c403c94e45735e8e2072e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fb775d8199642539df1f477850b9bb8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32033641990b41f0bbee1cb4eb29f795": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab984203a3b64540aaf15530cd751c56",
      "placeholder": "",
      "style": "IPY_MODEL_01870c47bcd4473ea6d4a75a5671983c",
      "value": " 0/12 [00:00&lt;?, ?it/s]"
     }
    },
    "8b729491eac44963bc4949b2d3ffda1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab984203a3b64540aaf15530cd751c56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc12aa92344d4fd885d91aafeda3da2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fb775d8199642539df1f477850b9bb8",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b729491eac44963bc4949b2d3ffda1a",
      "value": 0
     }
    },
    "e46f85e99e09488bae8eb6d70666e4ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc12aa92344d4fd885d91aafeda3da2a",
       "IPY_MODEL_32033641990b41f0bbee1cb4eb29f795"
      ],
      "layout": "IPY_MODEL_02fa5eedbf8c403c94e45735e8e2072e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
