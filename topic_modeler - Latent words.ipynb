{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + (np.e**-x))\n",
    "                \n",
    "def clean_documents(docs):\n",
    "    def clean_doc(doc):\n",
    "        ''' remove unwanter characters line new line '''\n",
    "\n",
    "        unwanted_chrs = [')', '(', '{', '}', '\\t', '\\n', '\\r', \"'\", '\"', \"!\"]\n",
    "        for unwanted_chr in unwanted_chrs:\n",
    "            doc = doc.replace(unwanted_chr, ' ')\n",
    "\n",
    "        return doc.strip()\n",
    "    \n",
    "    return [clean_doc(doc) for doc in docs]\n",
    "\n",
    "def build_topic_word_distr(topics, word_topic_cos, words, topic_word_window_width, word_doc_frequency):\n",
    "    topic_word_distr = pd.DataFrame(data=0.0, columns=topics, index=words)\n",
    "\n",
    "    for topic in tqdm(range(len(topics))):\n",
    "        word_topic_co = word_topic_cos[topic]\n",
    "        word_word_co = pd.DataFrame(data=0.0, columns=word_topic_co[:topic_word_window_width].index, index=words)\n",
    "\n",
    "        for index, (top_word, corelation) in enumerate(word_topic_co.items()):\n",
    "            if index == topic_word_window_width:\n",
    "                break\n",
    "\n",
    "            word_word_frequency = corelation * word_doc_binary_freqency[word_doc_binary_freqency[top_word] > 0].sum(0)\n",
    "            trust_factor = sigmoid(word_doc_frequency)\n",
    "\n",
    "            word_word_co[top_word] = (word_word_frequency * trust_factor) / word_doc_frequency\n",
    "        topic_word_distr[topics[topic]] = word_word_co.max(1)\n",
    "    return topic_word_distr\n",
    "\n",
    "def infer_topic(topics, doc_vector, topic_word_distr):\n",
    "    doc_topic_word_distr = topic_word_distr.copy()\n",
    "    doc_word_freq_norm = (doc_vector > 0).astype(int)\n",
    "#     doc_word_freq_norm = doc_vector / doc_vector.sum() if doc_vector.sum() else 0\n",
    "\n",
    "    for topic in topics:\n",
    "        doc_topic_word_distr[topic] *= doc_word_freq_norm\n",
    "    \n",
    "    return doc_topic_word_distr, np.max(doc_topic_word_distr).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "datasize = 3000\n",
    "\n",
    "# retrieve dataset\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=False, remove=('headers', 'footers', 'quotes'))\n",
    "docs, old_labels, classes = docs.data[:datasize], docs.target[:datasize], docs.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual labels as np array\n",
    "old_labels = np.array(old_labels)\n",
    "labels = np.zeros(old_labels.shape, dtype=int)\n",
    "\n",
    "# the new classes\n",
    "label_classes = list(set([x.split('.')[0] for x in classes]))\n",
    "\n",
    "# restructuring classes  from 19 to less\n",
    "for label, cl in enumerate(classes):\n",
    "    labels[old_labels == label] = label_classes.index(cl.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3000 docs and 7 classes: ['comp', 'talk', 'sci', 'soc', 'alt', 'rec', 'misc']\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(docs)} docs and {len(label_classes)} classes: {label_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morgan and guzman will have era s 1 run higher than last year, and  the cubs will be idiots and not pitch harkey as much as hibbard.  castillo won t be good  i think he s a stud pitcher'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean out the new line characters from text in docs\n",
    "clean_docs = clean_documents(docs)\n",
    "clean_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count shape is (1, 37782)\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# count_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "count_vectorizer.fit(clean_docs)\n",
    "\n",
    "# create dataset\n",
    "word_count = pd.DataFrame(count_vectorizer.vocabulary_, index=[0])\n",
    "\n",
    "print(\"word_count shape is\", word_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morgan</th>\n",
       "      <th>and</th>\n",
       "      <th>guzman</th>\n",
       "      <th>will</th>\n",
       "      <th>have</th>\n",
       "      <th>era</th>\n",
       "      <th>run</th>\n",
       "      <th>higher</th>\n",
       "      <th>than</th>\n",
       "      <th>last</th>\n",
       "      <th>...</th>\n",
       "      <th>rationalisations</th>\n",
       "      <th>_predict_</th>\n",
       "      <th>_believe_</th>\n",
       "      <th>disbelievers</th>\n",
       "      <th>_anything_</th>\n",
       "      <th>erasmus</th>\n",
       "      <th>dichotomy</th>\n",
       "      <th>nobodies</th>\n",
       "      <th>somethingness</th>\n",
       "      <th>unknowable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23248</td>\n",
       "      <td>5351</td>\n",
       "      <td>16883</td>\n",
       "      <td>36562</td>\n",
       "      <td>17210</td>\n",
       "      <td>13922</td>\n",
       "      <td>29579</td>\n",
       "      <td>17506</td>\n",
       "      <td>33536</td>\n",
       "      <td>20645</td>\n",
       "      <td>...</td>\n",
       "      <td>28046</td>\n",
       "      <td>4149</td>\n",
       "      <td>4032</td>\n",
       "      <td>12267</td>\n",
       "      <td>4024</td>\n",
       "      <td>13930</td>\n",
       "      <td>12070</td>\n",
       "      <td>24207</td>\n",
       "      <td>31484</td>\n",
       "      <td>35051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   morgan   and  guzman   will   have    era    run  higher   than   last  \\\n",
       "0   23248  5351   16883  36562  17210  13922  29579   17506  33536  20645   \n",
       "\n",
       "   ...  rationalisations  _predict_  _believe_  disbelievers  _anything_  \\\n",
       "0  ...             28046       4149       4032         12267        4024   \n",
       "\n",
       "   erasmus  dichotomy  nobodies  somethingness  unknowable  \n",
       "0    13930      12070     24207          31484       35051  \n",
       "\n",
       "[1 rows x 37782 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 train_docs, 990 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "doc_vectors = count_vectorizer.transform(clean_docs).toarray()\n",
    "\n",
    "train_doc_vectors, test_doc_vectors, train_labels, test_labels = train_test_split(doc_vectors, labels, test_size=.33, random_state=42)\n",
    "print(f\"{len(train_labels)} train_docs, {len(test_labels)} test docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_word_frequency shape is (2010, 37783)\n"
     ]
    }
   ],
   "source": [
    "document_word_frequency = pd.DataFrame(train_doc_vectors, columns=count_vectorizer.get_feature_names())\n",
    "document_word_binary_frequency = (document_word_frequency > 0).astype('int')\n",
    "\n",
    "document_word_frequency[\"__labels__\"] = train_labels\n",
    "document_word_binary_frequency[\"__labels__\"] = train_labels\n",
    "\n",
    "print(\"document_word_frequency shape is\", document_word_frequency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3000 docs and 7 classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>00000000b</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00000001b</th>\n",
       "      <th>00000010</th>\n",
       "      <th>00000010b</th>\n",
       "      <th>...</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvb</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx900a</th>\n",
       "      <th>zygot</th>\n",
       "      <th>zymmr</th>\n",
       "      <th>zyxel1496b</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000  00000000  00000000b  00000001  00000001b  00000010  \\\n",
       "0   0    0     0      0         0          0         0          0         0   \n",
       "1   0    0     0      0         0          0         0          0         0   \n",
       "2   0    0     0      0         0          0         0          0         0   \n",
       "3   0    0     0      0         0          0         0          0         0   \n",
       "4   0    0     0      0         0          0         0          0         0   \n",
       "\n",
       "   00000010b  ...  zurich  zvb  zx  zx900a  zygot  zymmr  zyxel1496b  zzz  \\\n",
       "0          0  ...       0    0   0       0      0      0           0    0   \n",
       "1          0  ...       0    0   0       0      0      0           0    0   \n",
       "2          0  ...       0    0   0       0      0      0           0    0   \n",
       "3          0  ...       0    0   0       0      0      0           0    0   \n",
       "4          0  ...       0    0   0       0      0      0           0    0   \n",
       "\n",
       "   zzzzzz  __labels__  \n",
       "0       0           2  \n",
       "1       0           5  \n",
       "2       0           2  \n",
       "3       0           4  \n",
       "4       0           5  \n",
       "\n",
       "[5 rows x 37783 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>00000000b</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00000001b</th>\n",
       "      <th>00000010</th>\n",
       "      <th>00000010b</th>\n",
       "      <th>...</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvb</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx900a</th>\n",
       "      <th>zygot</th>\n",
       "      <th>zymmr</th>\n",
       "      <th>zyxel1496b</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000  00000000  00000000b  00000001  00000001b  00000010  \\\n",
       "0   0    0     0      0         0          0         0          0         0   \n",
       "1   0    0     0      0         0          0         0          0         0   \n",
       "2   0    0     0      0         0          0         0          0         0   \n",
       "3   0    0     0      0         0          0         0          0         0   \n",
       "4   0    0     0      0         0          0         0          0         0   \n",
       "\n",
       "   00000010b  ...  zurich  zvb  zx  zx900a  zygot  zymmr  zyxel1496b  zzz  \\\n",
       "0          0  ...       0    0   0       0      0      0           0    0   \n",
       "1          0  ...       0    0   0       0      0      0           0    0   \n",
       "2          0  ...       0    0   0       0      0      0           0    0   \n",
       "3          0  ...       0    0   0       0      0      0           0    0   \n",
       "4          0  ...       0    0   0       0      0      0           0    0   \n",
       "\n",
       "   zzzzzz  __labels__  \n",
       "0       0           2  \n",
       "1       0           5  \n",
       "2       0           2  \n",
       "3       0           4  \n",
       "4       0           5  \n",
       "\n",
       "[5 rows x 37783 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_binary_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cherry pick dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trim the data to words that spread round the corpus\n",
    "\n",
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_binary_freqency = document_word_binary_frequency.drop([\"__labels__\"], axis='columns')\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_frequency = word_doc_binary_freqency.sum(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic and word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 has (6303,) skew words\n",
      "topic 1 has (5995,) skew words\n",
      "topic 2 has (6147,) skew words\n",
      "topic 3 has (1063,) skew words\n",
      "topic 4 has (472,) skew words\n",
      "topic 5 has (3718,) skew words\n",
      "topic 6 has (727,) skew words\n"
     ]
    }
   ],
   "source": [
    "word_topic_cos = []\n",
    "for topic, label in enumerate(label_classes):\n",
    "    word_topic_frequency = word_doc_binary_freqency[document_word_frequency['__labels__'] == topic].sum(0)\n",
    "    trust_factor = sigmoid(word_doc_frequency)\n",
    "    \n",
    "    word_topic_co = (word_topic_frequency * trust_factor) / word_doc_frequency\n",
    "    word_topic_co = word_topic_co[word_topic_co > 0.5].sort_values(ascending=False)\n",
    "    \n",
    "    word_topic_cos.append(word_topic_co)\n",
    "    print(f\"topic {topic} has {word_topic_co.shape} skew words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp', 'talk', 'sci', 'soc', 'alt', 'rec', 'misc']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encryption    1.000000\n",
       "clipper       1.000000\n",
       "nsa           1.000000\n",
       "geb           1.000000\n",
       "pitt          1.000000\n",
       "                ...   \n",
       "food          0.526316\n",
       "institute     0.523810\n",
       "gov           0.520000\n",
       "phone         0.515152\n",
       "expensive     0.515152\n",
       "Length: 6147, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_index = label_classes.index('sci')\n",
    "word_topic_cos[topic_index][word_topic_cos[topic_index] > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a30b0e52b5d461db178d0040ab8f86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7a4f0eb2864630aea665e0bce13210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 100 and window_step 100 accuracy is 71.24%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882da8407294de2a931a436cf9e5716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137cf5f797e2449d8a7dc342fdc7601a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 200 and window_step 100 accuracy is 75.97%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988fba0c664e41ae9dd050394aa469d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6482009ca4af4b6eb4bf4a0e0553f938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 300 and window_step 100 accuracy is 79.40%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3507492bb640259e385fb3b80a4b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183deb177b194d36b90202f0a9561712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 400 and window_step 100 accuracy is 80.60%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e4ace6fb245e1819a0606a0a16753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68c9aff36364835a0feec6a1600b6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 500 and window_step 100 accuracy is 81.99%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3b61162b30431ea6f3556f3d90afd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003e82d9dffd438cb97038879c85a7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 600 and window_step 100 accuracy is 82.89%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbf0efe2e14413f90c6ad35e1c7cf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d804ee90944d4cfb8a200f25a375208f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 700 and window_step 100 accuracy is 83.48%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ac3ca8d50741daa89a77cdef05fa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47794850df6e4d599ad3ea2b727efa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 800 and window_step 100 accuracy is 84.03%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e9507032244739aac358b867df79a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71aafac8c994ee6a3e9f54e79512242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2010.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (37782, 7) from window_size 900 and window_step 100 accuracy is 84.13%\n",
      "\n",
      "accuracy low 0.0009950248756219748\n"
     ]
    }
   ],
   "source": [
    "converged = False\n",
    "last_accuracy = last_max_accuracy = 0\n",
    "window_size = 100\n",
    "window_step = window_base_step = 100\n",
    "decay_factor = 10\n",
    "\n",
    "while not converged:\n",
    "    print(\"Building Topic_word_distr_prime...\")\n",
    "    topic_word_distr_prime = build_topic_word_distr(label_classes, word_topic_cos, word_doc_binary_freqency.columns, window_size, word_doc_frequency)\n",
    "\n",
    "    score = 0\n",
    "    print(\"Evaluating Topic Model...\")\n",
    "    for doc_index in tqdm(range(len(train_labels))):\n",
    "        doc_vector = train_doc_vectors[doc_index]\n",
    "        doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr_prime)\n",
    "        score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "\n",
    "    accuracy = score / (doc_index + 1)\n",
    "    print(f\"==> topic_word_distr_prime has shape {topic_word_distr_prime.shape} from window_size {window_size} and window_step {window_step} accuracy is {accuracy*100:.2f}%\\n\")\n",
    "    \n",
    "    if abs(accuracy - last_max_accuracy) < .001:\n",
    "        print(\"accuracy low\", abs(accuracy - last_max_accuracy))\n",
    "        converged = True\n",
    "        \n",
    "    elif accuracy >= last_max_accuracy:\n",
    "        window_size += window_step\n",
    "        last_max_accuracy = accuracy\n",
    "    \n",
    "    else:\n",
    "        if last_accuracy == last_max_accuracy:\n",
    "            window_size -= window_step\n",
    "            window_step = int(window_step / decay_factor)\n",
    "            \n",
    "            if not window_step:\n",
    "                print(\"window decayed!!\")\n",
    "                converged = False\n",
    "        window_size += window_step\n",
    "        \n",
    "    last_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f649e6699637442c91dd6741278550c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr has shape (37782, 7) from window_size 900 and window_step 100 test-accuracy is 68.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr_prime)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if score:\n",
    "        continue\n",
    "    \n",
    "#     print(clean_docs[len(train_labels)+doc_index])\n",
    "#     print(\"{:8s} {:16s} {:6s}\".format(\"topic\", \"word\", \"relation\"))\n",
    "#     print(\"=\"*40)\n",
    "#     for label, word in doc_topic_word_distr.idxmax().items():\n",
    "#         print(\"{:8s} {:16s} {:.4f}\".format(label, word, doc_topic_word_distr[label][word]))\n",
    "\n",
    "#     print(f\"\\nthe topic predicted is ==> '{np.max(doc_topic_word_distr).idxmax()}'\")\n",
    "#     print(f\"the actual topic is ==> '{label_classes[labels[doc_index]]}'\")\n",
    "\n",
    "accuracy = score / (doc_index + 1)\n",
    "print(f\"==> topic_word_distr has shape {topic_word_distr_prime.shape} from window_size {window_size} and window_step {window_step} test-accuracy is {accuracy*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Topic_word_distr...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f16b0756b34db3a1953207e3bae1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "ws = 1\n",
    "print(\"Building Topic_word_distr...\")\n",
    "\n",
    "topic_word_distr = build_topic_word_distr(label_classes, word_topic_cos, word_doc_binary_freqency.columns, ws, word_doc_frequency)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696ec9b72c98436995c13d88553ce771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr has shape (37782, 7) from window_size 1 and window_step 100 test-accuracy is 40.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "\n",
    "accuracy = score / (doc_index + 1)\n",
    "print(f\"==> topic_word_distr has shape {topic_word_distr.shape} from window_size {ws} and window_step {window_step} test-accuracy is {accuracy*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9746268656716418, 0.7717171717171717)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "Xa, Xb, Ya, Yb = train_test_split(clean_docs, labels, test_size=.33, random_state=42)\n",
    "train_vectors = vectorizer.fit_transform(Xa)\n",
    "test_vectors = vectorizer.transform(Xb)\n",
    "\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_vectors, Ya)\n",
    "\n",
    "clf.score(train_vectors, Ya), clf.score(test_vectors, Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2010, 31192)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 31192)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
