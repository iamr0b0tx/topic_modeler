{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + (np.e**-x))\n",
    "\n",
    "def build_topic_word_distr(topics, word_topic_cos, words, topic_word_window_width, word_doc_frequency):\n",
    "    topic_word_distr = pd.DataFrame(data=0.0, columns=topics, index=words)\n",
    "\n",
    "    for topic in tqdm(range(len(topics))):\n",
    "        word_topic_co = word_topic_cos[topic]\n",
    "        word_word_co = pd.DataFrame(data=0.0, columns=word_topic_co[:topic_word_window_width].index, index=words)\n",
    "\n",
    "        for index, (top_word, corelation) in enumerate(word_topic_co.items()):\n",
    "            if index == topic_word_window_width:\n",
    "                break\n",
    "\n",
    "            word_word_frequency = corelation * word_doc_freqency[word_doc_freqency[top_word] > 0].sum(0)\n",
    "            trust_factor = sigmoid((word_doc_freqency[top_word] > 0).sum(0))\n",
    "\n",
    "            word_word_co[top_word] = (word_word_frequency * trust_factor) / word_doc_frequency\n",
    "        topic_word_distr[topics[topic]] = word_word_co.max(1)\n",
    "    return topic_word_distr\n",
    "\n",
    "def infer_topic(label_classes, doc_vector, topic_word_distr):\n",
    "    doc_topic_word_distr = topic_word_distr.copy()\n",
    "\n",
    "    for label_class in label_classes:\n",
    "        doc_topic_word_distr[label_class] *= doc_vector\n",
    "    \n",
    "    \n",
    "    doc_topic = np.max(doc_topic_word_distr).idxmax()\n",
    "    return doc_topic_word_distr, doc_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "datasize = 300\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "label_classes = ['autos', 'religion', 'graphics', 'space']\n",
    "\n",
    "assert len(label_classes) == len(categories)\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, old_labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean out the new line characters from text in docs\n",
    "def clean_doc(doc):\n",
    "    ''' remove unwanter characters line new line '''\n",
    "\n",
    "    unwanted_chrs = [')', '(', '{', '}', '\\t', '\\n', '\\r', \"'\", '\"', \"!\"]\n",
    "    doc = doc.lower()\n",
    "    for unwanted_chr in unwanted_chrs:\n",
    "        doc = doc.replace(unwanted_chr, ' ')\n",
    "\n",
    "    return doc.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<apparently you re not a woman - my husband hates the auto door locks <feels safer in a car that locks easily  in addition to watching around <in a secluded spot, etc - have my keys ready to open the door so i m\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "clean_docs = []\n",
    "max_document_length = None\n",
    "\n",
    "# the new classes\n",
    "sizes = [0] * len(label_classes)\n",
    "assert len(label_classes) == len(sizes)\n",
    "\n",
    "for index, doc in enumerate(docs):\n",
    "    if len(clean_docs) == datasize*len(label_classes):\n",
    "        break\n",
    "        \n",
    "    cd = clean_doc(doc)\n",
    "    \n",
    "    if len(cd) == 0 or cd.isspace() or (max_document_length is not None and len(cd) <= max_document_length):\n",
    "        continue\n",
    "        \n",
    "    label_class = classes[old_labels[index]]\n",
    "    label = categories.index(label_class)\n",
    "\n",
    "    if sizes[label] < datasize:\n",
    "        clean_docs.append(cd)\n",
    "        labels.append(label)\n",
    "\n",
    "        sizes[label] += 1\n",
    "\n",
    "labels = np.array(labels)\n",
    "print(clean_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1200 docs and 4 classes: ['autos', 'religion', 'graphics', 'space'] of size min:300, max:300\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes: {label_classes} of size min:{min(sizes)}, max:{max(sizes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 17523\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# count_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "train_docs, test_docs, train_labels, test_labels = train_test_split(clean_docs, labels, test_size=.33, random_state=42)\n",
    "count_vectorizer.fit(train_docs)\n",
    "vocabulary = count_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 train_docs, 396 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = count_vectorizer.transform(train_docs).toarray()\n",
    "# train_doc_vectors = (train_doc_vectors > 0).astype(float)\n",
    "train_doc_vectors = normalize(train_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "test_doc_vectors = count_vectorizer.transform(test_docs).toarray()\n",
    "# test_doc_vectors = (test_doc_vectors > 0).astype(float)\n",
    "test_doc_vectors = normalize(test_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "print(f\"{len(train_labels)} train_docs, {len(test_labels)} test docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_word_frequency shape is (804, 17524)\n"
     ]
    }
   ],
   "source": [
    "document_word_frequency = pd.DataFrame(train_doc_vectors, columns=count_vectorizer.get_feature_names())\n",
    "document_word_frequency[\"__labels__\"] = train_labels\n",
    "\n",
    "print(\"document_word_frequency shape is\", document_word_frequency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1200 docs and 4 classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>0001</th>\n",
       "      <th>000100255pixel</th>\n",
       "      <th>00041032</th>\n",
       "      <th>0004136</th>\n",
       "      <th>0004246</th>\n",
       "      <th>0004422</th>\n",
       "      <th>...</th>\n",
       "      <th>zullen</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zurbrin</th>\n",
       "      <th>zurvanism</th>\n",
       "      <th>zwaartepunten</th>\n",
       "      <th>zwak</th>\n",
       "      <th>zwakke</th>\n",
       "      <th>zware</th>\n",
       "      <th>zwarte</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 17524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000  0000  00000  0001  000100255pixel  00041032  0004136  \\\n",
       "0  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "1  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "2  0.000119  0.000596   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "3  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "4  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "\n",
       "   0004246  0004422  ...  zullen  zulu  zurbrin  zurvanism  zwaartepunten  \\\n",
       "0      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "1      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "2      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "3      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "4      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "\n",
       "   zwak  zwakke  zware  zwarte  __labels__  \n",
       "0   0.0     0.0    0.0     0.0           3  \n",
       "1   0.0     0.0    0.0     0.0           0  \n",
       "2   0.0     0.0    0.0     0.0           2  \n",
       "3   0.0     0.0    0.0     0.0           3  \n",
       "4   0.0     0.0    0.0     0.0           1  \n",
       "\n",
       "[5 rows x 17524 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Binary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_freqency = document_word_frequency.drop([\"__labels__\"], axis='columns')\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_total_frequency = word_doc_freqency.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic and word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_word_distr has shape (17523, 4)\n"
     ]
    }
   ],
   "source": [
    "topic_word_distr = pd.DataFrame(data=0.0, columns=label_classes, index=vocabulary)\n",
    "\n",
    "for topic, label in enumerate(label_classes):\n",
    "    word_topic_frequency = word_doc_freqency[document_word_frequency['__labels__'] == topic].sum(0)\n",
    "    trust_factor = sigmoid((word_doc_freqency > 0).sum(0))\n",
    "    \n",
    "    topic_word_distr[label] = ((word_topic_frequency * trust_factor) / word_doc_total_frequency).fillna(0)\n",
    "\n",
    "topic_word_distr = topic_word_distr.T\n",
    "entropy = np.nan_to_num(calculate_entropy(topic_word_distr, base=2))\n",
    "topic_word_distr = (topic_word_distr * (np.e**(-entropy**2))).T\n",
    "print(f\"topic_word_distr has shape {topic_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autos</th>\n",
       "      <th>religion</th>\n",
       "      <th>graphics</th>\n",
       "      <th>space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.021364</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.107895</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.019123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          autos  religion  graphics     space\n",
       "00     0.021364  0.001354  0.102974  0.037267\n",
       "000    0.107895  0.008882  0.020714  0.019123\n",
       "0000   0.000000  0.000000  0.000000  0.880797\n",
       "00000  0.000000  0.000000  0.000000  0.880797\n",
       "0001   0.000000  0.731059  0.000000  0.000000"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autos', 'religion', 'graphics', 'space']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3d             1.000000\n",
       "vga            0.999999\n",
       "animation      0.999998\n",
       "formats        0.999994\n",
       "programming    0.999994\n",
       "                 ...   \n",
       "man            0.000142\n",
       "government     0.000138\n",
       "down           0.000129\n",
       "speak          0.000128\n",
       "stop           0.000116\n",
       "Name: graphics, Length: 6721, dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class = 'graphics'\n",
    "topic_word_distr[label_class][topic_word_distr[label_class] > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphics    0.178895\n",
       "autos       0.043989\n",
       "space       0.031708\n",
       "religion    0.000000\n",
       "Name: computer, dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=\"computer\"\n",
    "topic_word_distr.loc[word].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAc+klEQVR4nO3de5RddYHl8e82gMhDXileIZoMRDG2bdRMxPG9EBbgaHBEhW4RXxPoRQaZFqfT2tqx21F0QNQWyYBmhEZBUBijRgFpH60DmAIjJGAkYpCQkBQgIKBAyJ4/zq/kcL1VdW5VkSKc/VnrrnvO73FeuTn7nt8995ZsExER7fO0id6AiIiYGAmAiIiWSgBERLRUAiAioqUSABERLZUAiIhoqQRAxBYi6YOSvjjR2xExKAEQWy1J0yRZ0jYTvS1N2P647feOZRkj7bOkRZLuL4+HJT1Sm/9uafN0SZ+Q9FtJf5B0s6QPSFJtOT+U9MfS705Jl0jap9R9WdLHam23k7SwLOcBSWskLZY0rdQ/X9Llkn4n6R5J10o6YizHIcZHAiBaa2sJjl7YPsH2TrZ3Aj4OfG1w3vbhpdnFwMHAEcDOwLHAPOCzHYubX5bzHGBX4IwhVvt14I3AXwG7AC8Eri3rAPgWcAWwF7AncBJw31j3NcYuARBDkjS1vPMbkHSXpM+X8qdJ+gdJt0raKOk8SbuUusF3qO+SdFt513eCpP8o6fryDvDztXW8U9JPJf2LpHsl/VLSwbX6NZJeV5tfKOn8Mvvj8nxPeaf6stLm3ZJuKuu+TNKza/0t6URJNwM3D7HfF0u6o2zPjyU9v1a3h6RvSbpP0jJJH5P0k1r9Z8t+31fe6b6y27bXjtNx5Z34nZI+VGs7R1J/Wc4GSZ8ebp+bKsf2UODNtlfY3mT7auDtwImSDujsY/tu4BvAX3RZ3uuAQ4C5tpeV5d1r+0zbX5I0GZgOnGP74fL4qe2fdC4rtrwEQHQlaRLwbeBWYBowBbiwVL+zPF4L/AdgJ+DzHYt4KTADeBvwGeBDwOuA5wNvlfTqjra3AJOBfwQukbR7g818VXnetbzDvUrSkcAHgf8C9AH/DlzQ0e/Iss6ZQyz3u2Xb9wSuA75SqzsTeADYGziuPOqWAbOA3YGvAhdL2n6YfXgF8Fyqd8sfkfS8Uv5Z4LO2nwnsD1w01D4Ps+xuDgGusX1bvdD2NcBaHnvX/iflJP5m4Oddlvc64Gedy6u5C1gNnC/pSEl79bi98QRKAMRQ5gD7Ah+w/YDtP9betf018Gnbt9i+H/h74OiOIZV/Ln0upzphXmB7o+3bqU7KL6q13Qh8xvYjtr8GrAJeP8rtPh74hO2bbG+iGgaZVb8KKPV32/5DtwXYXmz797YfAhYCL5S0SwnFNwP/aPtB2zcC53b0Pd/2XeWd8OnA06lO8EP5qO0/2P4F8Auq4ROAR4ADJE22fX95lz4eJgPrh6hbX+oHfU7SPWW71gN/26XPHsMsD1c/NvZaYA1wOrC+XFXN6H3TY7wlAGIoU4Fby0m0075UVwaDbgW2oRrjHbShNv2HLvM71eZv9+N/lfDWso7ReDbw2TLUdA9wNyCqK5hBQ71bRdIkSadK+rWk+6hOXFCdGPuo9rPe/7aO/u8vw0/3lvXvwuNPqp3uqE0/yGPH5T1UY++/LENN/3mYZfTiTmCfIer2KfWDTrK9q+0ptv/a9kCXPncNszwAbK+1Pd/2/lT/Pg8A541i22OcJQBiKLcBzxrig9J1VP+RBz0L2MTjT/K9mCI9dgdKWd66Mv0AsEOtbu/adLefsr0NOL6cuAYfz7D9/0boN+ivgLlUQxu7UA1/QRUiA1T7uV+t/dTBiTLe/3fAW4HdbO8K3Fv69sT2zbaPoRqG+iTwdUk7jrDtTXwfeKmkqfVCSXOo9uXfRrG8OZL2G7ElUIaKzqTL5wmx5SUAYig/o7q0P1XSjpK2l/TyUncB8N8lTZdUv9uk29VCE3sCJ0naVtJbgOcBS0vdcqrhpW0lzQaOqvUbADZTfQ4xaBHw94Mf3Jahm7f0sC07Aw9RvbPdgWrfALD9KHAJsFDSDpIOBN7R0XdT2a5tJH0EeGYP6/4TSW+X1Gd7M3BPKX6U7vvcmO3vA1cC31B1e+YkSQdRfc5xlu2uH4yPsLwrgEslvUTSNpJ2Lh/8v1vSbpI+KukAVTcPTAbeDYzXkFaMQQIguionuzcABwC/pfqA8G2lejHwr1R3pPwG+CPw38awumuoPnS9E/ifwFG27yp1H6b6EPR3wEepPlgd3MYHS/ufliGfg2xfSvWO+cIyhLMCOJzmzqMagroduJE/P1HNp7oyuIPqGFxAFRgAl1F9gPyrsow/Msxw0wgOA1ZKup/qA+Gjy2cqf7bPo1j2m4EfAN8D7gfOB77E6P8Nj6IK7K9RXfGsAGZTXR08THUV9X2qWz9XUB2vd45yXTGOlD8IExNJ0juB99p+xURvy2hI+iSwt+3Ou4EinvRyBRDRA0kHSvpLVeZQfVh76URvV8RoPOW+CRnxBNuZathnX6rbV08HvjmhWxQxShkCiohoqQwBRUS01FY1BDR58mRPmzZtojcjImKrcu21195pu6+zfKsKgGnTptHf3z/RmxERsVWRdGu38gwBRUS0VAIgIqKlEgARES2VAIiIaKkEQERESyUAIiJaKgEQEdFSCYCIiJZKAEREtNRW9U3giK3VtAXfmehNmFBrTn39RG9CdNHoCkDSYZJWSVotaUGX+gMlXSXpIUmn1MqfK2l57XGfpJNL3UJJt9fqjhi/3YqIiJGMeAUgaRLVH3E+hOrPAi6TtMT2jbVmdwMnAUfW+9peBcyqLed2Hv/HM86wfdqY9iAiIkalyRXAHGC17VtsPwxcCMytN7C90fYy4JFhlnMw8GvbXX+UKCIitqwmATCFx/9h67WlrFdHU/0lpbr5kq6XtFjSbt06SZonqV9S/8DAwChWGxER3TQJAHUp6+nPiEnaDngjcHGt+Cxgf6ohovVUf1rvz1dkn217tu3ZfX1/9nPWERExSk0CYC0wtTa/H7Cux/UcDlxne8Ngge0Nth+1vRk4h2qoKSIitpAmAbAMmCFpenknfzSwpMf1HEPH8I+kfWqzbwJW9LjMiIgYgxHvArK9SdJ84DJgErDY9kpJJ5T6RZL2BvqBZwKby62eM23fJ2kHqjuIju9Y9KckzaIaTlrTpT4iIp5Ajb4IZnspsLSjbFFt+g6qoaFufR8E9uhSfmxPWxoREeMqPwUREdFSCYCIiJZKAEREtFQCICKipRIAEREtlQCIiGipBEBEREslACIiWioBEBHRUgmAiIiWSgBERLRUAiAioqUSABERLZUAiIhoqQRARERLJQAiIloqARAR0VIJgIiIlkoARES0VAIgIqKlGgWApMMkrZK0WtKCLvUHSrpK0kOSTumoWyPpBknLJfXXyneXdIWkm8vzbmPfnYiIaGrEAJA0CTgTOByYCRwjaWZHs7uBk4DThljMa23Psj27VrYAuNL2DODKMh8REVtIkyuAOcBq27fYfhi4EJhbb2B7o+1lwCM9rHsucG6ZPhc4soe+ERExRk0CYApwW21+bSlrysDlkq6VNK9Wvpft9QDlec9unSXNk9QvqX9gYKCH1UZExHCaBIC6lLmHdbzc9ouphpBOlPSqHvpi+2zbs23P7uvr66VrREQMo0kArAWm1ub3A9Y1XYHtdeV5I3Ap1ZASwAZJ+wCU541NlxkREWPXJACWATMkTZe0HXA0sKTJwiXtKGnnwWngUGBFqV4CHFemjwO+2cuGR0TE2GwzUgPbmyTNBy4DJgGLba+UdEKpXyRpb6AfeCawWdLJVHcMTQYulTS4rq/a/l5Z9KnARZLeA/wWeMv47lpERAxnxAAAsL0UWNpRtqg2fQfV0FCn+4AXDrHMu4CDG29pRESMq3wTOCKipRIAEREtlQCIiGipBEBEREslACIiWioBEBHRUgmAiIiWSgBERLRUAiAioqUSABERLZUAiIhoqQRARERLJQAiIloqARAR0VIJgIiIlkoARES0VAIgIqKlEgARES2VAIiIaKkEQERESzUKAEmHSVolabWkBV3qD5R0laSHJJ1SK58q6QeSbpK0UtL7anULJd0uaXl5HDE+uxQREU1sM1IDSZOAM4FDgLXAMklLbN9Ya3Y3cBJwZEf3TcD7bV8naWfgWklX1PqeYfu0Me9FRET0rMkVwBxgte1bbD8MXAjMrTewvdH2MuCRjvL1tq8r078HbgKmjMuWR0TEmDQJgCnAbbX5tYziJC5pGvAi4Jpa8XxJ10taLGm3IfrNk9QvqX9gYKDX1UZExBCaBIC6lLmXlUjaCfgGcLLt+0rxWcD+wCxgPXB6t762z7Y92/bsvr6+XlYbERHDaBIAa4Gptfn9gHVNVyBpW6qT/1dsXzJYbnuD7UdtbwbOoRpqioiILaRJACwDZkiaLmk74GhgSZOFSxLwJeAm25/uqNunNvsmYEWzTY6IiPEw4l1AtjdJmg9cBkwCFtteKemEUr9I0t5AP/BMYLOkk4GZwF8CxwI3SFpeFvlB20uBT0maRTWctAY4fnx3LSIihjNiAACUE/bSjrJFtek7qIaGOv2E7p8hYPvY5psZERHjLd8EjohoqQRARERLJQAiIloqARAR0VIJgIiIlkoARES0VAIgIqKlEgARES2VAIiIaKkEQERESyUAIiJaKgEQEdFSCYCIiJZKAEREtFQCICKipRIAEREtlQCIiGipBEBEREslACIiWioBEBHRUo0CQNJhklZJWi1pQZf6AyVdJekhSac06Stpd0lXSLq5PO829t2JiIimRgwASZOAM4HDgZnAMZJmdjS7GzgJOK2HvguAK23PAK4s8xERsYU0uQKYA6y2fYvth4ELgbn1BrY32l4GPNJD37nAuWX6XODIUe5DRESMQpMAmALcVptfW8qaGK7vXrbXA5TnPbstQNI8Sf2S+gcGBhquNiIiRtIkANSlzA2XP5a+VWP7bNuzbc/u6+vrpWtERAyjSQCsBabW5vcD1jVc/nB9N0jaB6A8b2y4zIiIGAdNAmAZMEPSdEnbAUcDSxouf7i+S4DjyvRxwDebb3ZERIzVNiM1sL1J0nzgMmASsNj2SkknlPpFkvYG+oFnApslnQzMtH1ft75l0acCF0l6D/Bb4C3jvXMRETG0EQMAwPZSYGlH2aLa9B1UwzuN+pbyu4CDe9nYiIgYP/kmcERESyUAIiJaKgEQEdFSCYCIiJZKAEREtFQCICKipRIAEREtlQCIiGipBEBEREslACIiWioBEBHRUgmAiIiWSgBERLRUAiAioqUSABERLZUAiIhoqQRARERLJQAiIloqARAR0VIJgIiIlmoUAJIOk7RK0mpJC7rUS9LnSv31kl5cyp8raXntcZ+kk0vdQkm31+qOGN9di4iI4WwzUgNJk4AzgUOAtcAySUts31hrdjgwozxeCpwFvNT2KmBWbTm3A5fW+p1h+7Tx2JGIiOhNkyuAOcBq27fYfhi4EJjb0WYucJ4rVwO7Stqno83BwK9t3zrmrY6IiDFrEgBTgNtq82tLWa9tjgYu6CibX4aMFkvardvKJc2T1C+pf2BgoMHmRkREE00CQF3K3EsbSdsBbwQurtWfBexPNUS0Hji928ptn217tu3ZfX19DTY3IiKaaBIAa4Gptfn9gHU9tjkcuM72hsEC2xtsP2p7M3AO1VBTRERsIU0CYBkwQ9L08k7+aGBJR5slwDvK3UAHAffaXl+rP4aO4Z+OzwjeBKzoeesjImLURrwLyPYmSfOBy4BJwGLbKyWdUOoXAUuBI4DVwIPAuwb7S9qB6g6i4zsW/SlJs6iGitZ0qY+IiCfQiAEAYHsp1Um+XraoNm3gxCH6Pgjs0aX82J62NCIixlW+CRwR0VIJgIiIlkoARES0VAIgIqKlEgARES2VAIiIaKkEQERESyUAIiJaKgEQEdFSCYCIiJZKAEREtFQCICKipRIAEREtlQCIiGipBEBEREslACIiWioBEBHRUgmAiIiWSgBERLRUAiAioqUaBYCkwyStkrRa0oIu9ZL0uVJ/vaQX1+rWSLpB0nJJ/bXy3SVdIenm8rzb+OxSREQ0MWIASJoEnAkcDswEjpE0s6PZ4cCM8pgHnNVR/1rbs2zPrpUtAK60PQO4ssxHRMQW0uQKYA6w2vYtth8GLgTmdrSZC5znytXArpL2GWG5c4Fzy/S5wJE9bHdERIxRkwCYAtxWm19bypq2MXC5pGslzau12cv2eoDyvGe3lUuaJ6lfUv/AwECDzY2IiCaaBIC6lLmHNi+3/WKqYaITJb2qh+3D9tm2Z9ue3dfX10vXiIgYRpMAWAtMrc3vB6xr2sb24PNG4FKqISWADYPDROV5Y68bHxERo9ckAJYBMyRNl7QdcDSwpKPNEuAd5W6gg4B7ba+XtKOknQEk7QgcCqyo9TmuTB8HfHOM+xIRET3YZqQGtjdJmg9cBkwCFtteKemEUr8IWAocAawGHgTeVbrvBVwqaXBdX7X9vVJ3KnCRpPcAvwXeMm57FRERIxoxAABsL6U6ydfLFtWmDZzYpd8twAuHWOZdwMG9bGxERIyffBM4IqKlGl0BPBVMW/Cdid6ECbXm1NdP9CZExJNMrgAiIloqARAR0VIJgIiIlkoARES0VAIgIqKlEgARES2VAIiIaKkEQERESyUAIiJaKgEQEdFSCYCIiJZKAEREtFQCICKipVrza6ARsfVq+6/5whPzi765AoiIaKkEQERESyUAIiJaKgEQEdFSjQJA0mGSVklaLWlBl3pJ+lypv17Si0v5VEk/kHSTpJWS3lfrs1DS7ZKWl8cR47dbERExkhHvApI0CTgTOARYCyyTtMT2jbVmhwMzyuOlwFnleRPwftvXSdoZuFbSFbW+Z9g+bfx2JyIimmpyBTAHWG37FtsPAxcCczvazAXOc+VqYFdJ+9heb/s6ANu/B24Cpozj9kdExCg1CYApwG21+bX8+Ul8xDaSpgEvAq6pFc8vQ0aLJe3WbeWS5knql9Q/MDDQYHMjIqKJJgGgLmXupY2knYBvACfbvq8UnwXsD8wC1gOnd1u57bNtz7Y9u6+vr8HmRkREE00CYC0wtTa/H7CuaRtJ21Kd/L9i+5LBBrY32H7U9mbgHKqhpoiI2EKaBMAyYIak6ZK2A44GlnS0WQK8o9wNdBBwr+31kgR8CbjJ9qfrHSTtU5t9E7Bi1HsRERE9G/EuINubJM0HLgMmAYttr5R0QqlfBCwFjgBWAw8C7yrdXw4cC9wgaXkp+6DtpcCnJM2iGipaAxw/bnsVEREjavRjcOWEvbSjbFFt2sCJXfr9hO6fD2D72J62NCIixlW+CRwR0VIJgIiIlkoARES0VAIgIqKlEgARES2VAIiIaKkEQERESyUAIiJaKgEQEdFSCYCIiJZKAEREtFQCICKipRIAEREtlQCIiGipBEBEREslACIiWioBEBHRUgmAiIiWSgBERLRUAiAioqUaBYCkwyStkrRa0oIu9ZL0uVJ/vaQXj9RX0u6SrpB0c3nebXx2KSIimhgxACRNAs4EDgdmAsdImtnR7HBgRnnMA85q0HcBcKXtGcCVZT4iIraQJlcAc4DVtm+x/TBwITC3o81c4DxXrgZ2lbTPCH3nAueW6XOBI8e4LxER0YNtGrSZAtxWm18LvLRBmykj9N3L9noA2+sl7dlt5ZLmUV1VANwvaVWDbX4ymgzcOVEr1ycnas3jZkKP31NAXn9jM+GvvzEew2d3K2wSAOpS5oZtmvQdlu2zgbN76fNkJKnf9uyJ3o6tVY7f2OT4jc1T9fg1GQJaC0ytze8HrGvYZri+G8owEeV5Y/PNjoiIsWoSAMuAGZKmS9oOOBpY0tFmCfCOcjfQQcC9ZXhnuL5LgOPK9HHAN8e4LxER0YMRh4Bsb5I0H7gMmAQstr1S0gmlfhGwFDgCWA08CLxruL5l0acCF0l6D/Bb4C3jumdPPlv9MNYEy/Ebmxy/sXlKHj/ZPQ3JR0TEU0S+CRwR0VIJgIiIlkoAbAGSjuzy7emokXR/ed5X0tcbtF8qadcnfsueOiS9RtK3h6j7Yl6j7ZMA2DKOpPopjFYrd4kN+5qzvc72USMty/YRtu8Zv63bukhq8h2exmy/1/aN47nMePJLAIySpP8r6VpJK8u3lf/0LrZMHyXpy5L+E/BG4H9JWi5pf0mzJF1dfjjv0sEfwpN0kqQbS/mFE7Nn40vSNEk3SfoCcB3wYUnLyj5+dIj2K8r0DpIuKm2/JukaSbNL3RpJk8v030paUR4nd6z3nPJvdLmkZ2y5PR8bSR+W9MvyQ4kXSDpF0g8lfVzSj4D3SXpDOSY/l/R9SXuVvgsl/aukfys/tvhfa4veSdLXy7K/Ikmlzw9rx/YwSddJ+oWkK0vZq8vrd3lZ385b+piMB0k7SvpO2bcVkt5WXkuflPSz8jigtB3q+O4k6f9IuqG8Nt9cyg+VdFU5dhdL2mki97UR23mM4gHsXp6fAawA9gDur9UfBXy5TH8ZOKpWdz3w6jL9T8BnyvQ64OlleteJ3sdxOk7TgM3AQcChVLfTierNx7eBV5V299faryjTpwD/u0z/BbAJmF3m11B9Pf8lwA3AjsBOwErgRWU5m4BZpf1FwNsn+ng0PGazgeXltbUzcHM5Fj8EvlBrtxuP3cn3XuD0Mr0Q+EXpP5nq51j2BV4D3Ev1hcynAVcBryh9fljW21faT+94nX8LeHmZ3gnYZqKP0yiP7ZuBc2rzu5TX0ofK/DuAb49wfD85+H+21m4y8GNgx1L2d8BHJnp/R3rkCmD0TpL0C+Bqqm87z2jSSdIuVCf3H5Wic4FXlenrga9IejvVyeup4lZXPxJ4aHn8nOpq4ECGP26voPoBQWyvoDo+3dpcavsB2/cDlwCvLHW/sb28TF9LFQpbg1cA37T9B9u/pzr5DvpabXo/4DJJNwAfAJ5fqxvsfyfwA6ofZgT4me21tjdThcy0jnUfBPzY9m8AbN9dyn8KfFrSSVSv36319XkD8Lryjv+Vtu8t5RfUnl9Wpoc6vq+j+pVjAGz/juq4zQR+Kmk51Zdbu/7+zpNJAmAUJL2G6kXwMtsvpDqhbc/jf+do+1Es+vVUL6yXANeO9zjvBHqgPAv4hO1Z5XGA7S8N06/bb0n10uah2vSjNPvtqyeD4fbpgdr0vwCft/0C4Hge/5rr/ILP4PxIx0Rd+mL7VKp3wc8ArpZ04DDb+KRl+1c8dtX4CUkfGayqNyvPQx3fbsdIwBW11/ZM2+95QnZiHCUARmcX4He2Hyz/EQ4q5RskPa980PmmWvvfU13KU95x/E7S4LvUY4EflT5Tbf8A+B/ArlSX2k8llwHvHhwblTRFQ/wKbPET4K2l7UzgBV3a/Bg4snxesCPVcf/38d3sLe4nwBskbV+O1euHaLcLcHuZPq6jbm7pvwfV0M+yhuu+Cni1pOlQ/eGm8ry/7RtsfxLop7p62+pI2hd40Pb5wGnA4B+velvt+aoyPdTxvRyYX1vmblQjAS+vfX6wg6TnPCE7MY62lndETzbfA06QdD2wiuofH6o/avNtqjHUFTx2Ar8QOKdcPh9F9WJaJGkH4Baqn86YBJxfhogEnOGn2F0uti+X9DzgqvLZ4/3A2xn6hwC/AJxbjvPPqYaA7q03sH2dpC8DPytFX7T9c0nTxn0HthDbyyQtoRrHv5XqhHtvl6YLgYsl3U71Gpxeq/sZ8B3gWcA/217X5IRke0DVTQ2XlDclG4FDgJMlvZbqquFG4Luj3b8J9gKqGzI2A48AfwN8HXi6pGuo3hQfU9oupPvx/RhwpqqbFR4FPmr7EknvBC6Q9PTS7h+AXz3xuzR6+SmIeNJS9RfltrX9R0n7U/3luOe4+uNCT2mSdrJ9f3mT8GNgnu3rGvZdSPWh+mlP5DY+VUhaQ3VzQev+3kSuAOLJbAfgB5K2pboq+ps2nPyLs8uw1/bAuU1P/hG9yBVARERL5UPgiIiWSgBERLRUAiAioqUSABERLZUAiIhoqf8PkUSKoa0oYfYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"{word} against TOPICS\")\n",
    "plt.bar(topic_word_distr.loc[word].index, topic_word_distr.loc[word])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4683e9c57c6f4aa695ffd72836e7b5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=804.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 99.50%, 4 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4254bd378643db89bca46d8b96dfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=396.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 82.32%, avg-accuarcy = 90.91%, 70 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e748af1be61454baef98ad8cca1f70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 autos  religion  graphics     space\n",
      "nasa          0.000000  0.000000  0.003257  0.019943\n",
      "akron         0.000000  0.000000  0.019113  0.000000\n",
      "composites    0.000000  0.000000  0.014334  0.000000\n",
      "modeling      0.000000  0.000000  0.012714  0.000155\n",
      "workstations  0.000000  0.000000  0.012837  0.000000\n",
      "...                ...       ...       ...       ...\n",
      "with          0.000037  0.000038  0.000039  0.000022\n",
      "is            0.000028  0.000040  0.000030  0.000030\n",
      "it            0.000038  0.000026  0.000031  0.000031\n",
      "in            0.000035  0.000032  0.000027  0.000029\n",
      "one           0.000031  0.000034  0.000028  0.000028\n",
      "\n",
      "[107 rows x 4 columns]\n",
      "sampe, ncga, the university of akron, and nasa lewis research center is sponsoring:                        computers and composites   a one-day seminar devoted to practical applications of  computer workstations for efficient processing, design, and    manufacture of composites  may 18, 1993 at  the university of akron   akron, ohio  speakers on:  advancement in graphics visualization   dr. jay horowitz, nasa  integrated product development with     mr. michael r. cowen   network workstations            sikorski aircraft  structural analysis    mr. brian fite, nasa  stereolithography    mr. jason williams, penn state-erie  molecular and physical modeling  dr. vassilios galiatsato,   of polymer curing                       university of akron  process modeling of polymer   matrix composites    dr ram upadhyay, ge corporate r&d  registration fees: $75.00 advance, $100.00 on site  includes box lunch   contact gary roberts, nasa lewis research center  216  433-344 or write:  sampe regional seminar  c/o gary roberts  nasa lewis research center  21000 brookpark rd ms 49-1  cleveland, ohio 44135  or email to me, | and i ll get it to gary.   |          \\/\n",
      "predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "slick       0.002512  0.003995  0.000000  0.000000\n",
      "wondering   0.003166  0.000000  0.002655  0.000033\n",
      "chances     0.003008  0.002455  0.000000  0.000051\n",
      "death       0.001242  0.002023  0.000000  0.000251\n",
      "site        0.000562  0.000099  0.002091  0.000305\n",
      "kept        0.001550  0.000083  0.000101  0.001234\n",
      "archive     0.001277  0.000000  0.000259  0.001206\n",
      "thanks      0.000653  0.000048  0.001540  0.000265\n",
      "support     0.000096  0.000270  0.000992  0.000269\n",
      "50          0.000840  0.000032  0.000403  0.000287\n",
      "data        0.000249  0.000019  0.000605  0.000645\n",
      "any         0.000404  0.000197  0.000598  0.000151\n",
      "basically   0.000401  0.000029  0.000248  0.000643\n",
      "info        0.000215  0.000102  0.000682  0.000192\n",
      "to          0.000233  0.000246  0.000236  0.000233\n",
      "me          0.000200  0.000259  0.000311  0.000113\n",
      "does        0.000265  0.000172  0.000300  0.000125\n",
      "who         0.000183  0.000382  0.000057  0.000181\n",
      "discussed   0.000202  0.000058  0.000361  0.000153\n",
      "already     0.000395  0.000097  0.000132  0.000147\n",
      "that        0.000186  0.000279  0.000147  0.000157\n",
      "has         0.000241  0.000157  0.000174  0.000142\n",
      "if          0.000222  0.000139  0.000195  0.000148\n",
      "it          0.000203  0.000137  0.000163  0.000166\n",
      "the         0.000172  0.000175  0.000137  0.000164\n",
      "and         0.000162  0.000174  0.000161  0.000143\n",
      "am          0.000148  0.000077  0.000267  0.000101\n",
      "really      0.000209  0.000214  0.000093  0.000066\n",
      "direct      0.000074  0.000170  0.000243  0.000091\n",
      "mail        0.000080  0.000099  0.000240  0.000122\n",
      "someone     0.000167  0.000101  0.000060  0.000201\n",
      "says        0.000083  0.000222  0.000113  0.000092\n",
      "just        0.000218  0.000080  0.000108  0.000097\n",
      "could       0.000079  0.000075  0.000140  0.000192\n",
      "been        0.000168  0.000141  0.000053  0.000112\n",
      "for         0.000096  0.000070  0.000155  0.000089\n",
      "so          0.000121  0.000106  0.000088  0.000060\n",
      "an          0.000125  0.000082  0.000081  0.000073\n",
      "there       0.000079  0.000080  0.000125  0.000077\n",
      "or          0.000073  0.000084  0.000119  0.000077\n",
      "claim       0.000072  0.000114  0.000072  0.000094\n",
      "all         0.000090  0.000112  0.000079  0.000068\n",
      "are         0.000097  0.000106  0.000068  0.000076\n",
      "also        0.000107  0.000077  0.000083  0.000071\n",
      "is          0.000073  0.000106  0.000079  0.000078\n",
      "this        0.000071  0.000088  0.000103  0.000074\n",
      "discussion  0.000090  0.000071  0.000074  0.000099\n",
      "chances are that this has been discussed to death already, and if so could someone who has kept the discussion mail me or direct me  to an archive site. basically, i am just wondering if slick 50 really does all it says that it does. and also, is there any data to support the claim.  thanks for any info.\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "batf       0.003123  0.008048  0.000000  0.000000\n",
      "smith      0.007172  0.000000  0.001106  0.000000\n",
      "warrant    0.002524  0.004103  0.000000  0.000000\n",
      "followups  0.005800  0.000000  0.000000  0.000000\n",
      "koresh     0.000102  0.005616  0.000000  0.000000\n",
      "...             ...       ...       ...       ...\n",
      "but        0.000025  0.000028  0.000032  0.000025\n",
      "be         0.000024  0.000031  0.000026  0.000029\n",
      "before     0.000028  0.000023  0.000027  0.000030\n",
      "one        0.000028  0.000030  0.000025  0.000025\n",
      "don        0.000027  0.000028  0.000024  0.000028\n",
      "\n",
      "[117 rows x 4 columns]\n",
      "perhaps it is because witnesses who have left the compound have all testified that the batf shot first, they they did not identify themselves before tossing in concussion grenades  not that anyone inside could have _heard_ such identification after being near a concussion grenade  and the announcement from the batf that they have sealed the warrant under which they were operating - which was a _search_ warrant, by the way, _not_ an arrest warrant.  in short, perhaps because the batf is wildly out of control and perhaps calmer heads have realized that bombing a compound full of woman and children will not improve their position. there is a real chance that koresh will be able to prove self-defense in court.  that will leave - what? - four officers dead and no one to blame but the batf.  followups directed to alt.activism, where the discussion has raged nearly as long as the seige, and which shows every sign of not giving up nearly as soon.  larry smith  smith@ctron.com   no, i don t speak for cabletron.  need you ask?\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "          autos  religion  graphics     space\n",
      "cult   0.000000  0.006709  0.000000  0.000659\n",
      "pdt    0.000000  0.000000  0.000000  0.005653\n",
      "jobs   0.001092  0.000265  0.000000  0.003506\n",
      "fri    0.000000  0.000103  0.000733  0.003783\n",
      "scott  0.002838  0.000000  0.000030  0.001471\n",
      "...         ...       ...       ...       ...\n",
      "by     0.000012  0.000018  0.000014  0.000014\n",
      "this   0.000012  0.000015  0.000018  0.000013\n",
      "want   0.000015  0.000015  0.000016  0.000011\n",
      "other  0.000015  0.000012  0.000014  0.000015\n",
      "more   0.000014  0.000015  0.000012  0.000015\n",
      "\n",
      "[218 rows x 4 columns]\n",
      "from: <tom> subject: computer cult  from scott fri apr 23 16:31:21 1993 received: by igc.apc.org  4.1/revision: 1.77    id aa16121; fri, 23 apr 93 16:31:09 pdt date: fri, 23 apr 93 16:31:09 pdt message-id: <9304232331.aa16121@igc.apc.org> from: scott weikart <scott> sender: scott to: cdplist subject: next stand-off? status: r  redwood city, ca  api  -- a tense stand-off entered its third week today as authorities reported no progress in negotiations with charismatic cult leader steve jobs.  negotiators are uncertain of the situation inside the compound, but some reports suggest that half of the hundreds of followers inside have been terminated.  others claim to be staying of their own free will, but jobs  persuasive manner makes this hard to confirm.  in conversations with authorities, jobs has given conflicting information on how heavily prepared the group is for war with the industry.  at times, he has claimed to  have hardware which will blow anything else away , while more recently he claims they have stopped manufacturing their own.  agents from the atf  apple-taligent forces  believe that the group is equipped with serious hardware, including 486-caliber pieces and possibly canon equipment.  the siege has attracted a variety of spectators, from the curious to other cultists.  some have offered to intercede in negotiations, including a young man who will identify himself only as  bill  and claims to be the  ms-iah .  former members of the cult, some only recently deprogrammed, speak hesitantly of their former lives, including being forced to work 20-hour days, and subsisting on jolt and twinkies.  there were frequent lectures in which they were indoctrinated into a theory of  interpersonal computing  which rejects traditional roles.  late-night vigils on chesapeake drive are taking their toll on federal marshals.  loud rock and roll, mostly talking heads, blares throughout the night.  some fear that jobs will fulfill his own apocalyptic prophecies, a worry reinforced when the loudspeakers carry jobs  own speeches -- typically beginning with a chilling  i want to welcome you to the  next world   .\n",
      "predicted_topic = religion, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07142857, 0.03947368, 0.03225806, 0.03125   , 0.02702703,\n",
       "       0.02631579, 0.02325581, 0.02173913, 0.0212766 , 0.02040816,\n",
       "       0.02      , 0.01587302, 0.01515152, 0.01492537, 0.01428571,\n",
       "       0.01204819, 0.01176471, 0.0106383 , 0.01052632, 0.00877193])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv = train_doc_vectors[:, vocabulary.index(\"enough\")]\n",
    "xv[xv.argsort()[::-1]][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usually....go enough places and you ll see stuff happen you didn t think did. ====> autos\n",
      "\n",
      "depends. if you assume the existance of a working ssto like dc, on billion $$ would be enough to put about a quarter million pounds of stuff on the moon. if some of that mass went to send equipment to make lox for the transfer vehicle, you could send a lot more. either way, its a lot more than needed.  this prize isn t big enough to warrent developing a ssto, but it is enough to do it if the vehicle exists.    allen ====> space\n",
      "\n",
      "where does the shadow come from?  there s nothing close enough to block sunlight from hitting them.  i wouldn t expect there to be anything block our view of them either.  what am i missing? ====> space\n",
      "\n",
      "if raw materials where to cost enough that getting them from space would be cost effective then the entire world economy would colapse long before the space mines could be built.    allen ====> space\n",
      "\n",
      "recently-manufactured locomotives have wheel-slip detection systems that use frequencies shared with police radar  i forget which band . these will set off your radar detector if you get close enough, though i believe the range is pretty short. ====> autos\n",
      "\n",
      "too many clues, not enough substance.  you ask a lot of good questions, though, but they are questions *you* should be worried about, not me.  i m not the inerrantist here.  let me know when you are ready to get serious. ====> religion\n",
      "\n",
      "cup holders  driving is an importantant enough undertaking  cellular phones and mobile fax machines  see above  vanity mirrors on the driver s side. ashtrays  smokers seem to think it s just fine to use the road  fake convertible roofs and vinyl roofs. any gold trim. ====> autos\n",
      "\n",
      "i bought an intrepid about two months ago and am very happy with it.  lots of room inside and even with the smaller engine it has enough power for me.  the only problem i found was a small selection on the dealer s lots. they are hot sellers around here. ====> autos\n",
      "\n",
      "right. in the thirties both buick and packard had two spares mounted in wells in the front fenders. of course that was back when the front fenders were long enough to provide room. there were a couple of other marques that did this as well, but memory fades. ====> autos\n",
      "\n",
      "well, first you work out how much cold gas you need, then make the tanks big enough.  working out how much cold gas is another problem, depending on vehicle configuration, flight duration, thruster isp  which couples into storage pressure, which may be a factor in selecting tank wall thickness etc. ====> space\n",
      "\n",
      "hi, i ve come across a fast triangle fill-draw routine for mode 13h.  by calling this routine enough times, you have a fast polygon drawing routine.  i think i ftp ed from wuarchive.wustl.edu:/pub/msdos_uploads/programming. i have a copy of it so i reupload it there.  the triangle.txt file has this to say : ====> graphics\n",
      "\n",
      "the girl s ok, actually, and she recovered well enough to go home.  i don t know if she has any permanent damage, though.  just in case anybody was concerned...    if people start forcing others to take responsibility for their actions things like this wouldn t happen.  untill we stop blaming outside causes, and start blaming the criminals, we will continue to let things like this happen. ====> autos\n",
      "\n",
      "hmmm....i was listening to the local radio expert  who is, amazingly enough, an honest-to-god expert tm ; it s amazing what he knows... ,  and he said that, based on his conversations with the inventor of  slick50  who is no longer with the comapny, due to some kind of  conflict , he avoids it like the plague.  he does recommend other  teflon-based/type oil additives, though.      james ====> autos\n",
      "\n",
      "how about brass or silver?  i ve seen real chessboards that use that material.   right here is as good a place as any.  can t wait to see it.  i use the pov raytracer - is it compatible enough for your chessboard?  -------------------------------------------------------------------------------       i don t know if you ve got the whole picture or not, but it doesn t        seem like he s running on all thrusters   -- leonard mccoy        a guess?  you, spock?  that s extraordinary   -- james t. kirk ====> graphics\n",
      "\n",
      "i like my power windows. i think they re worth it.  however, cruise control is a pretty dumb option. what s the point? if you re on a long trip, you floor the gas and keep your eyes on the rear-view mirror for cops, right?  power seats are pretty dumb too, unless you re unlucky enough to have to share your car. otherwise, you d just adjust it once and just leave it like that. ====> autos\n",
      "\n",
      "[constitution sacrificed to the bandwidth gods]  im glad i finally have heard exactly what the oto is all about.  i finally know that i can stop looking, content i the knowlege that im not interested. it s tough enough listening to all the religions who refer to themselves as  the one truth .  how can i possibly accept it from a magical order?   we have all the answers and will give them to those who join us  and pay dues ?  scary.  besides, answers are easy.  questions   now that s another story...  rintaw ====> religion\n",
      "\n",
      "no. reverse lights are to warn others that you are backing up. they aren t bright enough to  typically  see by without the brake and tail lights.    well, red and orange were already taken. maybe white defines the direction that the car is moving in.   if you really want to be able to see behind you, get some fog lamps for the back of the car. these work very well - and are a good way to get rid of tailgaters if you get that rush of testosterone. ====> autos\n",
      "\n",
      ">very cost effective if you use the right accounting method :-      sherzer methodology        hell, yes. i m not going to let a bunch of seven suits tell me what the right way to estimate cost effectiveness is, at least not until they can make their mind up long enough to leave their scheme stable for a fiscal year or two.   seriously though. if you were to ask the british government whether their colonisation efforts in the americas were cost effective, what answer do you think you d get? what if you asked in 1765, 1815, 1865, 1915 and 1945 respectively? ;- ====> space\n",
      "\n",
      "hi all,  in short: looking for very fast assembly code for line/circle drawing    on svga graphics.  complete:  i am thinking of a simple but fast molecular graphics program to write on pc or clones.  ball-and-stick type   reasons: programs that i ve seen are far too slow for this purpose.  platform: 386/486 class machine.    800x600-16 or 1024x728-16 vga graphics    speed is important, 16-color for non-rendering    purpose is enough; may stay at 800x600 for    speed reason.            hope the code would be generic enough for different svga           cards.  my own card is based on trident 8900c, not vesa?   what i m looking for? 1  fast, very fast routines to draw lines/circles/simple-shapes    on above-mentioned svga resolutions.    presumably in assembly languagine.  yes, very fast please. 2  related codes to help rotating/zooming/animating the drawings on screen.    drawings for beginning, would be lines, circles mainly, think of    text, else later.     you know, the way molecular graphics rotates, zooms a molecule  2  and any other codes  preferentially in c  that can help the     project.  final remarks;- non-profit.  expected to become share-, free-ware.   any help is appreciated.  thanks  -frankie lau@tammy.harvard.edu ====> graphics\n",
      "\n",
      "in spite of my great respect for the people you speak of, i think their cost estimates are a bit over-optimistic. if nothing else, a working ssto is at least as complex as a large airliner and has a smaller experience base. it therefore seems that ssto development should cost at least as much as a typical airliner development. that puts it in the $3g to $5g range.   true it and the contest would result in a much larger market. but i don t think it would be enough to attract the investors given the risks involved.  if you could gurantee the ssto costs and gurantee that it captures 100% of the available launch market, then i think you could do it.    allen ====> space\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in xv.argsort()[::-1][:20]:\n",
    "    print(train_docs[index], '====>', label_classes[train_labels[index]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.argsort()[::-1][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
