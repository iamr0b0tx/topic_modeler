{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.politics.mideast', 'alt.atheism', 'sci.space']\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, old_labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4943df3207f84d448037ca1e6089841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasize = 100\n",
    "max_document_length = None\n",
    "\n",
    "index = -1\n",
    "clean_docs, labels = [], []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) != len(categories)*datasize:\n",
    "        index += 1\n",
    "        size_index = categories.index(classes[old_labels[index]])\n",
    "        \n",
    "        if sizes[size_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = docs[index]\n",
    "        status, doc, word_count = clean_doc(doc, True)\n",
    "        \n",
    "        if (not status) or (max_document_length is not None and len(doc) > max_document_length):\n",
    "            continue\n",
    "        \n",
    "        labels.append(categories[size_index])\n",
    "        clean_docs.append(doc)\n",
    "        sizes[size_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: alt.atheism\n",
      "==================================================\n",
      "i think that domestication will change behavior to a large degree domesticate animal exhibit behavior not found in the wild i don t think that they can be view a good representative of the wild animal kingdom since they have be breed for thousand of year to produce certain behavior etc\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(f\"Topic: {labels[index]}\\n{'='*50}\\n{clean_docs[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 400 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 9116\n"
     ]
    }
   ],
   "source": [
    "# mode = \"tfidf\"\n",
    "# mode = \"binary\"\n",
    "# mode = \"normalize\"\n",
    "# mode = \"binary-normalize\"\n",
    "mode = \"pmi\"\n",
    "\n",
    "# initialize the count vectorizer\n",
    "vectorizer = TfidfVectorizer() if mode == \"tfidf\" else CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "train_docs, test_docs = clean_docs, []\n",
    "# train_docs, test_docs = train_test_split(clean_docs, test_size=.33, random_state=42)\n",
    "\n",
    "vectorizer.fit(train_docs)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 train_docs, 0 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(train_docs).toarray()\n",
    "test_doc_vectors = vectorizer.transform(test_docs).toarray()\n",
    "\n",
    "if mode in [\"binary-normalize\", \"binary\", \"pmi\"]:\n",
    "    train_doc_vectors = (train_doc_vectors > 0).astype(float)\n",
    "    test_doc_vectors = (test_doc_vectors > 0).astype(float)\n",
    "    \n",
    "if mode == \"normalize\" or mode == \"binary-normalize\":\n",
    "    train_doc_vectors = normalize(train_doc_vectors, norm=\"l1\", axis=1)\n",
    "    test_doc_vectors = normalize(test_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "print(f\"{len(train_doc_vectors)} train_docs, {len(test_doc_vectors)} test docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122cc9165f804e65a85e795ee503b9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\christian\\Documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\utils.py:15: RuntimeWarning: overflow encountered in power\n",
      "  return 1 / (1 + (np.e**-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_co has shape (9116, 9116)\n"
     ]
    }
   ],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "p = pd.DataFrame((train_doc_vectors.sum(0) / len(train_doc_vectors)), columns=[0], index=vocabulary)[0]\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = word_doc_freqency[word_doc_freqency[word] == 1].sum(0) / len(train_doc_vectors)\n",
    "#     word_word_co[word] = pxy / (p[word] * p)\n",
    "    word_word_co[word] = np.nan_to_num(sigmoid(np.nan_to_num(np.log2(pxy / (p[word] * p)))))\n",
    "\n",
    "# word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #reduce freq in doc to bin value of 1 or 0\n",
    "# word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "# #the sum vertically of bin freq\n",
    "# word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "# word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "# word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     word_word_frequency = word_doc_freqency[word_doc_freqency[word] > 0].sum(0)\n",
    "#     word_word_co[word] = ((word_word_frequency * word_frequency_norm) / word_doc_total_frequency).fillna(0)\n",
    "\n",
    "# # word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886843</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000th</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000     000th      0029       007        01  011  0119  013   02  \\\n",
       "000    0.990471  0.000000  0.000000  0.990471  0.000000  0.0   0.0  0.0  0.0   \n",
       "000th  0.000000  0.999824  0.000000  0.000000  0.000000  0.0   0.0  0.0  0.0   \n",
       "0029   0.000000  0.000000  0.999824  0.000000  0.999141  0.0   0.0  0.0  0.0   \n",
       "007    0.990471  0.000000  0.000000  0.999824  0.000000  0.0   0.0  0.0  0.0   \n",
       "01     0.000000  0.000000  0.999141  0.000000  0.999141  0.0   0.0  0.0  0.0   \n",
       "\n",
       "           0245  ...  zillion  zimogliad  ziona  zionism   zionist      zman  \\\n",
       "000    0.000000  ...      0.0   0.990471    0.0      0.0  0.886843  0.990471   \n",
       "000th  0.000000  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "0029   0.000000  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "007    0.000000  ...      0.0   0.999824    0.0      0.0  0.000000  0.000000   \n",
       "01     0.999141  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "\n",
       "       zone  zoo  zulu  zur  \n",
       "000     0.0  0.0   0.0  0.0  \n",
       "000th   0.0  0.0   0.0  0.0  \n",
       "0029    0.0  0.0   0.0  0.0  \n",
       "007     0.0  0.0   0.0  0.0  \n",
       "01      0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Word Trust ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor = pd.DataFrame(data=gaussian2(word_entropy), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"look\", \"algorithm\", \"program\"]\n",
    "# words = [\"looking\", \"algorithm\", \"program\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.set_title(f\"Word Trust factor\")\n",
    "ax1.bar(words, (word_trust_factor)[words])\n",
    "\n",
    "ax2.set_title(f\"Word Frequency Normalized\")\n",
    "ax2.bar(words, word_frequency_norm[words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"software\"\n",
    "words = [\"car\", \"god\", \"file\", \"nasa\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "plt.title(f\"word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generates       0.999521\n",
       "construe        0.999521\n",
       "spencer         0.999521\n",
       "calculate       0.999521\n",
       "uncover         0.999521\n",
       "coincidental    0.999521\n",
       "tsv             0.999521\n",
       "alia            0.999521\n",
       "baseless        0.999521\n",
       "vnet            0.999521\n",
       "bret            0.999521\n",
       "kslocs          0.999521\n",
       "ureply          0.999521\n",
       "factual         0.999521\n",
       "whore           0.999521\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with gaussian entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_word_co = (word_word_co * word_trust_factor)\n",
    "word_word_co = (word_word_co.T / word_word_co.sum(1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"Updated word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tz           0.029944\n",
       "spencer      0.029944\n",
       "dependent    0.029944\n",
       "vnet         0.029944\n",
       "ureply       0.029944\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy2 = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor2 = pd.DataFrame(data=gaussian2(word_entropy2), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with word_word_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wwc = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     for other_word in vocabulary:\n",
    "#         ratios = word_word_co.loc[word][other_word] * word_word_co.loc[other_word]\n",
    "#         wwc.loc[word][ratios > wwc.loc[word]] = ratios[ratios > wwc.loc[word]]\n",
    "\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['animal', 'behavior', 'breed', 'certain', 'change', 'degree',\n",
       "       'domesticate', 'domestication', 'etc', 'exhibit', 'found', 'kingdom',\n",
       "       'large', 'produce', 'representative', 'thousand', 'view', 'wild'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv = word_doc_norm.iloc[0]\n",
    "wv_indices = wv[wv > .001*wv.max()].index\n",
    "wv_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d6b5dde8324d3d909306d5894c0bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "doc_word_distr has shape (400, 9116)\n"
     ]
    }
   ],
   "source": [
    "# doc_word_distr = pd.DataFrame(data=0.0, columns=vocabulary, index=word_doc_freqency.index)\n",
    "# word_doc_norm = (word_doc_freqency.T / word_doc_freqency.sum(1)).T * word_trust_factor\n",
    "\n",
    "# for doc_index in tqdm([0]):#range(len(train_doc_vectors))):\n",
    "#     wv = word_doc_norm.iloc[doc_index]\n",
    "#     wv_indices = wv[wv > .001*wv.max()].index\n",
    "#     doc_word_distr.iloc[doc_index] = (word_word_co.loc[wv_indices] * word_doc_norm.iloc[doc_index]).mean(0)\n",
    "\n",
    "# print(f\"doc_word_distr has shape {doc_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_distr = (word_doc_freqency.T / word_doc_freqency.sum(1)).T * (np.e**word_trust_factor)\n",
    "doc_word_distr = (doc_word_distr.T / doc_word_distr.sum(1)).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "directly     1.0\n",
       "of           1.0\n",
       "didn         1.0\n",
       "10           1.0\n",
       "maybe        1.0\n",
       "his          1.0\n",
       "missile      1.0\n",
       "get          1.0\n",
       "kill         1.0\n",
       "operation    1.0\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_index = 13\n",
    "word_doc_freqency.iloc[doc_index].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desintegrated    0.038808\n",
       "surgical         0.038461\n",
       "directly         0.038448\n",
       "missile          0.038448\n",
       "operation        0.038447\n",
       "body             0.038447\n",
       "hit              0.038447\n",
       "destroy          0.038447\n",
       "someone          0.038447\n",
       "house            0.038447\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.iloc[doc_index].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk.politics.mideast maybe the missile didn t hit directly such that his body get desintegrated of course destroy 10 house to kill someone be not a surgical operation or be it\n"
     ]
    }
   ],
   "source": [
    "print(labels[doc_index], train_docs[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000th  0029  007   01  011  0119  013   02  0245  ...  zillion  \\\n",
       "0  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "1  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "2  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "3  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "4  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "\n",
       "   zimogliad  ziona  zionism  zionist  zman  zone  zoo  zulu  zur  \n",
       "0        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "1        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "2        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "3        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "4        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breed', 'domesticate', 'domestication', 'wild', 'exhibit']\n"
     ]
    }
   ],
   "source": [
    "for di in range(len(doc_word_distr.index)):\n",
    "    print(doc_word_distr.iloc[di].sort_values(ascending=False).head(5).index.to_list())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ironic             0.000545\n",
       "humanist           0.000197\n",
       "birthday           0.000181\n",
       "45th               0.000181\n",
       "drl                0.000023\n",
       "nonononnononono    0.000010\n",
       "nile               0.000010\n",
       "incredibly         0.000008\n",
       "huh                0.000008\n",
       "photosynthetic     0.000007\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(doc_word_distr.mean(0) * word_trust_factor).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Latent partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distr_params has shape (400, 4)\n"
     ]
    }
   ],
   "source": [
    "# reduction = None\n",
    "reduction = \"pca\"\n",
    "# reduction = \"normal\"\n",
    "\n",
    "if reduction is None:\n",
    "    columns = doc_word_distr.columns\n",
    "    param_values = doc_word_distr.values\n",
    "\n",
    "if reduction == \"pca\":\n",
    "    num_of_components = 4\n",
    "    columns = list(range(num_of_components))\n",
    "    \n",
    "    pca = PCA(n_components=num_of_components)\n",
    "    param_values = pca.fit_transform(doc_word_distr)\n",
    "\n",
    "if reduction == \"normal\":\n",
    "    columns = [\"mean\", \"std\"]\n",
    "    param_values = np.array([doc_word_distr.mean(1), doc_word_distr.std(1)]).T\n",
    "    \n",
    "distr_params = pd.DataFrame(data=param_values, columns=columns, index=list(range(len(doc_word_distr))))\n",
    "print(f\"distr_params has shape {distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.007101</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>-0.014602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003256</td>\n",
       "      <td>-0.005113</td>\n",
       "      <td>-0.003928</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003288</td>\n",
       "      <td>-0.004822</td>\n",
       "      <td>-0.004353</td>\n",
       "      <td>-0.010058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002784</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.004163 -0.007101 -0.006560 -0.014602\n",
       "1 -0.003256 -0.005113 -0.003928  0.002366\n",
       "2 -0.003288 -0.004822 -0.004353 -0.010058\n",
       "3 -0.001184  0.001934  0.003075  0.003528\n",
       "4 -0.002784 -0.003852 -0.002882  0.002375"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kmeans MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a902a23de484566a9bea779530b837d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_of_topics = 4\n",
    "# kmeans_model = MiniBatchKMeans(n_clusters=num_of_topics, random_state=0)\n",
    "\n",
    "# num_of_iterations = 256\n",
    "\n",
    "# num_of_samples = len(distr_params)\n",
    "# batch_size = num_of_samples // 2\n",
    "\n",
    "# for i in tqdm(range(num_of_iterations)):\n",
    "#     indices = np.random.randint(num_of_samples, size=batch_size)\n",
    "    \n",
    "#     kmeans_model.partial_fit(distr_params.iloc[indices])\n",
    "\n",
    "# kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=num_of_topics, random_state=0).fit(distr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist has shape (400, 4), predicted_labels has shape (400,)\n"
     ]
    }
   ],
   "source": [
    "dist = kmeans_model.transform(distr_params)\n",
    "predicted_labels = kmeans_model.predict(distr_params)\n",
    "\n",
    "# wtf = normalize(dist, norm=\"l1\", axis=1)\n",
    "# wtf = normalize(wtf, norm=\"l1\", axis=0)\n",
    "\n",
    "wtf = gaussian(dist / dist.max(0))\n",
    "\n",
    "print(f\"dist has shape {dist.shape}, predicted_labels has shape {predicted_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99928197, 0.81438448, 0.99993749, 0.80319777],\n",
       "       [0.99980747, 0.81610347, 0.99989714, 0.81445361],\n",
       "       [0.99954305, 0.81598989, 0.99999414, 0.80625491],\n",
       "       ...,\n",
       "       [0.9999297 , 0.81812275, 0.99983119, 0.81467086],\n",
       "       [0.99923891, 0.8136871 , 0.99992277, 0.80278813],\n",
       "       [0.99986256, 0.81784861, 0.99990108, 0.81408237]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 225, 0: 172, 3: 1, 1: 2})"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voc_array = np.array(vocabulary)\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = dist[:, topic].argsort()\n",
    "    print(labels[indices[:10]])\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print((doc_word_distr.T * wtf[:, topic]).T.iloc[indices].mean(0).sort_values(ascending=False).head(10))\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print(((doc_word_distr.T * wtf[:, topic]).T.iloc[indices].sum(0) * word_trust_factor).sort_values(ascending=False).head(10))\n",
    "    \n",
    "def get_top(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    count = Counter()\n",
    "    for index in indices:\n",
    "        count[labels[index]] += wtf[index, topic]\n",
    "        \n",
    "    print(Counter(labels[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be      0.002779\n",
      "the     0.002487\n",
      "to      0.001867\n",
      "of      0.001824\n",
      "and     0.001515\n",
      "you     0.001502\n",
      "that    0.001450\n",
      "have    0.001280\n",
      "it      0.001274\n",
      "in      0.001218\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zur            0.0\n",
      "enjoy          0.0\n",
      "ensure         0.0\n",
      "enrage         0.0\n",
      "enough         0.0\n",
      "enormous       0.0\n",
      "ennumerated    0.0\n",
      "enlighten      0.0\n",
      "enhancement    0.0\n",
      "entail         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offender         5.450304e-11\n",
      "cozy             5.450304e-11\n",
      "theodore         5.450304e-11\n",
      "kkkaldis         5.450304e-11\n",
      "doublespeak      5.450304e-11\n",
      "contradictory    5.432806e-11\n",
      "disgust          5.431219e-11\n",
      "harsh            5.430888e-11\n",
      "justification    5.430882e-11\n",
      "punishment       5.430876e-11\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deletion       1.209994e-08\n",
      "zur            0.000000e+00\n",
      "enlighten      0.000000e+00\n",
      "ensures        0.000000e+00\n",
      "ensure         0.000000e+00\n",
      "enrage         0.000000e+00\n",
      "enough         0.000000e+00\n",
      "enormous       0.000000e+00\n",
      "ennumerated    0.000000e+00\n",
      "enjoy          0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54029e101f0241e6bd32fc3234049bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 90.67%, 25 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c629d68d6d47ce9cd469637fff64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 54.55%, avg-accuarcy = 72.61%, 60 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0825f5c8984e1caeb6d5393e151907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "ve         0.000334  0.000191  0.001622  0.000000\n",
      "sense      0.000426  0.001182  0.000000  0.000000\n",
      "maybe      0.000000  0.000906  0.000605  0.000000\n",
      "shot       0.000000  0.000677  0.000000  0.000371\n",
      "that       0.000299  0.000251  0.000241  0.000251\n",
      "kind       0.000000  0.000394  0.000588  0.000000\n",
      "cheap      0.000000  0.000954  0.000000  0.000000\n",
      "embarrass  0.000000  0.000954  0.000000  0.000000\n",
      "fundies    0.000000  0.000954  0.000000  0.000000\n",
      "josh       0.000000  0.000954  0.000000  0.000000\n",
      "mood       0.000000  0.000954  0.000000  0.000000\n",
      "mcdowell   0.000000  0.000954  0.000000  0.000000\n",
      "be         0.000165  0.000224  0.000176  0.000203\n",
      "of         0.000119  0.000248  0.000176  0.000181\n",
      "to         0.000140  0.000208  0.000155  0.000176\n",
      "okay       0.000000  0.000375  0.000293  0.000000\n",
      "except     0.000307  0.000350  0.000000  0.000000\n",
      "who        0.000148  0.000316  0.000030  0.000111\n",
      "but        0.000055  0.000224  0.000197  0.000128\n",
      "have       0.000203  0.000131  0.000132  0.000116\n",
      "enough     0.000163  0.000133  0.000000  0.000267\n",
      "in         0.000133  0.000127  0.000159  0.000141\n",
      "know       0.000111  0.000089  0.000153  0.000047\n",
      "by         0.000070  0.000057  0.000077  0.000072\n",
      "few        0.000034  0.000022  0.000042  0.000071\n",
      "true       0.000036  0.000038  0.000019  0.000019\n",
      "true except that i ve know few fundies who have enough sense to be embarrass by josh mcdowell okay maybe a cheap shot but i m in that kind of mood\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.003337  0.000000  0.000834\n",
      "the         0.000517  0.000530  0.000481  0.000611\n",
      "it          0.000522  0.000267  0.000718  0.000488\n",
      "71          0.000000  0.000000  0.000000  0.001833\n",
      "until       0.000000  0.000000  0.000000  0.000917\n",
      "dubbed      0.000000  0.000000  0.000000  0.000917\n",
      "fwiw        0.000000  0.000000  0.000000  0.000917\n",
      "lbj         0.000000  0.000000  0.000000  0.000917\n",
      "mippselled  0.000000  0.000000  0.000000  0.000917\n",
      "page        0.000000  0.000000  0.000000  0.000917\n",
      "sic         0.000000  0.000000  0.000000  0.000917\n",
      "sr          0.000000  0.000000  0.000000  0.000917\n",
      "be          0.000159  0.000215  0.000170  0.000195\n",
      "doug        0.000000  0.000000  0.000438  0.000255\n",
      "who         0.000142  0.000304  0.000029  0.000107\n",
      "also        0.000165  0.000166  0.000000  0.000127\n",
      "one         0.000100  0.000080  0.000046  0.000163\n",
      "he s also the one who dubbed it the sr 71 it be the r 71 until lbj mippselled sic it fwiw doug page\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "file     0.000000  0.000000  0.005275  0.001317\n",
      "yo       0.000000  0.000000  0.000000  0.004052\n",
      "every    0.000000  0.000000  0.000454  0.001607\n",
      "string   0.000000  0.000000  0.000000  0.002026\n",
      "sig      0.000000  0.000000  0.000000  0.002026\n",
      "look     0.000375  0.000033  0.000778  0.000320\n",
      "publish  0.000000  0.000000  0.000000  0.001088\n",
      "plenty   0.000000  0.000000  0.000000  0.001088\n",
      "kiddo    0.000000  0.000000  0.000000  0.001088\n",
      "be       0.000188  0.000255  0.000201  0.000232\n",
      "to       0.000159  0.000237  0.000177  0.000200\n",
      "you      0.000255  0.000192  0.000166  0.000113\n",
      "have     0.000232  0.000150  0.000150  0.000132\n",
      "get      0.000128  0.000051  0.000223  0.000219\n",
      "one      0.000118  0.000095  0.000055  0.000193\n",
      "like     0.000133  0.000072  0.000077  0.000159\n",
      "just     0.000116  0.000059  0.000069  0.000115\n",
      "we       0.000031  0.000075  0.000074  0.000174\n",
      "we publish plenty kiddo you just have to look sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "human      0.000000  0.002433  0.000000  0.000381\n",
      "be         0.000572  0.000774  0.000611  0.000703\n",
      "45g        0.000000  0.000000  0.000000  0.001651\n",
      "sure       0.000000  0.000000  0.000505  0.000851\n",
      "lan        0.000000  0.000000  0.000000  0.000826\n",
      "8g         0.000000  0.000000  0.000000  0.000826\n",
      "9g         0.000000  0.000000  0.000000  0.000826\n",
      "blackout   0.000000  0.000000  0.000000  0.000826\n",
      "clarify    0.000000  0.000000  0.000000  0.000826\n",
      "dive       0.000000  0.000000  0.000000  0.000826\n",
      "pilot      0.000000  0.000000  0.000000  0.000826\n",
      "exceed     0.000000  0.000000  0.000000  0.000826\n",
      "the        0.000155  0.000159  0.000144  0.000183\n",
      "of         0.000103  0.000214  0.000153  0.000157\n",
      "to         0.000121  0.000180  0.000135  0.000152\n",
      "number     0.000048  0.000103  0.000372  0.000053\n",
      "tolerance  0.000000  0.000274  0.000000  0.000293\n",
      "far        0.000276  0.000000  0.000000  0.000290\n",
      "you        0.000193  0.000146  0.000126  0.000086\n",
      "right      0.000249  0.000059  0.000029  0.000172\n",
      "in         0.000115  0.000110  0.000138  0.000122\n",
      "please     0.000023  0.000193  0.000170  0.000090\n",
      "that       0.000130  0.000108  0.000104  0.000109\n",
      "this       0.000081  0.000102  0.000093  0.000119\n",
      "would      0.000123  0.000046  0.000073  0.000128\n",
      "know       0.000096  0.000077  0.000133  0.000041\n",
      "seem       0.000000  0.000145  0.000070  0.000077\n",
      "anybody    0.000064  0.000041  0.000153  0.000030\n",
      "out        0.000067  0.000063  0.000048  0.000029\n",
      "be you sure 45g be the right number a far a i know pilot be blackout in dive that exceed 8g 9g 45g seem to be out of human tolerance would anybody clarify this please lan\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000393  0.000173  0.001017  0.000217\n",
      "day           0.000000  0.000588  0.000000  0.000864\n",
      "any           0.000239  0.000079  0.000694  0.000206\n",
      "do            0.000234  0.000224  0.000367  0.000203\n",
      "lizard        0.000000  0.000921  0.000000  0.000000\n",
      "thelema       0.000000  0.000921  0.000000  0.000000\n",
      "sf            0.000000  0.000921  0.000000  0.000000\n",
      "organization  0.000000  0.000921  0.000000  0.000000\n",
      "official      0.000000  0.000921  0.000000  0.000000\n",
      "lodge         0.000000  0.000921  0.000000  0.000000\n",
      "bay           0.000000  0.000921  0.000000  0.000000\n",
      "an            0.000347  0.000229  0.000239  0.000082\n",
      "the           0.000173  0.000178  0.000161  0.000205\n",
      "of            0.000115  0.000239  0.000170  0.000175\n",
      "93            0.000272  0.000388  0.000000  0.000000\n",
      "have          0.000196  0.000127  0.000127  0.000112\n",
      "address       0.000144  0.000178  0.000215  0.000000\n",
      "these         0.000140  0.000238  0.000097  0.000000\n",
      "this          0.000090  0.000114  0.000104  0.000133\n",
      "would         0.000137  0.000051  0.000081  0.000142\n",
      "mail          0.000026  0.000037  0.000130  0.000075\n",
      "area          0.000063  0.000075  0.000000  0.000063\n",
      "do this organization have an official e mail address these day an address for any of the sf bay area lodge e g thelema would do 93 a lizard\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000452  0.000199  0.001170  0.000250\n",
      "seriously     0.000890  0.000389  0.000000  0.000000\n",
      "4000          0.001060  0.000000  0.000000  0.000000\n",
      "account       0.001060  0.000000  0.000000  0.000000\n",
      "depreciation  0.001060  0.000000  0.000000  0.000000\n",
      "taurus        0.001060  0.000000  0.000000  0.000000\n",
      "repair        0.001060  0.000000  0.000000  0.000000\n",
      "rack          0.001060  0.000000  0.000000  0.000000\n",
      "doubt         0.001060  0.000000  0.000000  0.000000\n",
      "extra         0.001060  0.000000  0.000000  0.000000\n",
      "cost          0.000124  0.000000  0.000194  0.000477\n",
      "you           0.000248  0.000187  0.000162  0.000110\n",
      "in            0.000148  0.000141  0.000177  0.000157\n",
      "do            0.000135  0.000129  0.000211  0.000117\n",
      "that          0.000166  0.000139  0.000134  0.000139\n",
      "an            0.000200  0.000132  0.000137  0.000047\n",
      "would         0.000158  0.000058  0.000094  0.000164\n",
      "up            0.000212  0.000084  0.000034  0.000066\n",
      "year          0.000070  0.000039  0.000065  0.000173\n",
      "over          0.000097  0.000028  0.000034  0.000030\n",
      "do you account for depreciation i seriously doubt that a taurus would rack up an extra 4000 in repair cost over 5 year\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "be       0.000507  0.000687  0.000542  0.000624\n",
      "brought  0.000595  0.000441  0.000000  0.000000\n",
      "you      0.000343  0.000258  0.000223  0.000152\n",
      "ok       0.000604  0.000181  0.000000  0.000151\n",
      "right    0.000442  0.000104  0.000051  0.000304\n",
      "john     0.000433  0.000281  0.000111  0.000000\n",
      "that     0.000230  0.000193  0.000185  0.000193\n",
      "if       0.000137  0.000137  0.000217  0.000159\n",
      "up       0.000293  0.000116  0.000047  0.000091\n",
      "name     0.000191  0.000195  0.000038  0.000079\n",
      "so       0.000155  0.000119  0.000109  0.000064\n",
      "good     0.000121  0.000086  0.000137  0.000031\n",
      "few      0.000052  0.000034  0.000065  0.000110\n",
      "example  0.000051  0.000023  0.000054  0.000028\n",
      "ok if you be so right name a few good example that be brought up john\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.000873  0.000124  0.003023  0.000781\n",
      "help        0.000000  0.000330  0.001958  0.000345\n",
      "for         0.000504  0.000222  0.001304  0.000279\n",
      "several     0.000000  0.000000  0.001029  0.000786\n",
      "it          0.000448  0.000230  0.000617  0.000419\n",
      "via         0.000000  0.000000  0.001130  0.000575\n",
      "found       0.000000  0.000675  0.000000  0.000509\n",
      "be          0.000205  0.000277  0.000219  0.000251\n",
      "offer       0.000335  0.000000  0.000000  0.000541\n",
      "contact     0.000000  0.000417  0.000000  0.000393\n",
      "and         0.000163  0.000217  0.000204  0.000217\n",
      "will        0.000103  0.000330  0.000044  0.000206\n",
      "get         0.000139  0.000055  0.000243  0.000237\n",
      "those       0.000058  0.000402  0.000111  0.000089\n",
      "people      0.000134  0.000136  0.000024  0.000067\n",
      "mail        0.000033  0.000047  0.000167  0.000096\n",
      "appreciate  0.000023  0.000073  0.000105  0.000042\n",
      "again       0.000033  0.000031  0.000017  0.000023\n",
      "found it thanks i get several offer for help i appreciate it and will be contact those people via e mail thanks again\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "moon        0.000000  0.001101  0.000000  0.001325\n",
      "the         0.000544  0.000558  0.000506  0.000643\n",
      "of          0.000240  0.000501  0.000356  0.000367\n",
      "have        0.000411  0.000265  0.000267  0.000234\n",
      "worship     0.000000  0.000964  0.000000  0.000000\n",
      "element     0.000000  0.000964  0.000000  0.000000\n",
      "sabbath     0.000000  0.000964  0.000000  0.000000\n",
      "phase       0.000000  0.000964  0.000000  0.000000\n",
      "originally  0.000000  0.000964  0.000000  0.000000\n",
      "nature      0.000000  0.000964  0.000000  0.000000\n",
      "egyptian    0.000000  0.000964  0.000000  0.000000\n",
      "be          0.000167  0.000226  0.000178  0.000205\n",
      "determine   0.000000  0.000321  0.000341  0.000000\n",
      "and         0.000133  0.000177  0.000166  0.000177\n",
      "in          0.000135  0.000128  0.000161  0.000143\n",
      "that        0.000151  0.000127  0.000122  0.000127\n",
      "early       0.000150  0.000092  0.000000  0.000077\n",
      "by          0.000071  0.000058  0.000078  0.000073\n",
      "heard       0.000028  0.000091  0.000024  0.000098\n",
      "stuff       0.000035  0.000042  0.000019  0.000016\n",
      "i have heard that the sabbath be originally determine by the phase of the moon and have element of moon worship early stuff egyptian in nature\n",
      "==> predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "file       0.000000  0.000000  0.005253  0.001311\n",
      "every      0.000000  0.000000  0.000452  0.001601\n",
      "feel       0.000000  0.000000  0.000000  0.002018\n",
      "be         0.000375  0.000508  0.000401  0.000461\n",
      "day        0.000000  0.000692  0.000000  0.001016\n",
      "could      0.000264  0.000000  0.000293  0.000662\n",
      "wonder     0.000000  0.000000  0.000714  0.000434\n",
      "monthly    0.000000  0.000000  0.000000  0.001083\n",
      "quarterly  0.000000  0.000000  0.000000  0.001083\n",
      "bloat      0.000000  0.000000  0.000000  0.001083\n",
      "28         0.000000  0.000000  0.000000  0.001083\n",
      "post       0.000401  0.000129  0.000000  0.000323\n",
      "the        0.000204  0.000209  0.000189  0.000241\n",
      "rather     0.000000  0.000128  0.000169  0.000380\n",
      "get        0.000128  0.000051  0.000223  0.000218\n",
      "this       0.000106  0.000134  0.000122  0.000157\n",
      "if         0.000101  0.000102  0.000160  0.000117\n",
      "30         0.000161  0.000000  0.000142  0.000094\n",
      "than       0.000041  0.000120  0.000050  0.000094\n",
      "faq        0.000000  0.000067  0.000080  0.000103\n",
      "i be wonder if the faq file could be post quarterly rather than monthly every 28 30 day i get this bloat feel\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "thanks     0.000397  0.000056  0.001375  0.000355\n",
      "be         0.000372  0.000504  0.000397  0.000457\n",
      "explain    0.000000  0.000358  0.000000  0.001189\n",
      "could      0.000262  0.000000  0.000290  0.000657\n",
      "activity   0.000000  0.000000  0.000000  0.001074\n",
      "loss       0.000000  0.000000  0.000000  0.001074\n",
      "alan       0.000000  0.000000  0.000000  0.001074\n",
      "ron        0.000000  0.000000  0.000000  0.001074\n",
      "regularly  0.000000  0.000000  0.000000  0.001074\n",
      "timer      0.000000  0.000000  0.000000  0.001074\n",
      "post       0.000397  0.000128  0.000000  0.000320\n",
      "the        0.000202  0.000207  0.000188  0.000239\n",
      "command    0.000000  0.000000  0.000315  0.000459\n",
      "report     0.000000  0.000000  0.000441  0.000321\n",
      "someone    0.000083  0.000319  0.000000  0.000306\n",
      "in         0.000150  0.000143  0.000179  0.000159\n",
      "this       0.000105  0.000133  0.000121  0.000155\n",
      "what       0.000085  0.000068  0.000085  0.000078\n",
      "interest   0.000000  0.000072  0.000079  0.000081\n",
      "this activity be regularly report in ron s interest post could someone explain what the command loss timer be thanks alan\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.003353  0.000625\n",
      "of          0.000269  0.000561  0.000399  0.000411\n",
      "thanks      0.000266  0.000038  0.000921  0.000238\n",
      "stereo      0.000000  0.000000  0.000000  0.001439\n",
      "planetary   0.000000  0.000000  0.000000  0.001439\n",
      "phobos      0.000000  0.000000  0.000000  0.001340\n",
      "satellite   0.000000  0.000000  0.000000  0.001340\n",
      "mar         0.000000  0.000000  0.000000  0.001340\n",
      "tell        0.000000  0.000000  0.000306  0.001020\n",
      "anyone      0.000262  0.000000  0.000733  0.000307\n",
      "might       0.000000  0.000000  0.000321  0.000896\n",
      "the         0.000271  0.000277  0.000252  0.000320\n",
      "surface     0.000000  0.000000  0.000495  0.000491\n",
      "and         0.000199  0.000265  0.000248  0.000265\n",
      "any         0.000187  0.000062  0.000542  0.000161\n",
      "moon        0.000000  0.000411  0.000000  0.000494\n",
      "in          0.000201  0.000191  0.000240  0.000213\n",
      "deimos      0.000000  0.000000  0.000000  0.000720\n",
      "gifs        0.000000  0.000000  0.000506  0.000175\n",
      "where       0.000135  0.000000  0.000286  0.000234\n",
      "me          0.000094  0.000182  0.000294  0.000036\n",
      "especially  0.000387  0.000000  0.000000  0.000192\n",
      "but         0.000042  0.000169  0.000149  0.000096\n",
      "will        0.000063  0.000201  0.000027  0.000126\n",
      "do          0.000091  0.000088  0.000143  0.000079\n",
      "that        0.000113  0.000095  0.000091  0.000095\n",
      "prefer      0.000071  0.000000  0.000235  0.000080\n",
      "can         0.000066  0.000054  0.000123  0.000099\n",
      "order       0.000193  0.000077  0.000000  0.000066\n",
      "find        0.000079  0.000030  0.000090  0.000019\n",
      "interested  0.000020  0.000014  0.000021  0.000020\n",
      "can anyone tell me where i might find stereo image of planetary and planetary satellite surface gifs prefer but any will do i m especially interested in stereo of the surface of phobos deimos mar and the moon in that order thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "42       0.000502  0.000000  0.001259  0.000000\n",
      "thought  0.000000  0.000000  0.000329  0.001421\n",
      "be       0.000363  0.000492  0.000388  0.000447\n",
      "the      0.000395  0.000404  0.000367  0.000466\n",
      "help     0.000000  0.000195  0.001159  0.000204\n",
      "chip     0.000000  0.000000  0.001302  0.000000\n",
      "really   0.000268  0.000739  0.000237  0.000000\n",
      "that     0.000329  0.000276  0.000265  0.000276\n",
      "on       0.000145  0.000152  0.000413  0.000366\n",
      "it       0.000265  0.000136  0.000365  0.000248\n",
      "could    0.000170  0.000000  0.000189  0.000428\n",
      "hear     0.000000  0.000303  0.000365  0.000097\n",
      "24       0.000000  0.000282  0.000454  0.000000\n",
      "pete     0.000000  0.000000  0.000699  0.000000\n",
      "intel    0.000000  0.000000  0.000699  0.000000\n",
      "reason   0.000000  0.000000  0.000699  0.000000\n",
      "proper   0.000000  0.000000  0.000699  0.000000\n",
      "egg      0.000000  0.000000  0.000699  0.000000\n",
      "stomp    0.000000  0.000000  0.000699  0.000000\n",
      "endian   0.000000  0.000000  0.000699  0.000000\n",
      "war      0.000000  0.000471  0.000173  0.000000\n",
      "value    0.000000  0.000469  0.000173  0.000000\n",
      "break    0.000000  0.000000  0.000220  0.000265\n",
      "side     0.000262  0.000000  0.000222  0.000000\n",
      "you      0.000164  0.000123  0.000107  0.000073\n",
      "but      0.000040  0.000164  0.000145  0.000094\n",
      "get      0.000082  0.000033  0.000144  0.000140\n",
      "write    0.000000  0.000066  0.000196  0.000099\n",
      "some     0.000027  0.000045  0.000169  0.000119\n",
      "their    0.000187  0.000101  0.000028  0.000032\n",
      "so       0.000074  0.000057  0.000052  0.000030\n",
      "out      0.000057  0.000053  0.000041  0.000025\n",
      "hear hear really i thought that the reason it be 42 be that it be really 24 but write a 42 so that on intel chip you could get the proper value pete help stomp out the endian war break some egg on their side\n",
      "==> predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "see       0.000979  0.001563  0.000139  0.000000\n",
      "you       0.000655  0.000493  0.000427  0.000290\n",
      "need      0.000262  0.000000  0.000793  0.000403\n",
      "unless    0.001399  0.000000  0.000000  0.000000\n",
      "hmmmmmmm  0.001399  0.000000  0.000000  0.000000\n",
      "accident  0.001399  0.000000  0.000000  0.000000\n",
      "me        0.000184  0.000354  0.000572  0.000070\n",
      "won       0.000645  0.000395  0.000000  0.000000\n",
      "have      0.000298  0.000192  0.000193  0.000170\n",
      "let       0.000224  0.000309  0.000200  0.000000\n",
      "an        0.000264  0.000174  0.000181  0.000062\n",
      "more      0.000097  0.000104  0.000052  0.000061\n",
      "let me see unless you have an accident you won t need more hmmmmmmm\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000740  0.000326  0.001915  0.000409\n",
      "motorcycle  0.001734  0.000000  0.000000  0.000000\n",
      "mandatory   0.001734  0.000000  0.000000  0.000000\n",
      "drl         0.001734  0.000000  0.000000  0.000000\n",
      "already     0.001038  0.000000  0.000446  0.000000\n",
      "be          0.000300  0.000407  0.000321  0.000369\n",
      "well        0.000068  0.000065  0.000040  0.000045\n",
      "well drl s be already mandatory for motorcycle\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "god       0.000000  0.003608  0.000000  0.000499\n",
      "profit    0.000000  0.000000  0.000000  0.001706\n",
      "the       0.000345  0.000353  0.000320  0.000407\n",
      "twilight  0.000000  0.000000  0.000000  0.000916\n",
      "blare     0.000000  0.000000  0.000000  0.000916\n",
      "bless     0.000000  0.000000  0.000000  0.000916\n",
      "cacs      0.000000  0.000000  0.000000  0.000916\n",
      "caste     0.000000  0.000000  0.000000  0.000916\n",
      "fraering  0.000000  0.000000  0.000000  0.000916\n",
      "freely    0.000000  0.000000  0.000000  0.000916\n",
      "usl       0.000000  0.000000  0.000000  0.000916\n",
      "pgf       0.000000  0.000000  0.000000  0.000916\n",
      "presence  0.000000  0.000000  0.000000  0.000916\n",
      "srl03     0.000000  0.000000  0.000000  0.000916\n",
      "edu       0.000099  0.000000  0.000348  0.000377\n",
      "be        0.000159  0.000215  0.000169  0.000195\n",
      "phil      0.000000  0.000257  0.000000  0.000430\n",
      "it        0.000174  0.000089  0.000239  0.000163\n",
      "and       0.000127  0.000169  0.000158  0.000169\n",
      "right     0.000276  0.000065  0.000032  0.000190\n",
      "in        0.000128  0.000122  0.000153  0.000136\n",
      "from      0.000060  0.000069  0.000096  0.000115\n",
      "even      0.000027  0.000153  0.000054  0.000087\n",
      "by        0.000067  0.000055  0.000074  0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may       0.000021  0.000090  0.000056  0.000031\n",
      "from phil g fraering pgf srl03 cacs usl edu right the profit caste be bless by god and may freely blare it presence in the even twilight\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "help     0.000000  0.000315  0.001873  0.000330\n",
      "the      0.000425  0.000436  0.000395  0.000502\n",
      "rest     0.000000  0.000886  0.000000  0.000424\n",
      "shirt    0.000000  0.001130  0.000000  0.000000\n",
      "night    0.000000  0.001130  0.000000  0.000000\n",
      "delete   0.000000  0.001130  0.000000  0.000000\n",
      "brown    0.000000  0.001130  0.000000  0.000000\n",
      "of       0.000141  0.000293  0.000209  0.000215\n",
      "out      0.000276  0.000259  0.000199  0.000120\n",
      "in       0.000158  0.000150  0.000188  0.000167\n",
      "can      0.000104  0.000085  0.000193  0.000155\n",
      "about    0.000169  0.000113  0.000081  0.000073\n",
      "anybody  0.000088  0.000057  0.000209  0.000041\n",
      "find     0.000124  0.000046  0.000141  0.000030\n",
      "rest delete can anybody out in a p h help out find out about the night of the brown shirt\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000710  0.000312  0.001838  0.000393\n",
      "new         0.001201  0.000000  0.000375  0.000582\n",
      "23          0.000685  0.000000  0.000000  0.001035\n",
      "thermostat  0.001664  0.000000  0.000000  0.000000\n",
      "sound       0.000415  0.000000  0.000242  0.000819\n",
      "you         0.000389  0.000293  0.000254  0.000173\n",
      "do          0.000211  0.000202  0.000331  0.000183\n",
      "that        0.000261  0.000219  0.000211  0.000219\n",
      "can         0.000153  0.000125  0.000284  0.000228\n",
      "say         0.000156  0.000370  0.000136  0.000080\n",
      "how         0.000102  0.000131  0.000086  0.000072\n",
      "again       0.000047  0.000044  0.000024  0.000033\n",
      "you can say that again how do 23 for a new thermostat sound\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.002411  0.000000  0.000602\n",
      "land        0.000000  0.000000  0.000000  0.001753\n",
      "mach        0.000000  0.000000  0.000000  0.001325\n",
      "flight      0.000000  0.000000  0.000000  0.001234\n",
      "head        0.000000  0.000000  0.000000  0.001234\n",
      "military    0.000000  0.000000  0.000000  0.001234\n",
      "of          0.000165  0.000344  0.000245  0.000252\n",
      "new         0.000478  0.000000  0.000149  0.000232\n",
      "could       0.000161  0.000000  0.000179  0.000405\n",
      "handle      0.000000  0.000000  0.000257  0.000474\n",
      "month       0.000000  0.000000  0.000260  0.000459\n",
      "belive      0.000000  0.000000  0.000000  0.000662\n",
      "boom        0.000000  0.000000  0.000000  0.000662\n",
      "decent      0.000000  0.000000  0.000000  0.000662\n",
      "direction   0.000000  0.000000  0.000000  0.000662\n",
      "fran        0.000000  0.000000  0.000000  0.000662\n",
      "aircraft    0.000000  0.000000  0.000000  0.000662\n",
      "25aircraft  0.000000  0.000000  0.000000  0.000662\n",
      "int         0.000000  0.000000  0.000000  0.000662\n",
      "25          0.000000  0.000000  0.000000  0.000662\n",
      "san         0.000000  0.000000  0.000000  0.000662\n",
      "odd         0.000000  0.000000  0.000000  0.000662\n",
      "supersonic  0.000000  0.000000  0.000000  0.000662\n",
      "super       0.000000  0.000000  0.000436  0.000165\n",
      "be          0.000115  0.000155  0.000123  0.000141\n",
      "the         0.000125  0.000128  0.000116  0.000147\n",
      "on          0.000069  0.000072  0.000196  0.000173\n",
      "ago         0.000053  0.000071  0.000048  0.000323\n",
      "it          0.000126  0.000064  0.000173  0.000118\n",
      "question    0.000086  0.000294  0.000043  0.000035\n",
      "east        0.000000  0.000222  0.000000  0.000232\n",
      "what        0.000105  0.000084  0.000104  0.000096\n",
      "hear        0.000000  0.000144  0.000173  0.000046\n",
      "that        0.000104  0.000087  0.000084  0.000087\n",
      "there       0.000113  0.000040  0.000062  0.000139\n",
      "some        0.000026  0.000043  0.000160  0.000113\n",
      "speed       0.000118  0.000000  0.000069  0.000051\n",
      "heard       0.000019  0.000062  0.000017  0.000067\n",
      "base        0.000015  0.000048  0.000024  0.000065\n",
      "over        0.000061  0.000018  0.000021  0.000019\n",
      "few         0.000024  0.000015  0.000029  0.000050\n",
      "the supersonic boom hear a few month ago over i belive san fran head east of what i heard some new super speed mach 25 aircraft what military base int he direction of flight be there that could handle a mach 25aircraft on it land decent odd question\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                  autos  religion  graphics     space\n",
      "try            0.000000  0.000329  0.004991  0.001203\n",
      "he             0.000000  0.002812  0.000000  0.000703\n",
      "thought        0.000000  0.000000  0.000363  0.001570\n",
      "be             0.000268  0.000362  0.000286  0.000329\n",
      "to             0.000226  0.000336  0.000252  0.000285\n",
      "win            0.000000  0.000000  0.000000  0.000773\n",
      "consideration  0.000000  0.000000  0.000000  0.000773\n",
      "sam            0.000000  0.000000  0.000000  0.000773\n",
      "ross           0.000000  0.000000  0.000000  0.000773\n",
      "perot          0.000000  0.000000  0.000000  0.000773\n",
      "disappoint     0.000000  0.000000  0.000000  0.000773\n",
      "further        0.000000  0.000000  0.000000  0.000773\n",
      "matt           0.000000  0.000000  0.000000  0.000773\n",
      "likely         0.000000  0.000000  0.000000  0.000773\n",
      "walton         0.000000  0.000000  0.000000  0.000773\n",
      "gate           0.000000  0.000000  0.000000  0.000773\n",
      "after          0.000414  0.000091  0.000000  0.000187\n",
      "it             0.000147  0.000075  0.000202  0.000137\n",
      "bill           0.000000  0.000301  0.000000  0.000239\n",
      "third          0.000282  0.000000  0.000000  0.000250\n",
      "kid            0.000000  0.000256  0.000000  0.000274\n",
      "but            0.000045  0.000182  0.000160  0.000103\n",
      "my             0.000224  0.000105  0.000045  0.000086\n",
      "in             0.000108  0.000103  0.000129  0.000114\n",
      "first          0.000076  0.000175  0.000041  0.000029\n",
      "think          0.000107  0.000054  0.000065  0.000018\n",
      "more           0.000054  0.000057  0.000029  0.000034\n",
      "come           0.000024  0.000019  0.000050  0.000060\n",
      "my first thought be ross perot after further consideration i think he d be more likely to try to win it but come in a disappoint third try bill gate try sam walton s kid matt\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "to    0.000505  0.000751  0.000563  0.000636\n",
      "know  0.000402  0.000322  0.000555  0.000171\n",
      "just  0.000370  0.000188  0.000218  0.000366\n",
      "want  0.000256  0.000173  0.000163  0.000111\n",
      "i just want to know\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "it         0.000610  0.000313  0.000839  0.000571\n",
      "be         0.000278  0.000377  0.000297  0.000342\n",
      "gee        0.000272  0.000000  0.000000  0.000856\n",
      "look       0.000277  0.000024  0.000574  0.000237\n",
      "you        0.000376  0.000283  0.000245  0.000167\n",
      "any        0.000209  0.000069  0.000605  0.000180\n",
      "release    0.000469  0.000000  0.000342  0.000000\n",
      "tion       0.000804  0.000000  0.000000  0.000000\n",
      "radia      0.000804  0.000000  0.000000  0.000000\n",
      "confuse    0.000804  0.000000  0.000000  0.000000\n",
      "genus      0.000804  0.000000  0.000000  0.000000\n",
      "hole       0.000804  0.000000  0.000000  0.000000\n",
      "locate     0.000804  0.000000  0.000000  0.000000\n",
      "tor        0.000804  0.000000  0.000000  0.000000\n",
      "radiation  0.000804  0.000000  0.000000  0.000000\n",
      "radiator   0.000804  0.000000  0.000000  0.000000\n",
      "punch      0.000804  0.000000  0.000000  0.000000\n",
      "where      0.000150  0.000000  0.000319  0.000262\n",
      "really     0.000154  0.000425  0.000136  0.000000\n",
      "sound      0.000200  0.000000  0.000117  0.000396\n",
      "me         0.000106  0.000204  0.000328  0.000040\n",
      "like       0.000197  0.000106  0.000114  0.000235\n",
      "what       0.000128  0.000102  0.000127  0.000117\n",
      "will       0.000070  0.000225  0.000030  0.000140\n",
      "do         0.000102  0.000098  0.000160  0.000088\n",
      "when       0.000041  0.000172  0.000039  0.000083\n",
      "since      0.000074  0.000065  0.000114  0.000000\n",
      "make       0.000051  0.000059  0.000031  0.000028\n",
      "gee you really make me confuse what be radiator where be it locate what do it look like will it release any radiation since it sound like radia tion genus tor when you punch hole\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "file      0.000000  0.000000  0.003935  0.000982\n",
      "yo        0.000000  0.000000  0.000000  0.003023\n",
      "assume    0.000000  0.000000  0.000000  0.002742\n",
      "be        0.000421  0.000571  0.000450  0.000518\n",
      "every     0.000000  0.000000  0.000339  0.001199\n",
      "string    0.000000  0.000000  0.000000  0.001512\n",
      "sig       0.000000  0.000000  0.000000  0.001512\n",
      "mining    0.000000  0.000000  0.000000  0.001512\n",
      "you       0.000380  0.000286  0.000248  0.000168\n",
      "cash      0.000000  0.000000  0.000000  0.000812\n",
      "limit     0.000000  0.000000  0.000000  0.000812\n",
      "award     0.000000  0.000000  0.000000  0.000812\n",
      "to        0.000119  0.000177  0.000132  0.000149\n",
      "away      0.000306  0.000000  0.000000  0.000257\n",
      "own       0.000000  0.000261  0.000000  0.000299\n",
      "ok        0.000335  0.000100  0.000000  0.000083\n",
      "right     0.000245  0.000058  0.000028  0.000169\n",
      "get       0.000096  0.000038  0.000167  0.000163\n",
      "there     0.000138  0.000049  0.000076  0.000170\n",
      "can       0.000075  0.000061  0.000138  0.000111\n",
      "them      0.000018  0.000142  0.000078  0.000142\n",
      "would     0.000121  0.000045  0.000072  0.000125\n",
      "one       0.000088  0.000071  0.000041  0.000144\n",
      "like      0.000099  0.000053  0.000058  0.000119\n",
      "because   0.000066  0.000122  0.000000  0.000130\n",
      "don       0.000044  0.000086  0.000057  0.000043\n",
      "anything  0.000030  0.000019  0.000036  0.000088\n",
      "give      0.000056  0.000046  0.000044  0.000014\n",
      "time      0.000023  0.000025  0.000046  0.000045\n",
      "mine      0.000022  0.000020  0.000024  0.000054\n",
      "nice      0.000013  0.000011  0.000013  0.000013\n",
      "a cash award be ok a time limit would be nice you can t give away mining right assume there s anything to mine because you don t own them sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "get     0.000358  0.000143  0.000625  0.000611\n",
      "life    0.000587  0.000170  0.000000  0.000775\n",
      "people  0.000346  0.000350  0.000062  0.000173\n",
      "people get a life\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.004100  0.000764\n",
      "site        0.000000  0.000000  0.001891  0.000881\n",
      "ftp         0.000000  0.000000  0.001515  0.000650\n",
      "the         0.000497  0.000509  0.000461  0.000587\n",
      "thanks      0.000325  0.000046  0.001126  0.000291\n",
      "phobos      0.000000  0.000000  0.000000  0.001639\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001639\n",
      "russian     0.000000  0.000000  0.000000  0.001639\n",
      "house       0.000000  0.000000  0.000000  0.001639\n",
      "anyone      0.000321  0.000000  0.000897  0.000375\n",
      "any         0.000229  0.000076  0.000663  0.000197\n",
      "moon        0.000000  0.000502  0.000000  0.000605\n",
      "do          0.000223  0.000214  0.000350  0.000194\n",
      "fat         0.000000  0.000000  0.000000  0.000880\n",
      "ill         0.000000  0.000000  0.000000  0.000880\n",
      "martian     0.000000  0.000000  0.000000  0.000880\n",
      "mission     0.000000  0.000000  0.000000  0.000880\n",
      "if          0.000164  0.000165  0.000260  0.000191\n",
      "on          0.000091  0.000096  0.000260  0.000230\n",
      "of          0.000110  0.000228  0.000163  0.000167\n",
      "ago         0.000070  0.000094  0.000064  0.000429\n",
      "back        0.000245  0.000093  0.000000  0.000139\n",
      "an          0.000166  0.000110  0.000114  0.000039\n",
      "they        0.000139  0.000066  0.000048  0.000130\n",
      "send        0.000176  0.000000  0.000076  0.000120\n",
      "know        0.000102  0.000082  0.000141  0.000044\n",
      "year        0.000058  0.000032  0.000054  0.000144\n",
      "so          0.000093  0.000071  0.000066  0.000038\n",
      "re          0.000049  0.000092  0.000018  0.000102\n",
      "at          0.000047  0.000048  0.000077  0.000062\n",
      "few         0.000031  0.000021  0.000039  0.000066\n",
      "do the russian spacecraft s on the ill fat phobos mission a few year ago send back any image of the martian moon if so do anyone know if they re house at an ftp site thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"==> predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuarcy = 100.00%, test_accuarcy = 62.88%, avg-accuarcy = 81.44%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_doc_vectors, train_labels)\n",
    "\n",
    "train_accuracy = clf.score(train_doc_vectors, train_labels)\n",
    "test_accuracy = clf.score(test_doc_vectors, test_labels)\n",
    "\n",
    "print(f\"training_accuarcy = {train_accuracy*100:.2f}%, test_accuarcy = {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
