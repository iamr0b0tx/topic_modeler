{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f10874c8ce4db78d544b80a92e0ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apparently you re not a woman my husband hate the auto door lock feel safer in a car that lock easily in addition to watching around in a secluded spot etc have my key ready to open the door so i m\n"
     ]
    }
   ],
   "source": [
    "datasize = 100\n",
    "max_document_length = 256\n",
    "\n",
    "index = -1\n",
    "clean_docs = []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) != len(categories)*datasize:\n",
    "        index += 1\n",
    "        size_index = categories.index(classes[labels[index]])\n",
    "        \n",
    "        if sizes[size_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = docs[index]\n",
    "        status, doc, word_count = clean_doc(doc)\n",
    "        \n",
    "        if (not status) or (max_document_length is not None and len(doc) > max_document_length):\n",
    "            continue\n",
    "\n",
    "        clean_docs.append(doc)\n",
    "        sizes[size_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(clean_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 400 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 2318\n"
     ]
    }
   ],
   "source": [
    "# mode = \"tfidf\"\n",
    "# mode = \"binary\"\n",
    "# mode = \"normalize\"\n",
    "# mode = \"binary-normalize\"\n",
    "mode = \"pmi\"\n",
    "\n",
    "# initialize the count vectorizer\n",
    "vectorizer = TfidfVectorizer() if mode == \"tfidf\" else CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "train_docs, test_docs = train_test_split(clean_docs, test_size=.33, random_state=42)\n",
    "\n",
    "vectorizer.fit(train_docs)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 train_docs, 132 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(train_docs).toarray()\n",
    "test_doc_vectors = vectorizer.transform(test_docs).toarray()\n",
    "\n",
    "if mode in [\"binary-normalize\", \"binary\", \"pmi\"]:\n",
    "    train_doc_vectors = (train_doc_vectors > 0).astype(float)\n",
    "    test_doc_vectors = (test_doc_vectors > 0).astype(float)\n",
    "    \n",
    "if mode == \"normalize\" or mode == \"binary-normalize\":\n",
    "    train_doc_vectors = normalize(train_doc_vectors, norm=\"l1\", axis=1)\n",
    "    test_doc_vectors = normalize(test_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "print(f\"{len(train_doc_vectors)} train_docs, {len(test_doc_vectors)} test docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6042c3655d7447bb91c19510cca4f85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\christian\\Documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\utils.py:15: RuntimeWarning: overflow encountered in power\n",
      "  return 1 / (1 + (np.e**-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_co has shape (2318, 2318)\n"
     ]
    }
   ],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "p = pd.DataFrame((train_doc_vectors.sum(0) / len(train_doc_vectors)), columns=[0], index=vocabulary)[0]\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = word_doc_freqency[word_doc_freqency[word] == 1].sum(0) / len(train_doc_vectors)\n",
    "    word_word_co[word] = sigmoid(np.nan_to_num(np.log2(pxy / (p[word] * p))))\n",
    "\n",
    "# word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #reduce freq in doc to bin value of 1 or 0\n",
    "# word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "# #the sum vertically of bin freq\n",
    "# word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "# word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "# word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     word_word_frequency = word_doc_freqency[word_doc_freqency[word] > 0].sum(0)\n",
    "#     word_word_co[word] = ((word_word_frequency * word_frequency_norm) / word_doc_total_frequency).fillna(0)\n",
    "\n",
    "# # word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>013846</th>\n",
       "      <th>020359</th>\n",
       "      <th>077</th>\n",
       "      <th>0a</th>\n",
       "      <th>0x100</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10k</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.99847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.99847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>013846</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>020359</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>077</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0a</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000    013846    020359       077        0a    0x100   10  100  \\\n",
       "000     0.99847  0.000000  0.000000  0.000000  0.000000  0.99847  0.0  0.0   \n",
       "013846  0.00000  0.999686  0.000000  0.000000  0.000000  0.00000  0.0  0.0   \n",
       "020359  0.00000  0.000000  0.999686  0.000000  0.000000  0.00000  0.0  0.0   \n",
       "077     0.00000  0.000000  0.000000  0.999686  0.000000  0.00000  0.0  0.0   \n",
       "0a      0.00000  0.000000  0.000000  0.000000  0.999686  0.00000  0.0  0.0   \n",
       "\n",
       "        10k   12  ...  yeah  year  yellow  yes  yet   yo       you  your  \\\n",
       "000     0.0  0.0  ...   0.0   0.0     0.0  0.0  0.0  0.0  0.592088   0.0   \n",
       "013846  0.0  0.0  ...   0.0   0.0     0.0  0.0  0.0  0.0  0.876269   0.0   \n",
       "020359  0.0  0.0  ...   0.0   0.0     0.0  0.0  0.0  0.0  0.000000   0.0   \n",
       "077     0.0  0.0  ...   0.0   0.0     0.0  0.0  0.0  0.0  0.000000   0.0   \n",
       "0a      0.0  0.0  ...   0.0   0.0     0.0  0.0  0.0  0.0  0.000000   0.0   \n",
       "\n",
       "        yuan  zip  \n",
       "000      0.0  0.0  \n",
       "013846   0.0  0.0  \n",
       "020359   0.0  0.0  \n",
       "077      0.0  0.0  \n",
       "0a       0.0  0.0  \n",
       "\n",
       "[5 rows x 2318 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Word Trust ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor = pd.DataFrame(data=gaussian2(word_entropy), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"look\", \"algorithm\", \"program\"]\n",
    "# words = [\"looking\", \"algorithm\", \"program\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.set_title(f\"Word Trust factor {word} against TOPICS\")\n",
    "ax1.bar(words, (word_trust_factor)[words])\n",
    "\n",
    "ax2.set_title(f\"Word Frequency Normalized {word} against TOPICS\")\n",
    "ax2.bar(words, word_frequency_norm[words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"software\"\n",
    "words = [\"car\", \"god\", \"file\", \"nasa\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "plt.title(f\"word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fashion         0.997685\n",
       "generate        0.997685\n",
       "analysis        0.997685\n",
       "chad            0.997685\n",
       "animation       0.997685\n",
       "filmrecorder    0.997685\n",
       "coreldraw       0.997685\n",
       "cdr             0.997685\n",
       "hava            0.997685\n",
       "convert         0.997685\n",
       "ge              0.997685\n",
       "paint           0.997685\n",
       "million         0.997685\n",
       "containing      0.997685\n",
       "analyze         0.997685\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with gaussian entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_word_co = (word_word_co + (word_word_co * word_word_co.T)) * word_trust_factor\n",
    "word_word_co = (word_word_co * word_trust_factor)\n",
    "word_word_co = (word_word_co.T / word_word_co.sum(1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"Updated word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bureau            0.032746\n",
       "filmrecorder      0.032746\n",
       "coreldraw         0.032746\n",
       "bitmap            0.032746\n",
       "cdr               0.032746\n",
       "scodal            0.032746\n",
       "convert           0.032746\n",
       "recognises        0.032746\n",
       "containing        0.032746\n",
       "fashion           0.032588\n",
       "ge                0.032588\n",
       "million           0.032588\n",
       "recommendation    0.032588\n",
       "professional      0.032588\n",
       "pattern           0.027876\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy2 = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor2 = pd.DataFrame(data=gaussian2(word_entropy2), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with word_word_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wwc = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     for other_word in vocabulary:\n",
    "#         ratios = word_word_co.loc[word][other_word] * word_word_co.loc[other_word]\n",
    "#         wwc.loc[word][ratios > wwc.loc[word]] = ratios[ratios > wwc.loc[word]]\n",
    "\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a479ffb4a5c4860928c71f127d1a47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "doc_word_distr has shape (268, 2318)\n"
     ]
    }
   ],
   "source": [
    "doc_word_distr = pd.DataFrame(data=0.0, columns=vocabulary, index=word_doc_freqency.index)\n",
    "\n",
    "for doc_index in tqdm(range(len(train_doc_vectors))):\n",
    "    doc_word_distr.loc[doc_index] = (word_word_co * train_doc_vectors[0]).max(1)\n",
    "\n",
    "print(f\"doc_word_distr has shape {doc_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 2318)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      268.0\n",
       "1      268.0\n",
       "2      268.0\n",
       "3      268.0\n",
       "4      268.0\n",
       "       ...  \n",
       "263    268.0\n",
       "264    268.0\n",
       "265    268.0\n",
       "266    268.0\n",
       "267    268.0\n",
       "Length: 268, dtype: float64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(doc_word_distr)\n",
    "dds = pd.DataFrame(cosine_similarity(doc_word_distr), columns=range(size), index=range(size))\n",
    "dds.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Latent partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_word_distr_params has shape (2318, 4)\n"
     ]
    }
   ],
   "source": [
    "num_of_components = 4\n",
    "\n",
    "pca = PCA(n_components=num_of_components)\n",
    "result = pca.fit_transform(doc_word_distr.T)\n",
    "\n",
    "word_word_distr_params = pd.DataFrame(data=result, columns=list(range(num_of_components)), index=vocabulary)\n",
    "\n",
    "# word_word_distr_params = sigmoid(word_word_distr_params)\n",
    "# word_word_distr_params = (word_word_distr_params.T / word_word_distr_params.sum(1)).T\n",
    "\n",
    "# we = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_distr_params.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "# wtf = pd.DataFrame(data=gaussian2(we), columns=[0], index=vocabulary)[0]\n",
    "# word_word_distr_params = (word_word_distr_params.T * wtf).T\n",
    "\n",
    "print(f\"word_word_distr_params has shape {word_word_distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_word_distr_params has shape (2318, 2)\n"
     ]
    }
   ],
   "source": [
    "word_word_distr_params = pd.DataFrame(data=np.array([doc_word_distr.mean(0), doc_word_distr.std(0)]).T, columns=[\"mean\", \"std\"], index=vocabulary)\n",
    "\n",
    "print(f\"word_word_distr_params has shape {word_word_distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>013846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>020359</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean  std\n",
       "000      0.0  0.0\n",
       "013846   0.0  0.0\n",
       "020359   0.0  0.0\n",
       "077      0.0  0.0\n",
       "0a       0.0  0.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_distr_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-3bec508e0052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_word_distr_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "word_word_distr_params[2].sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_word_distr_params[1].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Kmeans to cluster the word_distr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_doc_frequency' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-241-9c9281b11360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_of_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkmeans_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_of_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_doc_frequency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, word_trust_factor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_doc_frequency' is not defined"
     ]
    }
   ],
   "source": [
    "num_of_topics = 4\n",
    "kmeans_model = KMeans(n_clusters=num_of_topics, random_state=0).fit()#, word_trust_factor)\n",
    "kmeans_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist has shape (268, 4)\n"
     ]
    }
   ],
   "source": [
    "dist = kmeans_model.transform(doc_word_distr)\n",
    "# dist = normalize(dist, norm='l1', axis=0)\n",
    "# dist = normalize(dist, norm='l1', axis=1)\n",
    "print(f\"dist has shape {dist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top(topic):\n",
    "    word_indices = dist[:, topic].argsort()\n",
    "    print(word_word_distr_params.iloc[word_indices].head(20))\n",
    "    \n",
    "#     word_indices = np.where(kmeans_model.labels_ == topic)[0]\n",
    "#     print(wtf.iloc[word_indices].sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mean  std\n",
      "000         0.0  0.0\n",
      "alignment   0.0  0.0\n",
      "all         0.0  0.0\n",
      "alleged     0.0  0.0\n",
      "allen       0.0  0.0\n",
      "alley       0.0  0.0\n",
      "allow       0.0  0.0\n",
      "allows      0.0  0.0\n",
      "almost      0.0  0.0\n",
      "alot        0.0  0.0\n",
      "aloud       0.0  0.0\n",
      "already     0.0  0.0\n",
      "also        0.0  0.0\n",
      "alt         0.0  0.0\n",
      "always      0.0  0.0\n",
      "am          0.0  0.0\n",
      "amazing     0.0  0.0\n",
      "america     0.0  0.0\n",
      "amiga       0.0  0.0\n",
      "ammended    0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "get_top(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mean  std\n",
      "000         0.0  0.0\n",
      "alignment   0.0  0.0\n",
      "all         0.0  0.0\n",
      "alleged     0.0  0.0\n",
      "allen       0.0  0.0\n",
      "alley       0.0  0.0\n",
      "allow       0.0  0.0\n",
      "allows      0.0  0.0\n",
      "almost      0.0  0.0\n",
      "alot        0.0  0.0\n",
      "aloud       0.0  0.0\n",
      "already     0.0  0.0\n",
      "also        0.0  0.0\n",
      "alt         0.0  0.0\n",
      "always      0.0  0.0\n",
      "am          0.0  0.0\n",
      "amazing     0.0  0.0\n",
      "america     0.0  0.0\n",
      "amiga       0.0  0.0\n",
      "ammended    0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "get_top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mean  std\n",
      "000         0.0  0.0\n",
      "alignment   0.0  0.0\n",
      "all         0.0  0.0\n",
      "alleged     0.0  0.0\n",
      "allen       0.0  0.0\n",
      "alley       0.0  0.0\n",
      "allow       0.0  0.0\n",
      "allows      0.0  0.0\n",
      "almost      0.0  0.0\n",
      "alot        0.0  0.0\n",
      "aloud       0.0  0.0\n",
      "already     0.0  0.0\n",
      "also        0.0  0.0\n",
      "alt         0.0  0.0\n",
      "always      0.0  0.0\n",
      "am          0.0  0.0\n",
      "amazing     0.0  0.0\n",
      "america     0.0  0.0\n",
      "amiga       0.0  0.0\n",
      "ammended    0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "get_top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mean  std\n",
      "000         0.0  0.0\n",
      "alignment   0.0  0.0\n",
      "all         0.0  0.0\n",
      "alleged     0.0  0.0\n",
      "allen       0.0  0.0\n",
      "alley       0.0  0.0\n",
      "allow       0.0  0.0\n",
      "allows      0.0  0.0\n",
      "almost      0.0  0.0\n",
      "alot        0.0  0.0\n",
      "aloud       0.0  0.0\n",
      "already     0.0  0.0\n",
      "also        0.0  0.0\n",
      "alt         0.0  0.0\n",
      "always      0.0  0.0\n",
      "am          0.0  0.0\n",
      "amazing     0.0  0.0\n",
      "america     0.0  0.0\n",
      "amiga       0.0  0.0\n",
      "ammended    0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "get_top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54029e101f0241e6bd32fc3234049bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 90.67%, 25 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c629d68d6d47ce9cd469637fff64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 54.55%, avg-accuarcy = 72.61%, 60 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0825f5c8984e1caeb6d5393e151907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "ve         0.000334  0.000191  0.001622  0.000000\n",
      "sense      0.000426  0.001182  0.000000  0.000000\n",
      "maybe      0.000000  0.000906  0.000605  0.000000\n",
      "shot       0.000000  0.000677  0.000000  0.000371\n",
      "that       0.000299  0.000251  0.000241  0.000251\n",
      "kind       0.000000  0.000394  0.000588  0.000000\n",
      "cheap      0.000000  0.000954  0.000000  0.000000\n",
      "embarrass  0.000000  0.000954  0.000000  0.000000\n",
      "fundies    0.000000  0.000954  0.000000  0.000000\n",
      "josh       0.000000  0.000954  0.000000  0.000000\n",
      "mood       0.000000  0.000954  0.000000  0.000000\n",
      "mcdowell   0.000000  0.000954  0.000000  0.000000\n",
      "be         0.000165  0.000224  0.000176  0.000203\n",
      "of         0.000119  0.000248  0.000176  0.000181\n",
      "to         0.000140  0.000208  0.000155  0.000176\n",
      "okay       0.000000  0.000375  0.000293  0.000000\n",
      "except     0.000307  0.000350  0.000000  0.000000\n",
      "who        0.000148  0.000316  0.000030  0.000111\n",
      "but        0.000055  0.000224  0.000197  0.000128\n",
      "have       0.000203  0.000131  0.000132  0.000116\n",
      "enough     0.000163  0.000133  0.000000  0.000267\n",
      "in         0.000133  0.000127  0.000159  0.000141\n",
      "know       0.000111  0.000089  0.000153  0.000047\n",
      "by         0.000070  0.000057  0.000077  0.000072\n",
      "few        0.000034  0.000022  0.000042  0.000071\n",
      "true       0.000036  0.000038  0.000019  0.000019\n",
      "true except that i ve know few fundies who have enough sense to be embarrass by josh mcdowell okay maybe a cheap shot but i m in that kind of mood\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.003337  0.000000  0.000834\n",
      "the         0.000517  0.000530  0.000481  0.000611\n",
      "it          0.000522  0.000267  0.000718  0.000488\n",
      "71          0.000000  0.000000  0.000000  0.001833\n",
      "until       0.000000  0.000000  0.000000  0.000917\n",
      "dubbed      0.000000  0.000000  0.000000  0.000917\n",
      "fwiw        0.000000  0.000000  0.000000  0.000917\n",
      "lbj         0.000000  0.000000  0.000000  0.000917\n",
      "mippselled  0.000000  0.000000  0.000000  0.000917\n",
      "page        0.000000  0.000000  0.000000  0.000917\n",
      "sic         0.000000  0.000000  0.000000  0.000917\n",
      "sr          0.000000  0.000000  0.000000  0.000917\n",
      "be          0.000159  0.000215  0.000170  0.000195\n",
      "doug        0.000000  0.000000  0.000438  0.000255\n",
      "who         0.000142  0.000304  0.000029  0.000107\n",
      "also        0.000165  0.000166  0.000000  0.000127\n",
      "one         0.000100  0.000080  0.000046  0.000163\n",
      "he s also the one who dubbed it the sr 71 it be the r 71 until lbj mippselled sic it fwiw doug page\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "file     0.000000  0.000000  0.005275  0.001317\n",
      "yo       0.000000  0.000000  0.000000  0.004052\n",
      "every    0.000000  0.000000  0.000454  0.001607\n",
      "string   0.000000  0.000000  0.000000  0.002026\n",
      "sig      0.000000  0.000000  0.000000  0.002026\n",
      "look     0.000375  0.000033  0.000778  0.000320\n",
      "publish  0.000000  0.000000  0.000000  0.001088\n",
      "plenty   0.000000  0.000000  0.000000  0.001088\n",
      "kiddo    0.000000  0.000000  0.000000  0.001088\n",
      "be       0.000188  0.000255  0.000201  0.000232\n",
      "to       0.000159  0.000237  0.000177  0.000200\n",
      "you      0.000255  0.000192  0.000166  0.000113\n",
      "have     0.000232  0.000150  0.000150  0.000132\n",
      "get      0.000128  0.000051  0.000223  0.000219\n",
      "one      0.000118  0.000095  0.000055  0.000193\n",
      "like     0.000133  0.000072  0.000077  0.000159\n",
      "just     0.000116  0.000059  0.000069  0.000115\n",
      "we       0.000031  0.000075  0.000074  0.000174\n",
      "we publish plenty kiddo you just have to look sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "human      0.000000  0.002433  0.000000  0.000381\n",
      "be         0.000572  0.000774  0.000611  0.000703\n",
      "45g        0.000000  0.000000  0.000000  0.001651\n",
      "sure       0.000000  0.000000  0.000505  0.000851\n",
      "lan        0.000000  0.000000  0.000000  0.000826\n",
      "8g         0.000000  0.000000  0.000000  0.000826\n",
      "9g         0.000000  0.000000  0.000000  0.000826\n",
      "blackout   0.000000  0.000000  0.000000  0.000826\n",
      "clarify    0.000000  0.000000  0.000000  0.000826\n",
      "dive       0.000000  0.000000  0.000000  0.000826\n",
      "pilot      0.000000  0.000000  0.000000  0.000826\n",
      "exceed     0.000000  0.000000  0.000000  0.000826\n",
      "the        0.000155  0.000159  0.000144  0.000183\n",
      "of         0.000103  0.000214  0.000153  0.000157\n",
      "to         0.000121  0.000180  0.000135  0.000152\n",
      "number     0.000048  0.000103  0.000372  0.000053\n",
      "tolerance  0.000000  0.000274  0.000000  0.000293\n",
      "far        0.000276  0.000000  0.000000  0.000290\n",
      "you        0.000193  0.000146  0.000126  0.000086\n",
      "right      0.000249  0.000059  0.000029  0.000172\n",
      "in         0.000115  0.000110  0.000138  0.000122\n",
      "please     0.000023  0.000193  0.000170  0.000090\n",
      "that       0.000130  0.000108  0.000104  0.000109\n",
      "this       0.000081  0.000102  0.000093  0.000119\n",
      "would      0.000123  0.000046  0.000073  0.000128\n",
      "know       0.000096  0.000077  0.000133  0.000041\n",
      "seem       0.000000  0.000145  0.000070  0.000077\n",
      "anybody    0.000064  0.000041  0.000153  0.000030\n",
      "out        0.000067  0.000063  0.000048  0.000029\n",
      "be you sure 45g be the right number a far a i know pilot be blackout in dive that exceed 8g 9g 45g seem to be out of human tolerance would anybody clarify this please lan\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000393  0.000173  0.001017  0.000217\n",
      "day           0.000000  0.000588  0.000000  0.000864\n",
      "any           0.000239  0.000079  0.000694  0.000206\n",
      "do            0.000234  0.000224  0.000367  0.000203\n",
      "lizard        0.000000  0.000921  0.000000  0.000000\n",
      "thelema       0.000000  0.000921  0.000000  0.000000\n",
      "sf            0.000000  0.000921  0.000000  0.000000\n",
      "organization  0.000000  0.000921  0.000000  0.000000\n",
      "official      0.000000  0.000921  0.000000  0.000000\n",
      "lodge         0.000000  0.000921  0.000000  0.000000\n",
      "bay           0.000000  0.000921  0.000000  0.000000\n",
      "an            0.000347  0.000229  0.000239  0.000082\n",
      "the           0.000173  0.000178  0.000161  0.000205\n",
      "of            0.000115  0.000239  0.000170  0.000175\n",
      "93            0.000272  0.000388  0.000000  0.000000\n",
      "have          0.000196  0.000127  0.000127  0.000112\n",
      "address       0.000144  0.000178  0.000215  0.000000\n",
      "these         0.000140  0.000238  0.000097  0.000000\n",
      "this          0.000090  0.000114  0.000104  0.000133\n",
      "would         0.000137  0.000051  0.000081  0.000142\n",
      "mail          0.000026  0.000037  0.000130  0.000075\n",
      "area          0.000063  0.000075  0.000000  0.000063\n",
      "do this organization have an official e mail address these day an address for any of the sf bay area lodge e g thelema would do 93 a lizard\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000452  0.000199  0.001170  0.000250\n",
      "seriously     0.000890  0.000389  0.000000  0.000000\n",
      "4000          0.001060  0.000000  0.000000  0.000000\n",
      "account       0.001060  0.000000  0.000000  0.000000\n",
      "depreciation  0.001060  0.000000  0.000000  0.000000\n",
      "taurus        0.001060  0.000000  0.000000  0.000000\n",
      "repair        0.001060  0.000000  0.000000  0.000000\n",
      "rack          0.001060  0.000000  0.000000  0.000000\n",
      "doubt         0.001060  0.000000  0.000000  0.000000\n",
      "extra         0.001060  0.000000  0.000000  0.000000\n",
      "cost          0.000124  0.000000  0.000194  0.000477\n",
      "you           0.000248  0.000187  0.000162  0.000110\n",
      "in            0.000148  0.000141  0.000177  0.000157\n",
      "do            0.000135  0.000129  0.000211  0.000117\n",
      "that          0.000166  0.000139  0.000134  0.000139\n",
      "an            0.000200  0.000132  0.000137  0.000047\n",
      "would         0.000158  0.000058  0.000094  0.000164\n",
      "up            0.000212  0.000084  0.000034  0.000066\n",
      "year          0.000070  0.000039  0.000065  0.000173\n",
      "over          0.000097  0.000028  0.000034  0.000030\n",
      "do you account for depreciation i seriously doubt that a taurus would rack up an extra 4000 in repair cost over 5 year\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "be       0.000507  0.000687  0.000542  0.000624\n",
      "brought  0.000595  0.000441  0.000000  0.000000\n",
      "you      0.000343  0.000258  0.000223  0.000152\n",
      "ok       0.000604  0.000181  0.000000  0.000151\n",
      "right    0.000442  0.000104  0.000051  0.000304\n",
      "john     0.000433  0.000281  0.000111  0.000000\n",
      "that     0.000230  0.000193  0.000185  0.000193\n",
      "if       0.000137  0.000137  0.000217  0.000159\n",
      "up       0.000293  0.000116  0.000047  0.000091\n",
      "name     0.000191  0.000195  0.000038  0.000079\n",
      "so       0.000155  0.000119  0.000109  0.000064\n",
      "good     0.000121  0.000086  0.000137  0.000031\n",
      "few      0.000052  0.000034  0.000065  0.000110\n",
      "example  0.000051  0.000023  0.000054  0.000028\n",
      "ok if you be so right name a few good example that be brought up john\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.000873  0.000124  0.003023  0.000781\n",
      "help        0.000000  0.000330  0.001958  0.000345\n",
      "for         0.000504  0.000222  0.001304  0.000279\n",
      "several     0.000000  0.000000  0.001029  0.000786\n",
      "it          0.000448  0.000230  0.000617  0.000419\n",
      "via         0.000000  0.000000  0.001130  0.000575\n",
      "found       0.000000  0.000675  0.000000  0.000509\n",
      "be          0.000205  0.000277  0.000219  0.000251\n",
      "offer       0.000335  0.000000  0.000000  0.000541\n",
      "contact     0.000000  0.000417  0.000000  0.000393\n",
      "and         0.000163  0.000217  0.000204  0.000217\n",
      "will        0.000103  0.000330  0.000044  0.000206\n",
      "get         0.000139  0.000055  0.000243  0.000237\n",
      "those       0.000058  0.000402  0.000111  0.000089\n",
      "people      0.000134  0.000136  0.000024  0.000067\n",
      "mail        0.000033  0.000047  0.000167  0.000096\n",
      "appreciate  0.000023  0.000073  0.000105  0.000042\n",
      "again       0.000033  0.000031  0.000017  0.000023\n",
      "found it thanks i get several offer for help i appreciate it and will be contact those people via e mail thanks again\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "moon        0.000000  0.001101  0.000000  0.001325\n",
      "the         0.000544  0.000558  0.000506  0.000643\n",
      "of          0.000240  0.000501  0.000356  0.000367\n",
      "have        0.000411  0.000265  0.000267  0.000234\n",
      "worship     0.000000  0.000964  0.000000  0.000000\n",
      "element     0.000000  0.000964  0.000000  0.000000\n",
      "sabbath     0.000000  0.000964  0.000000  0.000000\n",
      "phase       0.000000  0.000964  0.000000  0.000000\n",
      "originally  0.000000  0.000964  0.000000  0.000000\n",
      "nature      0.000000  0.000964  0.000000  0.000000\n",
      "egyptian    0.000000  0.000964  0.000000  0.000000\n",
      "be          0.000167  0.000226  0.000178  0.000205\n",
      "determine   0.000000  0.000321  0.000341  0.000000\n",
      "and         0.000133  0.000177  0.000166  0.000177\n",
      "in          0.000135  0.000128  0.000161  0.000143\n",
      "that        0.000151  0.000127  0.000122  0.000127\n",
      "early       0.000150  0.000092  0.000000  0.000077\n",
      "by          0.000071  0.000058  0.000078  0.000073\n",
      "heard       0.000028  0.000091  0.000024  0.000098\n",
      "stuff       0.000035  0.000042  0.000019  0.000016\n",
      "i have heard that the sabbath be originally determine by the phase of the moon and have element of moon worship early stuff egyptian in nature\n",
      "==> predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "file       0.000000  0.000000  0.005253  0.001311\n",
      "every      0.000000  0.000000  0.000452  0.001601\n",
      "feel       0.000000  0.000000  0.000000  0.002018\n",
      "be         0.000375  0.000508  0.000401  0.000461\n",
      "day        0.000000  0.000692  0.000000  0.001016\n",
      "could      0.000264  0.000000  0.000293  0.000662\n",
      "wonder     0.000000  0.000000  0.000714  0.000434\n",
      "monthly    0.000000  0.000000  0.000000  0.001083\n",
      "quarterly  0.000000  0.000000  0.000000  0.001083\n",
      "bloat      0.000000  0.000000  0.000000  0.001083\n",
      "28         0.000000  0.000000  0.000000  0.001083\n",
      "post       0.000401  0.000129  0.000000  0.000323\n",
      "the        0.000204  0.000209  0.000189  0.000241\n",
      "rather     0.000000  0.000128  0.000169  0.000380\n",
      "get        0.000128  0.000051  0.000223  0.000218\n",
      "this       0.000106  0.000134  0.000122  0.000157\n",
      "if         0.000101  0.000102  0.000160  0.000117\n",
      "30         0.000161  0.000000  0.000142  0.000094\n",
      "than       0.000041  0.000120  0.000050  0.000094\n",
      "faq        0.000000  0.000067  0.000080  0.000103\n",
      "i be wonder if the faq file could be post quarterly rather than monthly every 28 30 day i get this bloat feel\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "thanks     0.000397  0.000056  0.001375  0.000355\n",
      "be         0.000372  0.000504  0.000397  0.000457\n",
      "explain    0.000000  0.000358  0.000000  0.001189\n",
      "could      0.000262  0.000000  0.000290  0.000657\n",
      "activity   0.000000  0.000000  0.000000  0.001074\n",
      "loss       0.000000  0.000000  0.000000  0.001074\n",
      "alan       0.000000  0.000000  0.000000  0.001074\n",
      "ron        0.000000  0.000000  0.000000  0.001074\n",
      "regularly  0.000000  0.000000  0.000000  0.001074\n",
      "timer      0.000000  0.000000  0.000000  0.001074\n",
      "post       0.000397  0.000128  0.000000  0.000320\n",
      "the        0.000202  0.000207  0.000188  0.000239\n",
      "command    0.000000  0.000000  0.000315  0.000459\n",
      "report     0.000000  0.000000  0.000441  0.000321\n",
      "someone    0.000083  0.000319  0.000000  0.000306\n",
      "in         0.000150  0.000143  0.000179  0.000159\n",
      "this       0.000105  0.000133  0.000121  0.000155\n",
      "what       0.000085  0.000068  0.000085  0.000078\n",
      "interest   0.000000  0.000072  0.000079  0.000081\n",
      "this activity be regularly report in ron s interest post could someone explain what the command loss timer be thanks alan\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.003353  0.000625\n",
      "of          0.000269  0.000561  0.000399  0.000411\n",
      "thanks      0.000266  0.000038  0.000921  0.000238\n",
      "stereo      0.000000  0.000000  0.000000  0.001439\n",
      "planetary   0.000000  0.000000  0.000000  0.001439\n",
      "phobos      0.000000  0.000000  0.000000  0.001340\n",
      "satellite   0.000000  0.000000  0.000000  0.001340\n",
      "mar         0.000000  0.000000  0.000000  0.001340\n",
      "tell        0.000000  0.000000  0.000306  0.001020\n",
      "anyone      0.000262  0.000000  0.000733  0.000307\n",
      "might       0.000000  0.000000  0.000321  0.000896\n",
      "the         0.000271  0.000277  0.000252  0.000320\n",
      "surface     0.000000  0.000000  0.000495  0.000491\n",
      "and         0.000199  0.000265  0.000248  0.000265\n",
      "any         0.000187  0.000062  0.000542  0.000161\n",
      "moon        0.000000  0.000411  0.000000  0.000494\n",
      "in          0.000201  0.000191  0.000240  0.000213\n",
      "deimos      0.000000  0.000000  0.000000  0.000720\n",
      "gifs        0.000000  0.000000  0.000506  0.000175\n",
      "where       0.000135  0.000000  0.000286  0.000234\n",
      "me          0.000094  0.000182  0.000294  0.000036\n",
      "especially  0.000387  0.000000  0.000000  0.000192\n",
      "but         0.000042  0.000169  0.000149  0.000096\n",
      "will        0.000063  0.000201  0.000027  0.000126\n",
      "do          0.000091  0.000088  0.000143  0.000079\n",
      "that        0.000113  0.000095  0.000091  0.000095\n",
      "prefer      0.000071  0.000000  0.000235  0.000080\n",
      "can         0.000066  0.000054  0.000123  0.000099\n",
      "order       0.000193  0.000077  0.000000  0.000066\n",
      "find        0.000079  0.000030  0.000090  0.000019\n",
      "interested  0.000020  0.000014  0.000021  0.000020\n",
      "can anyone tell me where i might find stereo image of planetary and planetary satellite surface gifs prefer but any will do i m especially interested in stereo of the surface of phobos deimos mar and the moon in that order thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "42       0.000502  0.000000  0.001259  0.000000\n",
      "thought  0.000000  0.000000  0.000329  0.001421\n",
      "be       0.000363  0.000492  0.000388  0.000447\n",
      "the      0.000395  0.000404  0.000367  0.000466\n",
      "help     0.000000  0.000195  0.001159  0.000204\n",
      "chip     0.000000  0.000000  0.001302  0.000000\n",
      "really   0.000268  0.000739  0.000237  0.000000\n",
      "that     0.000329  0.000276  0.000265  0.000276\n",
      "on       0.000145  0.000152  0.000413  0.000366\n",
      "it       0.000265  0.000136  0.000365  0.000248\n",
      "could    0.000170  0.000000  0.000189  0.000428\n",
      "hear     0.000000  0.000303  0.000365  0.000097\n",
      "24       0.000000  0.000282  0.000454  0.000000\n",
      "pete     0.000000  0.000000  0.000699  0.000000\n",
      "intel    0.000000  0.000000  0.000699  0.000000\n",
      "reason   0.000000  0.000000  0.000699  0.000000\n",
      "proper   0.000000  0.000000  0.000699  0.000000\n",
      "egg      0.000000  0.000000  0.000699  0.000000\n",
      "stomp    0.000000  0.000000  0.000699  0.000000\n",
      "endian   0.000000  0.000000  0.000699  0.000000\n",
      "war      0.000000  0.000471  0.000173  0.000000\n",
      "value    0.000000  0.000469  0.000173  0.000000\n",
      "break    0.000000  0.000000  0.000220  0.000265\n",
      "side     0.000262  0.000000  0.000222  0.000000\n",
      "you      0.000164  0.000123  0.000107  0.000073\n",
      "but      0.000040  0.000164  0.000145  0.000094\n",
      "get      0.000082  0.000033  0.000144  0.000140\n",
      "write    0.000000  0.000066  0.000196  0.000099\n",
      "some     0.000027  0.000045  0.000169  0.000119\n",
      "their    0.000187  0.000101  0.000028  0.000032\n",
      "so       0.000074  0.000057  0.000052  0.000030\n",
      "out      0.000057  0.000053  0.000041  0.000025\n",
      "hear hear really i thought that the reason it be 42 be that it be really 24 but write a 42 so that on intel chip you could get the proper value pete help stomp out the endian war break some egg on their side\n",
      "==> predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "see       0.000979  0.001563  0.000139  0.000000\n",
      "you       0.000655  0.000493  0.000427  0.000290\n",
      "need      0.000262  0.000000  0.000793  0.000403\n",
      "unless    0.001399  0.000000  0.000000  0.000000\n",
      "hmmmmmmm  0.001399  0.000000  0.000000  0.000000\n",
      "accident  0.001399  0.000000  0.000000  0.000000\n",
      "me        0.000184  0.000354  0.000572  0.000070\n",
      "won       0.000645  0.000395  0.000000  0.000000\n",
      "have      0.000298  0.000192  0.000193  0.000170\n",
      "let       0.000224  0.000309  0.000200  0.000000\n",
      "an        0.000264  0.000174  0.000181  0.000062\n",
      "more      0.000097  0.000104  0.000052  0.000061\n",
      "let me see unless you have an accident you won t need more hmmmmmmm\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000740  0.000326  0.001915  0.000409\n",
      "motorcycle  0.001734  0.000000  0.000000  0.000000\n",
      "mandatory   0.001734  0.000000  0.000000  0.000000\n",
      "drl         0.001734  0.000000  0.000000  0.000000\n",
      "already     0.001038  0.000000  0.000446  0.000000\n",
      "be          0.000300  0.000407  0.000321  0.000369\n",
      "well        0.000068  0.000065  0.000040  0.000045\n",
      "well drl s be already mandatory for motorcycle\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "god       0.000000  0.003608  0.000000  0.000499\n",
      "profit    0.000000  0.000000  0.000000  0.001706\n",
      "the       0.000345  0.000353  0.000320  0.000407\n",
      "twilight  0.000000  0.000000  0.000000  0.000916\n",
      "blare     0.000000  0.000000  0.000000  0.000916\n",
      "bless     0.000000  0.000000  0.000000  0.000916\n",
      "cacs      0.000000  0.000000  0.000000  0.000916\n",
      "caste     0.000000  0.000000  0.000000  0.000916\n",
      "fraering  0.000000  0.000000  0.000000  0.000916\n",
      "freely    0.000000  0.000000  0.000000  0.000916\n",
      "usl       0.000000  0.000000  0.000000  0.000916\n",
      "pgf       0.000000  0.000000  0.000000  0.000916\n",
      "presence  0.000000  0.000000  0.000000  0.000916\n",
      "srl03     0.000000  0.000000  0.000000  0.000916\n",
      "edu       0.000099  0.000000  0.000348  0.000377\n",
      "be        0.000159  0.000215  0.000169  0.000195\n",
      "phil      0.000000  0.000257  0.000000  0.000430\n",
      "it        0.000174  0.000089  0.000239  0.000163\n",
      "and       0.000127  0.000169  0.000158  0.000169\n",
      "right     0.000276  0.000065  0.000032  0.000190\n",
      "in        0.000128  0.000122  0.000153  0.000136\n",
      "from      0.000060  0.000069  0.000096  0.000115\n",
      "even      0.000027  0.000153  0.000054  0.000087\n",
      "by        0.000067  0.000055  0.000074  0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may       0.000021  0.000090  0.000056  0.000031\n",
      "from phil g fraering pgf srl03 cacs usl edu right the profit caste be bless by god and may freely blare it presence in the even twilight\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "help     0.000000  0.000315  0.001873  0.000330\n",
      "the      0.000425  0.000436  0.000395  0.000502\n",
      "rest     0.000000  0.000886  0.000000  0.000424\n",
      "shirt    0.000000  0.001130  0.000000  0.000000\n",
      "night    0.000000  0.001130  0.000000  0.000000\n",
      "delete   0.000000  0.001130  0.000000  0.000000\n",
      "brown    0.000000  0.001130  0.000000  0.000000\n",
      "of       0.000141  0.000293  0.000209  0.000215\n",
      "out      0.000276  0.000259  0.000199  0.000120\n",
      "in       0.000158  0.000150  0.000188  0.000167\n",
      "can      0.000104  0.000085  0.000193  0.000155\n",
      "about    0.000169  0.000113  0.000081  0.000073\n",
      "anybody  0.000088  0.000057  0.000209  0.000041\n",
      "find     0.000124  0.000046  0.000141  0.000030\n",
      "rest delete can anybody out in a p h help out find out about the night of the brown shirt\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000710  0.000312  0.001838  0.000393\n",
      "new         0.001201  0.000000  0.000375  0.000582\n",
      "23          0.000685  0.000000  0.000000  0.001035\n",
      "thermostat  0.001664  0.000000  0.000000  0.000000\n",
      "sound       0.000415  0.000000  0.000242  0.000819\n",
      "you         0.000389  0.000293  0.000254  0.000173\n",
      "do          0.000211  0.000202  0.000331  0.000183\n",
      "that        0.000261  0.000219  0.000211  0.000219\n",
      "can         0.000153  0.000125  0.000284  0.000228\n",
      "say         0.000156  0.000370  0.000136  0.000080\n",
      "how         0.000102  0.000131  0.000086  0.000072\n",
      "again       0.000047  0.000044  0.000024  0.000033\n",
      "you can say that again how do 23 for a new thermostat sound\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.002411  0.000000  0.000602\n",
      "land        0.000000  0.000000  0.000000  0.001753\n",
      "mach        0.000000  0.000000  0.000000  0.001325\n",
      "flight      0.000000  0.000000  0.000000  0.001234\n",
      "head        0.000000  0.000000  0.000000  0.001234\n",
      "military    0.000000  0.000000  0.000000  0.001234\n",
      "of          0.000165  0.000344  0.000245  0.000252\n",
      "new         0.000478  0.000000  0.000149  0.000232\n",
      "could       0.000161  0.000000  0.000179  0.000405\n",
      "handle      0.000000  0.000000  0.000257  0.000474\n",
      "month       0.000000  0.000000  0.000260  0.000459\n",
      "belive      0.000000  0.000000  0.000000  0.000662\n",
      "boom        0.000000  0.000000  0.000000  0.000662\n",
      "decent      0.000000  0.000000  0.000000  0.000662\n",
      "direction   0.000000  0.000000  0.000000  0.000662\n",
      "fran        0.000000  0.000000  0.000000  0.000662\n",
      "aircraft    0.000000  0.000000  0.000000  0.000662\n",
      "25aircraft  0.000000  0.000000  0.000000  0.000662\n",
      "int         0.000000  0.000000  0.000000  0.000662\n",
      "25          0.000000  0.000000  0.000000  0.000662\n",
      "san         0.000000  0.000000  0.000000  0.000662\n",
      "odd         0.000000  0.000000  0.000000  0.000662\n",
      "supersonic  0.000000  0.000000  0.000000  0.000662\n",
      "super       0.000000  0.000000  0.000436  0.000165\n",
      "be          0.000115  0.000155  0.000123  0.000141\n",
      "the         0.000125  0.000128  0.000116  0.000147\n",
      "on          0.000069  0.000072  0.000196  0.000173\n",
      "ago         0.000053  0.000071  0.000048  0.000323\n",
      "it          0.000126  0.000064  0.000173  0.000118\n",
      "question    0.000086  0.000294  0.000043  0.000035\n",
      "east        0.000000  0.000222  0.000000  0.000232\n",
      "what        0.000105  0.000084  0.000104  0.000096\n",
      "hear        0.000000  0.000144  0.000173  0.000046\n",
      "that        0.000104  0.000087  0.000084  0.000087\n",
      "there       0.000113  0.000040  0.000062  0.000139\n",
      "some        0.000026  0.000043  0.000160  0.000113\n",
      "speed       0.000118  0.000000  0.000069  0.000051\n",
      "heard       0.000019  0.000062  0.000017  0.000067\n",
      "base        0.000015  0.000048  0.000024  0.000065\n",
      "over        0.000061  0.000018  0.000021  0.000019\n",
      "few         0.000024  0.000015  0.000029  0.000050\n",
      "the supersonic boom hear a few month ago over i belive san fran head east of what i heard some new super speed mach 25 aircraft what military base int he direction of flight be there that could handle a mach 25aircraft on it land decent odd question\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                  autos  religion  graphics     space\n",
      "try            0.000000  0.000329  0.004991  0.001203\n",
      "he             0.000000  0.002812  0.000000  0.000703\n",
      "thought        0.000000  0.000000  0.000363  0.001570\n",
      "be             0.000268  0.000362  0.000286  0.000329\n",
      "to             0.000226  0.000336  0.000252  0.000285\n",
      "win            0.000000  0.000000  0.000000  0.000773\n",
      "consideration  0.000000  0.000000  0.000000  0.000773\n",
      "sam            0.000000  0.000000  0.000000  0.000773\n",
      "ross           0.000000  0.000000  0.000000  0.000773\n",
      "perot          0.000000  0.000000  0.000000  0.000773\n",
      "disappoint     0.000000  0.000000  0.000000  0.000773\n",
      "further        0.000000  0.000000  0.000000  0.000773\n",
      "matt           0.000000  0.000000  0.000000  0.000773\n",
      "likely         0.000000  0.000000  0.000000  0.000773\n",
      "walton         0.000000  0.000000  0.000000  0.000773\n",
      "gate           0.000000  0.000000  0.000000  0.000773\n",
      "after          0.000414  0.000091  0.000000  0.000187\n",
      "it             0.000147  0.000075  0.000202  0.000137\n",
      "bill           0.000000  0.000301  0.000000  0.000239\n",
      "third          0.000282  0.000000  0.000000  0.000250\n",
      "kid            0.000000  0.000256  0.000000  0.000274\n",
      "but            0.000045  0.000182  0.000160  0.000103\n",
      "my             0.000224  0.000105  0.000045  0.000086\n",
      "in             0.000108  0.000103  0.000129  0.000114\n",
      "first          0.000076  0.000175  0.000041  0.000029\n",
      "think          0.000107  0.000054  0.000065  0.000018\n",
      "more           0.000054  0.000057  0.000029  0.000034\n",
      "come           0.000024  0.000019  0.000050  0.000060\n",
      "my first thought be ross perot after further consideration i think he d be more likely to try to win it but come in a disappoint third try bill gate try sam walton s kid matt\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "to    0.000505  0.000751  0.000563  0.000636\n",
      "know  0.000402  0.000322  0.000555  0.000171\n",
      "just  0.000370  0.000188  0.000218  0.000366\n",
      "want  0.000256  0.000173  0.000163  0.000111\n",
      "i just want to know\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "it         0.000610  0.000313  0.000839  0.000571\n",
      "be         0.000278  0.000377  0.000297  0.000342\n",
      "gee        0.000272  0.000000  0.000000  0.000856\n",
      "look       0.000277  0.000024  0.000574  0.000237\n",
      "you        0.000376  0.000283  0.000245  0.000167\n",
      "any        0.000209  0.000069  0.000605  0.000180\n",
      "release    0.000469  0.000000  0.000342  0.000000\n",
      "tion       0.000804  0.000000  0.000000  0.000000\n",
      "radia      0.000804  0.000000  0.000000  0.000000\n",
      "confuse    0.000804  0.000000  0.000000  0.000000\n",
      "genus      0.000804  0.000000  0.000000  0.000000\n",
      "hole       0.000804  0.000000  0.000000  0.000000\n",
      "locate     0.000804  0.000000  0.000000  0.000000\n",
      "tor        0.000804  0.000000  0.000000  0.000000\n",
      "radiation  0.000804  0.000000  0.000000  0.000000\n",
      "radiator   0.000804  0.000000  0.000000  0.000000\n",
      "punch      0.000804  0.000000  0.000000  0.000000\n",
      "where      0.000150  0.000000  0.000319  0.000262\n",
      "really     0.000154  0.000425  0.000136  0.000000\n",
      "sound      0.000200  0.000000  0.000117  0.000396\n",
      "me         0.000106  0.000204  0.000328  0.000040\n",
      "like       0.000197  0.000106  0.000114  0.000235\n",
      "what       0.000128  0.000102  0.000127  0.000117\n",
      "will       0.000070  0.000225  0.000030  0.000140\n",
      "do         0.000102  0.000098  0.000160  0.000088\n",
      "when       0.000041  0.000172  0.000039  0.000083\n",
      "since      0.000074  0.000065  0.000114  0.000000\n",
      "make       0.000051  0.000059  0.000031  0.000028\n",
      "gee you really make me confuse what be radiator where be it locate what do it look like will it release any radiation since it sound like radia tion genus tor when you punch hole\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "file      0.000000  0.000000  0.003935  0.000982\n",
      "yo        0.000000  0.000000  0.000000  0.003023\n",
      "assume    0.000000  0.000000  0.000000  0.002742\n",
      "be        0.000421  0.000571  0.000450  0.000518\n",
      "every     0.000000  0.000000  0.000339  0.001199\n",
      "string    0.000000  0.000000  0.000000  0.001512\n",
      "sig       0.000000  0.000000  0.000000  0.001512\n",
      "mining    0.000000  0.000000  0.000000  0.001512\n",
      "you       0.000380  0.000286  0.000248  0.000168\n",
      "cash      0.000000  0.000000  0.000000  0.000812\n",
      "limit     0.000000  0.000000  0.000000  0.000812\n",
      "award     0.000000  0.000000  0.000000  0.000812\n",
      "to        0.000119  0.000177  0.000132  0.000149\n",
      "away      0.000306  0.000000  0.000000  0.000257\n",
      "own       0.000000  0.000261  0.000000  0.000299\n",
      "ok        0.000335  0.000100  0.000000  0.000083\n",
      "right     0.000245  0.000058  0.000028  0.000169\n",
      "get       0.000096  0.000038  0.000167  0.000163\n",
      "there     0.000138  0.000049  0.000076  0.000170\n",
      "can       0.000075  0.000061  0.000138  0.000111\n",
      "them      0.000018  0.000142  0.000078  0.000142\n",
      "would     0.000121  0.000045  0.000072  0.000125\n",
      "one       0.000088  0.000071  0.000041  0.000144\n",
      "like      0.000099  0.000053  0.000058  0.000119\n",
      "because   0.000066  0.000122  0.000000  0.000130\n",
      "don       0.000044  0.000086  0.000057  0.000043\n",
      "anything  0.000030  0.000019  0.000036  0.000088\n",
      "give      0.000056  0.000046  0.000044  0.000014\n",
      "time      0.000023  0.000025  0.000046  0.000045\n",
      "mine      0.000022  0.000020  0.000024  0.000054\n",
      "nice      0.000013  0.000011  0.000013  0.000013\n",
      "a cash award be ok a time limit would be nice you can t give away mining right assume there s anything to mine because you don t own them sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "get     0.000358  0.000143  0.000625  0.000611\n",
      "life    0.000587  0.000170  0.000000  0.000775\n",
      "people  0.000346  0.000350  0.000062  0.000173\n",
      "people get a life\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.004100  0.000764\n",
      "site        0.000000  0.000000  0.001891  0.000881\n",
      "ftp         0.000000  0.000000  0.001515  0.000650\n",
      "the         0.000497  0.000509  0.000461  0.000587\n",
      "thanks      0.000325  0.000046  0.001126  0.000291\n",
      "phobos      0.000000  0.000000  0.000000  0.001639\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001639\n",
      "russian     0.000000  0.000000  0.000000  0.001639\n",
      "house       0.000000  0.000000  0.000000  0.001639\n",
      "anyone      0.000321  0.000000  0.000897  0.000375\n",
      "any         0.000229  0.000076  0.000663  0.000197\n",
      "moon        0.000000  0.000502  0.000000  0.000605\n",
      "do          0.000223  0.000214  0.000350  0.000194\n",
      "fat         0.000000  0.000000  0.000000  0.000880\n",
      "ill         0.000000  0.000000  0.000000  0.000880\n",
      "martian     0.000000  0.000000  0.000000  0.000880\n",
      "mission     0.000000  0.000000  0.000000  0.000880\n",
      "if          0.000164  0.000165  0.000260  0.000191\n",
      "on          0.000091  0.000096  0.000260  0.000230\n",
      "of          0.000110  0.000228  0.000163  0.000167\n",
      "ago         0.000070  0.000094  0.000064  0.000429\n",
      "back        0.000245  0.000093  0.000000  0.000139\n",
      "an          0.000166  0.000110  0.000114  0.000039\n",
      "they        0.000139  0.000066  0.000048  0.000130\n",
      "send        0.000176  0.000000  0.000076  0.000120\n",
      "know        0.000102  0.000082  0.000141  0.000044\n",
      "year        0.000058  0.000032  0.000054  0.000144\n",
      "so          0.000093  0.000071  0.000066  0.000038\n",
      "re          0.000049  0.000092  0.000018  0.000102\n",
      "at          0.000047  0.000048  0.000077  0.000062\n",
      "few         0.000031  0.000021  0.000039  0.000066\n",
      "do the russian spacecraft s on the ill fat phobos mission a few year ago send back any image of the martian moon if so do anyone know if they re house at an ftp site thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"==> predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuarcy = 100.00%, test_accuarcy = 62.88%, avg-accuarcy = 81.44%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_doc_vectors, train_labels)\n",
    "\n",
    "train_accuracy = clf.score(train_doc_vectors, train_labels)\n",
    "test_accuracy = clf.score(test_doc_vectors, test_labels)\n",
    "\n",
    "print(f\"training_accuarcy = {train_accuracy*100:.2f}%, test_accuarcy = {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
